{
  "hash": "aa81b22270725bdd0d8c493269c3b084",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"M√©thodes de pr√©vision\"\ntitle-block-banner: true\ntoc: true\ntoc-title: üìö Table des mati√®res\nlang: fr\nnumber-sections: true\nsubtitle: \"\"\nauthor: \"`BOUSSENGUI Fran√ßois` - `BARRE Nicolas` - `SABAYE Fried` \"\nimage: \"mco.png\"\ndescription: \"*Travaux de recherche en √©conom√©trie*\"\ncategories: [√âconom√©trie]\nformat:\n    html:\n        code-fold: true \n        code-line-numbers: false\n        anchor-sections: true\n        smooth-scroll: true\n        citations-hover: true\n        footnotes-hover: true\n        html-math-method: mathjax\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n# Contexte \n\nLes **Moindres Carr√©s Ordinaires** (MCO), ou en anglais Ordinary Least Squares (OLS) est une m√©thode statistique utilis√©e pour mod√©liser la relation entre deux variables quantitatives. Il s'agit de la forme la plus √©l√©mentaire de la r√©gression lin√©aire. En r√©gression lin√©aire simple, une variable ind√©pendante (ou explicative) $x$, est utilis√©e pour pr√©dire une variable d√©pendante (ou r√©ponse) $y$. L'objectif de la r√©gression lin√©aire simple est de trouver les valeurs des coefficients $\\beta_0$ et $\\beta_1$ qui minimisent la somme des carr√©s des erreurs entre les valeurs observ√©es et les valeurs pr√©dites par le mod√®le.\n\nL'√©conom√©trie offre un panel de m√©thodes de pr√©vision statistique qui d√©pendent de la nature des donn√©es ainsi que de la probl√©matique √† r√©soudre.\n\nAinsi, ces r√©sultats s'inscrivent dans le cadre de travaux de recherche en √©conom√©trie r√©alis√©es durant ma seconde ann√©e de Master en √©conomie.\n\n# Objectifs \n\nLes objectifs de ces travaux sont divers.\n\nPrincipalement, ces travaux portent sur la pr√©sentation des principales m√©thodes alternatives aux **Moindres Carr√©s Ordinaires** (MCO).\n\nDans un premier temps, il √©t√© question de proposer une repr√©sentation alternatives des principaux r√©sultats d'une r√©gression lin√©aire simple. Pour ce faire, nous avons propos√© une repr√©sentation sous forme *diagrammatique* (graphique/visuel) des principaux r√©sultats de la m√©thode des **Moindres Carr√©s Ordinaires**.\n\nPuis, dans un second temps, il a √©t√© question de pr√©senter et de classifier les principales m√©thodes alternatives √† celles des **Moindres Carr√©s Ordinaires**.\n\n# M√©thodologie\n\nPour atteindre ces objectifs, nous avons analyser des travaux de recherche en √©conom√©trie et nous avons travaill√© en √©troite collaboration avec notre professeur r√©f√©rent en la mati√®re.\n\nAinsi, nos recherches nous ont permis d'aboutir √† la proposition d'une repr√©sentation graphique des principaux r√©sultats d'une r√©gression lin√©aire simple dont la sp√©cification math√©matiques est : $y = \\beta_0 + \\beta_1x + \\epsilon$, o√π :\n\n-   $y$ est la variable d√©pendante (la r√©ponse)\n-   $x$ est la variable explicative (le pr√©dicteur)\n-   $\\beta_0$ est l'ordonn√©e √† l'origine (l'intercept)\n-   $\\beta_1$ est le coefficient de regression (la pente)\n-   $\\epsilon$ est l'erreur al√©atoire\n\nPar ailleurs, nous avons mis en exergue plusieurs familles de m√©thodes de pr√©vision. Nous pouvons les classer comme suit :\n\n1.  Les m√©thodes d'estimation d√©crivant une **relation lin√©aire** entre la variable √† expliquer $y$ et la/les variable(s) explicative(s) $X$.\n\n-   **Moindres carr√©s ordinaires** : C'est une m√©thode utilis√©e pour estimer les param√®tres d'un mod√®le de r√©gression lin√©aire. Elle minimise la somme des carr√©s des diff√©rences entre les valeurs observ√©es et les valeurs pr√©dites par le mod√®le.\n\n::: {.callout-tip icon=\"false\" collapse=\"true\"}\n## NB\n\nEn d'autres termes, l'objectif est de minimiser la fonction de co√ªt suivante : $S(a,b) = \\sum_{i=1}^{n} (y_i - (a + bx_i ))^2$.\n:::\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n```{=html}\n<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"‚ñ∏\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"‚ñæ\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>\n```\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOrdonn√©e √† l'origine: 4.222151077447228\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCoefficient (pente): 2.9684675107010197\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n-   **R√©gression orthogonale** : √âgalement connue sous le nom de r√©gression des **Moindres Carr√©s Orthogonaux** (Orthogonal Least Squares Regression) ou r√©gression de Deming, est une m√©thode qui prend en compte les erreurs dans les deux variables, √† la fois la variable ind√©pendante ($x$) et la variable d√©pendante ($y$). Contrairement √† la r√©gression lin√©aire ordinaire qui minimise uniquement les erreurs en $y$, la r√©gression orthogonale minimise la somme des distances orthogonales entre les points de donn√©es et la ligne de r√©gression.\n\n::: {.callout-tip icon=\"false\" collapse=\"true\"}\n## NB\n\nEn effet, l'erreur orthogonale pour chaque point $(x_i, y_i)$ est d√©fini√© comme la distance perpendiculaire de ce point √† la ligne $(y = a + bx)$.\n\nCette distance peut √™tre exprim√© par la formule : $d_i = \\frac{|bx_i - y_i + a|}{1 + b^2}$.\n\nLa somme des carr√©s des distances orthogonales est donc :\n\n$S(a,b) = \\sum_{i=1}^{n} \\frac{(bx_i + y_i +a)^2}{1+b^2}$.\n:::\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\nCoefficient (pente): 3.893973142858568\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOrdonn√©e √† l'origine: 3.3470043884096006\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-3.png){fig-align='center' width=100%}\n:::\n:::\n\n\n-   **Moindre Carr√©s Ordinaires VS R√©gression orthogonale**\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n```{=html}\n<style>#sk-container-id-2 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-2 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-2 pre {\n  padding: 0;\n}\n\n#sk-container-id-2 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-2 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-2 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-2 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-2 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-2 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-2 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-2 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-2 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-2 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-2 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-2 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-2 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"‚ñ∏\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-2 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"‚ñæ\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n#sk-container-id-2 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-2 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-2 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-2 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-2 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-2 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-2 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-2 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>\n```\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-5.png){fig-align='center' width=100%}\n:::\n:::\n\n\n> A travers cette visualisation, on peut voir que les droites de r√©gression des 2 m√©thodes sont quasiement surperpos√©es. En d'autres termes, les r√©sultats d'estimation fournis par les 2 m√©thodes sont assez proches.\n\n2.  Les mod√®les qui d√©crivent une **relation non lin√©aire** entre la variable √† expliquer et la/les variable(s) explicative(s).\n\nIl s'agit de la famille des m√©thodes de **R√©gressions non param√©triques** : La r√©gression non param√©trique est une technique statistique qui permet de mod√©liser les relations entre variables sans supposer de forme param√©trique sp√©cifique pour la relation. Contrairement √† la r√©gression param√©trique (comme la r√©gression lin√©aire), la r√©gression non param√©trique ne n√©cessite pas d'hypoth√®ses strictes sur la forme de la relation, ce qui permet de capturer des relations plus complexes et non lin√©aires. Voici quelques exemples de m√©thodes d'estimation non param√©triques :\n\n-   **R√©gression par noyau** : La r√©gression par noyau est une m√©thode non param√©trique qui utilise une fonction noyau pour estimer la relation entre les variables ind√©pendantes et d√©pendantes. Une forme courante de r√©gression par noyau est la r√©gression par noyau de [Nadaraya-Watson](https://en.wikipedia.org/wiki/Kernel_regression). Cette m√©thode consiste √† estimer la valeur de la variable d√©pendante pour une valeur donn√©e de la variable ind√©pendante en prenant une moyenne pond√©r√©e des valeurs observ√©es, les poids √©tant d√©termin√©s par une fonction noyau.\n\n::: {.callout-tip icon=\"false\" collapse=\"true\"}\n## NB\n\n1.  La r√©gression √† noyau est une extension de la r√©gression lin√©aire qui utilise des fonctions de noyau pour permettre la mod√©lisation de relations non lin√©aires. Une fonction de noyau $K(x, x')$ mesure la similarit√© entre deux points dans l'espace de caract√©ristiques.\n\n## 2. Fonction de Co√ªt\n\nLa fonction de co√ªt pour la r√©gression √† noyau est souvent bas√©e sur la perte de Huber, la perte d'epsilon-insensible ou d'autres fonctions de perte robustes. Une fonction de co√ªt typique pour la r√©gression √† noyau est la suivante :\n\n$J(\\alpha) = \\frac{1}{2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\alpha_i \\alpha_j K(x_i, x_j) - \\sum_{i=1}^{N} \\alpha_i y_i$ $+$ $C \\sum_{i=1}^{N} \\max(0, |f(x_i) - y_i| - \\epsilon)$\n\no√π : - $\\alpha_i$ sont les coefficients duals. - $K(x_i, x_j)$est la fonction de noyau. - $y_i$ sont les valeurs cibles. - $C$est un param√®tre de r√©gularisation. - $\\epsilon$ est un param√®tre de tol√©rance pour la perte epsilon-insensible.\n\n## 3. Minimisation de la Fonction de Co√ªt\n\nPour minimiser cette fonction de co√ªt, nous utilisons des techniques d'optimisation convexes telles que le **Gradient Descent**, le **Coordinate Descent** ou des algorithmes sp√©cialis√©s comme le **Sequential Minimal Optimization (SMO)**.\n\n#### Gradient Descent\n\nL'algorithme de gradient descent ajuste les param√®tres $\\alpha$ en suivant le gradient de la fonction de co√ªt :\n\n$\\alpha_i \\leftarrow \\alpha_i - \\eta \\frac{\\partial J(\\alpha)}{\\partial \\alpha_i}$\n\no√π $\\eta$ est le taux d'apprentissage.\n\n#### Sequential Minimal Optimization (SMO)\n\nL'algorithme SMO divise le probl√®me d'optimisation en sous-probl√®mes plus petits qui peuvent √™tre r√©solus analytiquement. Ce processus est it√©ratif et continue jusqu'√† ce que la convergence soit atteinte.\n:::\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n<matplotlib.collections.PathCollection object at 0x148c58730>\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[<matplotlib.lines.Line2D object at 0x148c594b0>]\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<matplotlib.legend.Legend object at 0x148c59900>\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nText(0.5, 1.0, 'R√©gression par noyau')\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-7.png){fig-align='center' width=100%}\n:::\n:::\n\n\n-   **k-NN (k-plus proches voisin)** : Le k-plus proches voisins (k-NN) est un algorithme d'apprentissage supervis√© utilis√© pour la classification et la r√©gression. L'id√©e de base est de pr√©dire la classe ou la valeur d'une observation en utilisant les $k$ observations les plus proches dans l'ensemble d'entra√Ænement.\n\n::: {.callout-tip icon=\"false\" collapse=\"true\"}\n## NB\n\nLa minimisation de la fonction de co√ªt pour les m√©thodes de **k-plus proches voisins** (K-Nearest Neighbors ou K-NN) diff√®re des m√©thodes de r√©gression classiques comme celles utilisant des fonctions de noyau. **k-NN** est un algorithme non param√©trique qui ne construit pas de mod√®le explicite, mais utilise les donn√©es d'apprentissage pour pr√©dire les nouvelles instances directement.\n\n### 1. Introduction √† K-NN\n\nK-NN est une m√©thode bas√©e sur la proximit√© : pour une nouvelle observation, l'algorithme recherche les $k$ observations les plus proches dans l'ensemble de donn√©es d'apprentissage et effectue des pr√©dictions bas√©es sur ces voisins. Pour la r√©gression, la pr√©diction est g√©n√©ralement la moyenne des valeurs cibles des $k$ plus proches voisins.\n\n### 2. Fonction de Co√ªt\n\nDans le contexte de K-NN, la fonction de co√ªt peut √™tre d√©finie comme l'erreur de pr√©diction globale, typiquement mesur√©e par l'erreur quadratique moyenne (Mean Squared Error, MSE) ou l'erreur absolue moyenne (Mean Absolute Error, MAE). Pour la minimiser, l'algorithme K-NN cherche √† optimiser les choix des hyperparam√®tres (notamment $k$ et la m√©trique de distance).\n\n#### Erreur Quadratique Moyenne (MSE)\n\n$J = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2$\n\no√π $y_i$ est la valeur r√©elle et $\\hat{y}_i$ est la valeur pr√©dite.\n\n#### Erreur Absolue Moyenne (MAE)\n\n$J = \\frac{1}{N} \\sum_{i=1}^{N} |y_i - \\hat{y}_i|$\n\n### 3. Optimisation des Hyperparam√®tres\n\nL'optimisation dans K-NN consiste principalement √† trouver le meilleur nombre de voisins ($k$) et la meilleure m√©trique de distance. Les approches courantes pour ce faire incluent la validation crois√©e et les grilles de recherche.\n\n#### Validation Crois√©e\n\nLa validation crois√©e permet de diviser les donn√©es en plusieurs sous-ensembles (folds), en utilisant certains pour entra√Æner le mod√®le et les autres pour le tester, et en r√©p√©tant ce processus plusieurs fois pour r√©duire la variance des r√©sultats.\n\n#### Grille de Recherche (Grid Search)\n\nLa grille de recherche explore syst√©matiquement une plage d'hyperparam√®tres pour trouver la combinaison qui minimise la fonction de co√ªt.\n\n:::\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\nKNeighborsRegressor()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<matplotlib.collections.PathCollection object at 0x148ce0c10>\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[<matplotlib.lines.Line2D object at 0x148ce1b70>]\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<matplotlib.legend.Legend object at 0x148ce2f50>\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nText(0.5, 1.0, 'k-NN')\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-9.png){fig-align='center' width=100%}\n:::\n:::\n\n\n-   **Mod√®les Additifs G√©n√©ralis√©s (GAM)**: Les mod√®les additifs g√©n√©ralis√©s (GAM) sont une extension des mod√®les lin√©aires g√©n√©ralis√©s (GLM) qui permettent de mod√©liser des relations non lin√©aires. Les GAM utilisent des fonctions lisses (comme les splines) pour mod√©liser la relation entre chaque pr√©dicteur et la variable r√©ponse.\n\n::: {.callout-tip icon=\"false\" collapse=\"true\"}\n## NB\n\nDans un GAM, la fonction de co√ªt est minimis√©e en ajustant les fonctions lisses pour chaque variable explicative.\n\nUn GAM a la forme suivante :\n\n$g(E(y)) = \\beta_0 + f_1(x_1) + f_2(x_2) + \\ldots + f_p(x_p)$\n\no√π $g$ est une fonction de lien, $E(y)$ est l'esp√©rance de $y$, $\\beta_0$ est une constante, et $f_i$ sont des fonctions lisses des variables explicatives $x_i$.\n\n### 2. Fonction de Co√ªt\n\nLa fonction de co√ªt pour les GAMs peut √™tre formul√©e en termes de log-vraisemblance n√©gative pour des distributions sp√©cifiques (par exemple, gaussienne, binomiale, poisson). En plus de la log-vraisemblance, on ajoute souvent des p√©nalit√©s de lissage pour √©viter le surajustement. La fonction de co√ªt typique est :\n\n$J(f_1, f_2, \\ldots, f_p) = -\\text{log-vraisemblance} + \\sum_{i=1}^{p} \\lambda_i \\int (f_i''(x_i))^2 dx_i$\n\no√π $\\lambda_i$ sont des param√®tres de r√©gularisation pour les p√©nalit√©s de lissage.\n\n### 3. Minimisation de la Fonction de Co√ªt\n\nLa minimisation de cette fonction de co√ªt se fait g√©n√©ralement par des m√©thodes d'optimisation num√©riques, telles que :\n\n-   **Penalized Iteratively Reweighted Least Squares (P-IRLS)** : Une extension de l'algorithme IRLS utilis√© pour les mod√®les lin√©aires g√©n√©ralis√©s, adapt√©e pour inclure les p√©nalit√©s de lissage.\n-   **Gradient Descent** et ses variantes.\n\n:::\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n<matplotlib.collections.PathCollection object at 0x148d055d0>\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[<matplotlib.lines.Line2D object at 0x148d06260>]\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<matplotlib.legend.Legend object at 0x148d07eb0>\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nText(0.5, 1.0, 'Mod√®le Additif G√©n√©ralis√©')\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-11.png){fig-align='center' width=100%}\n:::\n:::\n\n\n-   **For√™t al√©atoire**: Les for√™ts al√©atoires (Random Forests) sont une m√©thode d'apprentissage supervis√© populaire utilis√©e pour la classification et la r√©gression. Elles fonctionnent en construisant plusieurs arbres de d√©cision pendant la phase d'entra√Ænement et en produisant la classe qui est le mode des classes (classification) ou la moyenne des pr√©dictions (r√©gression) de chaque arbre individuel.\n\n::: {.callout-tip icon=\"false\" collapse=\"true\"}\n## NB\n\nLa for√™t al√©atoire (Random Forest) est un ensemble d'arbres de d√©cision entra√Æn√©s sur des sous-√©chantillons al√©atoires des donn√©es. L'id√©e est de combiner les pr√©dictions de plusieurs arbres pour am√©liorer la performance et r√©duire le risque de surajustement. La fonction de co√ªt dans une for√™t al√©atoire est g√©n√©ralement li√©e √† l'erreur de pr√©diction des arbres, et l'optimisation consiste √† ajuster divers hyperparam√®tres pour minimiser cette erreur.\n\n### 1. Introduction √† la For√™t Al√©atoire\n\nUne for√™t al√©atoire est un mod√®le d'ensemble qui construit plusieurs arbres de d√©cision et combine leurs pr√©dictions. Pour la r√©gression, la pr√©diction finale est la moyenne des pr√©dictions de tous les arbres.\n\n### 2. Fonction de Co√ªt\n\nPour la r√©gression, la fonction de co√ªt est souvent mesur√©e par l'erreur quadratique moyenne (Mean Squared Error, MSE) ou l'erreur absolue moyenne (Mean Absolute Error, MAE) entre les valeurs r√©elles et les valeurs pr√©dites :\n\n#### Erreur Quadratique Moyenne (MSE)\n\n$J = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2$\n\no√π $y_i$ est la valeur r√©elle et $\\hat{y}_i$ est la valeur pr√©dite.\n\n### 3. Optimisation des Hyperparam√®tres\n\nLa minimisation de la fonction de co√ªt dans une for√™t al√©atoire passe par l'optimisation des hyperparam√®tres suivants :\n\n-   **Nombre d'arbres (n_estimators)** : Plus d'arbres peuvent am√©liorer la performance mais augmentent le temps de calcul.\n\n-   **Profondeur maximale des arbres (max_depth)** : Limiter la profondeur peut pr√©venir le surajustement.\n\n-   **Nombre de caract√©ristiques consid√©r√©es pour chaque split (max_features)** : Un bon r√©glage de ce param√®tre peut am√©liorer la performance.\n\n-   **Taille minimale des √©chantillons pour diviser un n≈ìud (min_samples_split)**.\n\n-   **Taille minimale des √©chantillons pour une feuille (min_samples_leaf)**.\n:::\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\nRandomForestRegressor()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<matplotlib.collections.PathCollection object at 0x14ac8b7c0>\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[<matplotlib.lines.Line2D object at 0x14aca4670>]\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<matplotlib.legend.Legend object at 0x14aca6050>\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nText(0.5, 1.0, 'For√™t al√©atoire')\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-13.png){fig-align='center' width=100%}\n:::\n:::\n\n\n# Comparaison des m√©thodes et conclusion\n\nEn conclusion, nous pouvons dire qu'il existe 2 grandes familles de m√©thodes de pr√©vision :\n\n-   **Les mod√®les lin√©aires** : d√©crivant une relation lin√©aire entre la variable d√©pendante et les variables ind√©pendantes.\n-   **Les mod√®les non lin√©aires** : inversement, d√©crivant une relation non lin√©aire entre la variable d√©pendante et les variables ind√©pendantes.\n\nGr√¢ce √† des repr√©sentations graphiques, nous allons visualiser les diff√©rences de r√©sultats entre ces deux familles de m√©thodes :\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\nLinearRegression()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinearRegression()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRandomForestRegressor()\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<matplotlib.collections.PathCollection object at 0x14c8571f0>\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[<matplotlib.lines.Line2D object at 0x14c857d00>]\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[<matplotlib.lines.Line2D object at 0x14c880c40>]\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[<matplotlib.lines.Line2D object at 0x14c881c30>]\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<matplotlib.legend.Legend object at 0x148c5a6b0>\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-15.png){fig-align='center' width=100%}\n:::\n:::\n\n\nPar ailleurs, pour chacune de ces m√©thodes nous avons mis en √©vidence les √©l√©ments suivants :\n\n-   **La forme fonctionnelle du mod√®le** : La forme fonctionnelle d'un mod√®le se r√©f√®re √† la sp√©cification de la relation math√©matiques entre les variables ind√©pendantes (ou explicatives) et la variable d√©pendante (ou √† expliquer). Cette sp√©cification d√©finit comment les variables sont li√©es dans le mod√®le et peut prendre plusieurs formes selon la nature des donn√©es et les hypoth√®ses sous-jacentes\n\n-   **Les principales hypoth√®ses associ√©es au mod√®le** : Les principales hypoth√®ses d'un mod√®le sont essentielles pour garantir la validit√© et la fiabilit√© des estimations des coefficients.\n\n-   Leur application dans des outils techniques appropri√©s : {{< fa brands r-project >}} et `Python` {{< fa brands python >}}\n\n# Outils techniques\n\nPour r√©aliser ces travaux, nous avons utilis√© {{< fa brands r-project >}} et `Python` {{<fa brands python >}} pour la partie mod√©lisation. Pour la mise en forme du rapport ainsi que du support de pr√©sentation, nous avons utilis√© [LateX](https://fr.wikipedia.org/wiki/LaTeX).\n\n::: {style=\"text-align:center;\"}\n> Vous trouverez le rapport ainsi que le support de pr√©sentation ici :\n\n::: chevron-styling\n\n{{< iconify pixelarticons:chevron-down size=5x >}}\n\n\n:::\n:::\n\n::: {style=\"text-align:center;\"}\n[Rapport : Repr√©sentation sous forme de diagramme des MCO {{< fa arrow-up-right-from-square >}}](AlternativesMCO.pdf){.btn .btn-outline-primary .btn .center role=\"button\"}\n:::\n\n::: {style=\"text-align:center;\"}\n[Pr√©sentation : Alternatives aux MCO {{< fa arrow-up-right-from-square >}}](Alternatives%20aux%20MCO.pdf){.btn .btn-outline-primary .btn .center role=\"button\"}\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}