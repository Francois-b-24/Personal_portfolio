{
  "hash": "0fe44c7f42c98cad0c863ef41092b697",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Pr√©vision des d√©fauts de paiement bancaire\"\ntitle-block-banner: true\ntoc: true\ntoc-title: üìö Table des mati√®res\nlang: fr\nnumber-sections: true\nsubtitle: \"\"\nauthor: \"`BOUSSENGUI Fran√ßois` - `BARRE Nicolas` - `LEGER Aline`\"\ndescription: \"*Application des m√©thodes de classification supervis√©e*\"\nimage: \"classification.png\"\ncategories: [Machine Learning]\nformat:\n    html:\n        code-fold: true \n        code-line-numbers: false\n        anchor-sections: true\n        smooth-scroll: true\n        citations-hover: true\n        footnotes-hover: true\n        html-math-method: mathjax\n---\n\n\n\n\n# Contexte g√©n√©ral\n\nLa d√©tection des d√©fauts de paiements des cr√©dits bancaires est un enjeu majeur pour les banques. Une gestion rigoureuse, permet d'avoir un recouvrement de cr√©ance efficace et maintenir des flux de tr√©sorerie solides. De ce fait, il est essentiel de minimmiser ces pertes. La **classification supervis√©e** regroupe l'ensemble des m√©thodes statistiques dont l'objectif principal est de pr√©dire pour un individu donn√© l'appartenance √† une classe connue au pr√©alable. Nous sommes ici dans le cas d'une banque de d√©tails qui souhaite attribuer un *score* ou *probabilit√©* de risque √† ses clients. \n\n# Objectifs du travail\n\nAinsi, dans le cas des d√©fauts de paiement bancaire, l'objectif est de pouvoir mod√©liser l'appartenance d'un individu √† l'une des classes suivantes :\n\n1.  **Oui** [1], l'individu est en d√©faut de paiement ;\n\n2.  **Non** [0], l'individu n'est pas en d√©faut de paiement ;\n\n\n# M√©thodologie\n\nDe prime abord, nous avons r√©alis√© une analyse descriptive qui a nous permis de mettre en exergue un **d√©s√©quilibre des classes** pour la variable √† expliquer. En d'autres termes, nous avons une pr√©sence √©lev√©e de personne n'√©tant pas en d√©faut de paiement contrairement √† celles qui le sont. \n\nCela est un fait positif pour une banque en soi. \n\nCependant, ce d√©s√©quilibre impact n√©gativement la performance et biaise le r√©sultat des mod√®les.  \n\nCela nous a donc conduit a proc√©d√© comme suit :\n\n\n*   D√©coupage de la population en 2 sous-groupes :\n\n    +   Un groupe d√©di√© √† l'apprentissage, autrement dit, le groupe d'entra√Ænement (2/3) ;\n\n    +   Un groupe d√©di√© √† la validation des mod√®les, autrement dit, le groupe test (1/3) ;\n\n*   Premi√®re application des mod√®les sans prise en compte du d√©s√©quilibre des classes. \n\n*   Seconde √† application des mod√®les en prenant en compte le d√©s√©quilibre des classes par le biais d'application de m√©thode de r√©-√©chantillonnage des classes, √† savoir :\n\n::: {.callout-tip icon=false collapse=\"true\"}\n## Sous-√©chantillonnage\n\nR√©duit le nombre d'√©chantillons de la classe majoritaire.\n\n:::\n\n::: {.callout-tip icon=false collapse=\"true\"}\n## Sur-√©chantillognnage\n\nAugmente le nombre d'√©chantillons de la classe minoritaire.\n\n:::\n    \n::: {.callout-tip icon=false collapse=\"true\"}\n##  SMOTE\n\nG√©n√®re des exemples synth√©tiques de la classe minoritaire.\n\n:::\n\n* Les mod√®les utilis√©s sont les suivants :\n\n::: {.callout-tip icon=false collapse=\"true\"}\n## Analyse lin√©aire discriminante (LDA)\n\nL'analyse discriminante lin√©aire (LDA) est une technique de classification et de r√©duction de dimension qui vise √† s√©parer les classes en trouvant une projection lin√©aire des donn√©es qui maximise la s√©paration entre les classes tout en minimisant la variance au sein des classes. \n\n:::\n\n::: {.callout-tip icon=false collapse=\"true\"}\n## Analyse quadratique discriminante (QDA)\n\nL'analyse discriminante quadratique (QDA) est une extension de l'analyse discriminante lin√©aire (LDA) qui permet de mod√©liser des fronti√®res de d√©cision non lin√©aires. Contrairement √† LDA, qui suppose que les covariances des classes sont identiques, QDA permet √† chaque classe d'avoir sa propre matrice de covariance. Cela permet une mod√©lisation plus flexible, mais n√©cessite plus de param√®tres et peut donc √™tre moins efficace avec de petits ensembles de donn√©es.\n:::\n \n::: {.callout-tip icon=false collapse=\"true\"}   \n## Arbres de d√©cisions\n\nLes arbres de d√©cision sont des mod√®les de machine learning non param√©triques utilis√©s pour la classification et la r√©gression. Ils apprennent des r√®gles de d√©cision simples d√©duites des donn√©es pour pr√©dire la valeur de la variable cible.\n\n:::\n  \n::: {.callout-tip icon=false collapse=\"true\"} \n## Bagging, Boosting\n\nLes termes \"Bagging\" et \"Boosting\" sont des techniques utilis√©es en apprentissage automatique (machine learning) pour am√©liorer les performances des mod√®les pr√©dictifs en utilisant des ensembles de mod√®les plus simples.\n\n:::\n\n::: {.callout-tip icon=false collapse=\"true\"}\n## For√™ts al√©atoires\n\nLes for√™ts al√©atoires sont une technique de machine learning utilis√©e pour la classification et la r√©gression. Elles fonctionnent en combinant plusieurs arbres de d√©cision, chacun construit sur un √©chantillon diff√©rent des donn√©es d'entra√Ænement. Le principe de base est le suivant :\n\n1. **Construction d'arbres** : Un grand nombre d'arbres de d√©cision sont construits, chaque arbre √©tant entra√Æn√© sur un √©chantillon al√©atoire des donn√©es d'entra√Ænement.\n2. **Pr√©diction par vote majoritaire** : Pour la classification, chaque arbre \"vote\" pour une classe, et la classe la plus souvent choisie par les arbres est la pr√©diction finale. Pour la r√©gression, la pr√©diction finale est la moyenne des pr√©dictions de tous les arbres.\n\nL'utilisation de multiples arbres et l'√©chantillonnage al√©atoire des donn√©es permettent de r√©duire le risque de surapprentissage (overfitting) et d'am√©liorer la robustesse et la pr√©cision des pr√©dictions.\n\n:::   \n\n   \n\n# Principaux r√©sultats\n\nApr√®s avoir entra√Æn√© les mod√®les sur l'√©chantillon d'entra√Ænement, nous avons appliqu√© les mod√®les sur les donn√©es test afin d'en appr√©cier leur performance. Plus pr√©cis√©ment, nous avons compar√© les r√©sultats de nos 2 approches. C'est-√†-dire l'approche tenant compte du d√©s√©quilibre des classes et celle ne la prenant pas en compte.\n\nSur la base des diff√©rentes m√©triques d'√©valuation que nous avons utilis√©, ils s'av√®re que le mod√®le le plus performabnt est une **For√™t Al√©atoire** sur laquelle nous avons appliqu√© la m√©thode **SMOTE**. \n\nIl pr√©sente un taux de bonne pr√©dictions de 94,6% contre 5,4% de taux de mauvaises pr√©dictions.\n\n# Conclusions et perspective\n\nDans la r√©alit√©, il est tr√®s probable de rencontrer un d√©s√©quilibre de classes de la variable √† expliquer pour les probl√®mes de classification supervis√©e. \n\nC'est un aspect qui biaise fortement les r√©sultats d'estimations. Par cons√©quent, il est important de pouvoir le d√©tecter assez t√¥t et appliquer les m√©thodes ad√©quates pour prendre en compte le probl√®me. Au sortir de l√†, cela nous permet d'obtenir un mod√®le qui n'est pas biais√©. Ce dernier nous permet donc ais√©ment de pr√©dire l'appartenance √† l'une des classes de la variable √† expliquer. Dans le cas des d√©fauts de paiement bancaire, l'int√©r√™t de ce genre de m√©thodes est qu'elle donne la possibilit√© de mettre en place de moyens de pr√©vention pour se pr√©munir des personnes qui pr√©sentent un fort risque d'√™tre en d√©faut de paiement. \n\n# Outil technique \n\n- {{< fa brands r-project >}}\n\n\n::: {style=\"text-align:center;\"}\n\n> Vous trouverez le rapport ici :\n\n::: chevron-styling\n\n{{< iconify pixelarticons:chevron-down size=5x >}}\n\n\n:::\n:::\n\n::: {style=\"text-align:center;\"}\n[Lire le rapport {{< fa arrow-up-right-from-square >}}](Application de modeÃÄles de machine learning.pdf){.btn .btn-outline-primary .btn .center role=\"button\"}\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}