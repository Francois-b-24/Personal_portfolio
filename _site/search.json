[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Passionné par l’analyse des données et l’apprentissage automatique, avec une solide expérience dans la création de modèles prédictifs et le traitement de grandes quantités de données. Compétences éprouvées en Python, , SQL, et dans l’utilisation de bibliothèques de machine learning telles que TensorFlow, scikit-learn et PyTorch. Expérience dans l’application de techniques de data mining, de modélisation statistique et de deep learning pour résoudre des problèmes complexes et améliorer la prise de décision.\nPar ailleurs, je suis passionné de sport mécanique ainsi que d’horlogerie.\nTélécharger mon CV"
  },
  {
    "objectID": "index.html#bonjour-et-bienvenue",
    "href": "index.html#bonjour-et-bienvenue",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Passionné par l’analyse des données et l’apprentissage automatique, avec une solide expérience dans la création de modèles prédictifs et le traitement de grandes quantités de données. Compétences éprouvées en Python, , SQL, et dans l’utilisation de bibliothèques de machine learning telles que TensorFlow, scikit-learn et PyTorch. Expérience dans l’application de techniques de data mining, de modélisation statistique et de deep learning pour résoudre des problèmes complexes et améliorer la prise de décision.\nPar ailleurs, je suis passionné de sport mécanique ainsi que d’horlogerie.\nTélécharger mon CV"
  },
  {
    "objectID": "index.html#expérience-professionnelle",
    "href": "index.html#expérience-professionnelle",
    "title": "Curriculum Vitae",
    "section": " Expérience professionnelle",
    "text": "Expérience professionnelle\n\nChargé d’études statistiques | (Février 2023 – ) | AON France\nData analyst | (Novembre 2021 – Février 2023) | Ascential group\nData analyst | (Avril 2021 – Septembre 2021) | April Moto"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Curriculum Vitae",
    "section": " Education",
    "text": "Education\n\nMaster Data Science / Business Econ. (2019 – 2021) Université de Tours\nLicence d’économie d’entreprise (2016 – 2019) Université de Tours"
  },
  {
    "objectID": "index.html#capacités-de-présentation-et-de-vulgarisation",
    "href": "index.html#capacités-de-présentation-et-de-vulgarisation",
    "title": "Curriculum Vitae",
    "section": " Capacités de présentation et de vulgarisation",
    "text": "Capacités de présentation et de vulgarisation"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Tout",
    "section": "",
    "text": "Stratégie de fixation des prix\n\n\n4 min.\n\n\n\nTarification\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMéthodes de prévision économétrique\n\n\n2 min.\n\n\n\nÉconométrie\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModélisation de l’efficacité technique d’une entreprise\n\n\n4 min.\n\n\n\nÉconométrie\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL’immobilier à Saratoga ~ Californie\n\n\n2 min.\n\n\n\nMachine Learning\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMarketing quantitatif au service de la santé\n\n\n3 min.\n\n\n\nÉconométrie\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrévision des défauts de paiement bancaire\n\n\n4 min.\n\n\n\nMachine Learning\n\n\n\n\n\n\n\n\nAucun article correspondant\n\n Retour au sommet"
  },
  {
    "objectID": "posts/second/index.html",
    "href": "posts/second/index.html",
    "title": "L’immobilier à Saratoga ~ Californie",
    "section": "",
    "text": "Contexte général\nDans le cadre d’un projet réalisé dans l’apprentissage de méthodes de datamining, il a été question d’appliquer des méthodes de classification non supervisée sur une base de données contenant des informations sur 1728 biens immobiliers de la ville de Saratoga, en Californie.\n\n\nObjectifs du travail\nLes biens immobiliers de la ville de Saratoga présentent des caractéristiques qui ont une influence non négligeable sur leur prix. Cependant, malgré ces différence de prix, nous partons du postulat qu’il est tout à fait possible de regrouper ces biens en classes homogènes. En d’autres termes, en groupe de biens présentant des caractéristiques similaires. Par le biais de techniques de classification non supervisée, il a donc été donc question de proposer des classes de biens homogènes au sens statistique du terme.\n\n\nMéthodologie\nPour ce faire, nous avons appliquer des méthodes de classification non supervisée sur notre jeu de données.\n\nAnalyses factorielles\n\nAnalyse factorielle des correspondances (AFC)\nAnalyse des composantes principales (ACP)\nAnalyse des composantes multiples (ACM)\n\nMéthodes de partitionnement\n\nClassification ascendante hiérarchique (CAH)\nK-Means (K plus proches voisins)\n\n\n\n\nPrincipaux résultats\nL’analyse des composantes principales (ACP) nous a permis de déterminer les 2 grandes classes de biens homogènes suivantes :\n\nLes biens immobiliers présentant des prix faibles, une petite surface habitable et qui sont récents.\nInverserment, les biens immobiliers présentant des prix relativement élevés, une surface habitable relativement élevée et qui sont plus anciens.\n\nL’analyse des composantes multiples (ACM) nous a permis quant à elle de classifier les biens comme suit :\n\nLes biens chauffés à l’électrique et n’ayant pas de cheminée\nInversement, les biens possédant au minimum une cheminée et chauffés à l’air chaud ou à l’eau chaude\n\n\n\nOutil technique\n\nLogiciel R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Retour au sommet"
  },
  {
    "objectID": "posts/first/index.html",
    "href": "posts/first/index.html",
    "title": "Méthodes de prévision économétrique",
    "section": "",
    "text": "Contexte général\nLes moindres carrés ordinaires (MCO), ou en anglais Ordinary Least Squares (OLS), est une méthode statistique utilisée pour estimer les coefficients d’une équation de régression linéaire. La méthode des moindres carrés vise à minimiser la somme des carrés des résidus (différences entre les valeurs observées et les valeurs prédites par le modèle).\nL’économétrie offre un panel de méthodes de prévision statistique qui dépendent de la nature des données ainsi que de la problématique à résoudre. Ainsi, ces travaux de s’inscrivent dans le cadre de travaux de recherches réalisées durant ma seconde année de Master en économétrie.\n\n\nObjectifs du travail\nLes objectifs de ces travaux sont divers. Principalement, ces travaux portent sur la présentation des principales méthodes alternatives à celle des Moindres Carrés Ordinaires (MCO). Dans un premier temps, il a donc été question de présenter sous forme de diagramme (graphique) les principaux résultats de la méthode des Moindres Carrés Ordinaires. Dans un second temps, il a été question de présenter les principales méthodes alternatives à la méthode des Moindres Carrés Ordinaires.\n\n\nMéthodologie\nPour atteindre ces objectifs, nous avons analysé les travaux de recherche en économétrie et nous avons travaillé en étroite collaboration avec notre professeur référent en la matière.\nAinsi, nos recherches nous ont permis d’aboutir à la proposition d’une représentation graphique des principaux résultats d’une régression linéaire simple : \\(y = \\beta_0 + \\beta_1X + \\epsilon\\)\nPar ailleurs, nous avons mis en exergue plusieurs familles de méthodes de prévision économétrique. Nous pouvons les classer comme suit :\n\nMoindres carrés ordinaires\nRégression orthogonale\nRégression non paramétrique\n\nPour chacune des méthodes, nous avons mis en évidence :\n\nLa forme fonctionnelle du modèle\nLes principales hypothèses associées au modèle\nLeur application dans le logiciel R\n\n\n\nOutils techniques\n\nLogiciel R\nLatex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Retour au sommet"
  },
  {
    "objectID": "posts/sixth/index.html",
    "href": "posts/sixth/index.html",
    "title": "Marketing quantitatif au service de la santé",
    "section": "",
    "text": "Contexte général\nLe marketing quantitatif est une approche analytique du marketing qui se concentre sur l’utilisation de données et de statistiques pour prendre des décisions éclairées et mesurer les performances des activités marketing. Les prestataires de services peuvent avoir recours à ce genre de techniques afin de mieux comprendre la demande et ainsi affiner leur propositions. En l’occurrence, nous sommes dans le cas d’une étude qui concerne le programme d’assurance Medicare aux Etats-Unis. C’est un programme d’assurance maladie qui aide les personnes âgées à payer les services de santé. Certaines personnes souscrivent une assurance complémentaire (Medigap) qui les aide à payer le reste à charge de Medicare et les autres dépenses médicales qui ne sont pas couvertes par Medicare. Cette assurance est parfois fournie par le dernier employeur de la personne dans le cadre d’une prestation de retraite. D’autres personnes souscrivent une assurance maladie complémentaire auprès de sociétés d’assurances privées.\n\n\nObjectifs du travail\nL’objectif du travail est d’appliquer des méthodes issues de l’économétrie afin de répondre à la question suivante : Au vue des caractéristiques des individus ayant souscrit au programme Medicare, quel est le profil des ceux ayant souscrit à une complémentaire santé ?\n\n\nMéthodologie\nPour ce faire, il a été nécessaire de traiter une base données contenant des informations sur des indivudus ayant souscrits au programme d’assurance Medicare. La variable d’intérêt est Assurance. Elle vaut 1 quand l’individu à souscrit à une complémentaire et 0 sinon.\nDans un premier temps, une analyse descriptive de la base de données à été nécessaire pour dégager les tendances primaires de cette base données. Cette analyse descriptive a permis de déterminer les profils types des individus ayant souscrit à une complémentaire et ceux ne l’ayant pas fait.\nEnsuite, afin de répondre à la question soulevée dans la problématique, l’application de méthodes économétriques à été nécessaire. Plus précisément, la réponse à la question à nécéssité l’application de modèles dont la variable à expliquer est binaire. Dans. notre cas, il s’agit d’un modèle Logit. Le modèle Logit, ou modèle de régression logistique, est un outil statistique utilisé pour modéliser une variable dépendante binaire (c’est-à-dire une variable qui prend deux valeurs possibles, généralement 0 et 1) en fonction d’une ou plusieurs variables explicatives. Dans notre cas, la variable dépendante que nous modélisons est Assurance, valant 1 quand l’individu à souscrit à une complémentaire et 0 sinon.\n\n\nPrincipaux résultats\nL’application de cette méthode économétrique a permis de déterminer le type d’individu inscrit au programme d’assurance Medicare ayant une forte probabilité de souscrire à une complémentaire privée. Par la suite, au vue des résultats obtenus, cela à conduit à des recommandations qui peuvent être utiles lors des campagnes de prévention, ou pour mieux cibler les personnes qui sont plus probables de souscrire à ce genre de services.\n\n\nOutil technique\n\nLogiciel R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Retour au sommet"
  },
  {
    "objectID": "posts/third/index.html",
    "href": "posts/third/index.html",
    "title": "Prévision des défauts de paiement bancaire",
    "section": "",
    "text": "Contexte général\nLa détection des défauts de paiements des crédits bancaires est un enjeu majeur pour les banques. Une gestion rigoureuse, permet d’avoir un recouvrement de créance efficace et maintenir des flux de trésorerie solides. De ce fait, il est essentiel de minimmiser ces pertes. La classification supervisée regroupe l’ensemble des méthodes statistiques dont l’objectif principal est de prédire pour un individu donné l’appartenance à une classe connue au préalable. Nous sommes ici dans le cas d’un banque de détails qui souhaite attribuer un score ou probabilité de risque à ses clients.\n\n\nObjectifs du travail\nAinsi, dans le cas des défauts de paiement bancaire, l’objectif est de pouvoir modéliser l’appartenance d’un individu à l’une des classes suivantes :\n\nOui (1), l’individu est en défaut de paiement ;\nNon (0), l’individu n’est pas en défaut de paiement ;\n\nL’application des méthodes de classification supervisée aboutira à l’attribution d’un score ou probabilité de risque de défauts de paiement.\n\n\nMéthodologie\nAprès avoir réalisé une analyse descriptive qui a nous permis de découvrir un déséquilibre des classes pour la variable à expliquer (Une présence élevée de personne n’étant pas en défaut de paiement contrairement à celles qui le sont). Cela nous a donc conduit a procédé comme suit :\n\nDécoupage de la population en 2 sous-groupes :\n\nUn groupe dédié à l’apprentissage, autrement dit, le groupe d’entraînement (2/3) ;\nUn groupe dédié à la validation des modèles, autrement dit, le groupe test (1/3) ;\n\nPremière application des modèles sans prise en compte du déséquilibre des classes\nSeconde à application des modèles en prenant en compte le déséquilibre des classes par le biais d’application de méthode de ré-échantillonnage des classes, à savoir :\n\nSous-échantillonnage\nSur-échantillognnage\nSMOTE (qui est une combinaison des 2 méthodes précédentes)\n\nLes modèles utilisés sont les suivants :\n\nAnalyse linéaire discriminante\nAnalyse quadratique discriminante\nArbres de décisions\nBagging, Boosting\nForêts aléatoires\n\n\n\n\nPrincipaux résultats\nAprès avoir entraîné les modèles sur l’échantillon d’entraînement, nous avons appliqué les modèles sur les données test. Plus précisément, nous avons comparé les résultats obtenu en ayant pris en compte le déséquilibre des classes et ceux obtenu en ne l’ayant pas pris en compte. Il s’avère que le modèle que nous avons retenu sur la base des métriques d’évaluation est une Forêt Aléatoire sur laquelle nous avons appliqué la méthode SMOTE. Il présente un taux de bonne prédictions de 94,6% contre 5,4% de taux de mauvaises prédictions.\n\n\nConclusions et perspective\nIl est fort probable de rencontrer un déséquilibre de classes de la variable à expliquer pour les problèmes de classification supervisée. C’est un aspect qui biaise fortement les résultats d’estimations. Par conséquent, il est important de pouvoir le détecter assez tôt et appliquer les méthodes adéquates pour résoudre le problème. Au sortir de là, nous obtenons un modèle qui n’est pas biaisé. Ce dernier nous permet donc aisément de prédire l’appartenance à l’une des classes de la variable à expliquer. Dans le cas des défauts de paiement bancaire, l’intérêt de ce genre de méthodes est qu’elle donne la possibilité de mettre en place de moyens de prévention pour se protéger des risques des personnes qui sont en défauts de paiement.\n\n\nOutil technique\n\nLogiciel R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Retour au sommet"
  },
  {
    "objectID": "posts/fourth/index.html",
    "href": "posts/fourth/index.html",
    "title": "Modélisation de l’efficacité technique d’une entreprise",
    "section": "",
    "text": "Contexte général\nL’analyse des frontières stochastiques (SFA) est une méthode de modélisation économique. Elle trouve son point de départ dans les modèles stochastiques de production frontière introduits simultanément par Aigner, Lovell et Schmidt (1977) et Meeusen et Van den Broeck (1977).\nLe modèle de frontière de production sans composante aléatoire peut s’écrire :\n\\(y_i = f(x_i, \\beta)\\times TE_i\\)\noù \\(y_i\\) est la production scalaire observée du producteur \\(i\\) ; \\(i=1,..I,\\) \\(x_i\\) est un vecteur de \\(N\\) entrées utilisé par le \\(producteur_i\\) ;\n\n\\(\\beta\\) est un vecteur de paramètres technologiques à estimer ;\n\\(f(x_i , \\beta)\\) est la fonction frontière de production.\n\n\\(TE_i\\) désigne l’efficacité technique définie comme le rapport entre la production observée et la production maximale réalisable. \\(TE = (\\frac{y}{y*})\\). \\(TE_i = 1\\) montre que la ième entreprise obtient la production maximale réalisable, tandis que \\(TE_i\\) &lt; 1 fournit une mesure de l’écart entre la production observée et la production maximale réalisable. En d’autres, détermine l’utilisation non efficiente des inputs.\nUne composante stochastique décrivant les chocs aléatoires affectant le processus de production est ajoutée. Ces chocs ne sont pas directement imputables au producteur ou à la technologie sous-jacente. Ces chocs peuvent provenir de changements climatiques, de difficultés économiques ou simplement de chance. Nous notons ces effets par \\(exp(v_i)\\). Chaque producteur est confronté à un choc différent, mais nous supposons que les chocs sont aléatoires et qu’ils sont décrits par une distribution commune.\nLa frontière de production stochastique deviendra :\n\\(y_i = f(x_i, \\beta) \\times TE_i \\times (v_i)\\)\nNous supposons que \\(TE_i\\) est également une variable stochastique, avec une fonction de distribution spécifique, commune à tous les producteurs.\nL’analyse des frontières stochastiques a également examiné l’efficacité du « coût » et du « profit » (voir Kumbhakar & Lovell 2003). L’approche de la « frontière des coûts » tente de mesurer dans quelle mesure l’entreprise se trouve loin de la minimisation totale des coûts (c’est-à-dire du rapport coût-efficacité). Du point de vue de la modélisation, la composante non négative d’inefficacité des coûts est ajoutée plutôt que soustraite dans la spécification stochastique. “L’analyse de la frontière du profit” examine le cas où les producteurs sont traités comme ceux qui maximisent le profit (la production et les intrants doivent être décidés par l’entreprise) et non comme ceux qui minimisent les coûts (où le niveau de production est considéré comme étant donné de manière exogène). La spécification ici est similaire à celle de la « frontière de production ».\n\n\nObjectifs du travail\nL’objectif de ce travail est d’appliquer les techniques d’analyse des frontières de production sur des données de transport aérien américain. Pour ce faire, nous disposions d’une base de données de 232 observations de sociétés issues du transport aérien américain. Les variables présentes dans le jeu de données sont :\n\nLe coût total\nLa quantité produite\nLe prix du travail\nLe prix du capital\nLe prix du carburant\nLa part du coût du travail dans le coût total\nLa part du coût du capital dans le coût total\nLa part du coût du carburant dans le coût total\n\n\n\nMéthodologie\nPour atteindre notre objectif, nous avons tout d’abord procédé à une analyse descriptive de notre jeu de données qui nous a permis d’observer les tendances générales qui s’y dégagent. En d’autres termes, nous avons réalisé une analyse des coûts, des quantités produites et de la productivité des entreprises.\nEnsuite, nous avons réalisé une analyse de la frontière stochastique respectivement du point de vue des coûts mais aussi de la production. Dans les deux cas, nous avons réalisé diverses modélisations afin d’apprécier les résultats des différentes formes fonctionnelles que peuvent prendre ces modèles.\n\n\nOutil technique\n\nLogiciel R\n\n\n\n\n\n\n\n Retour au sommet"
  },
  {
    "objectID": "posts/fifth/index.html",
    "href": "posts/fifth/index.html",
    "title": "Stratégie de fixation des prix",
    "section": "",
    "text": "Le pricing en économie fait référence à l’ensemble des processus et des stratégies utilisés par les entreprises pour fixer les prix de leurs produits ou services. Il s’agit d’une composante essentielle du marketing et de la gestion des entreprises, car le prix d’un produit influence directement la demande des consommateurs, la concurrence sur le marché, et la rentabilité de l’entreprise.\n\n\n\nAnalyse des Coûts : Comprendre les coûts fixes et variables associés à la production et à la distribution d’un produit pour s’assurer que le prix couvre ces coûts et permet une marge bénéficiaire.\nÉtude de la Demande : Analyser comment les consommateurs réagissent aux changements de prix, ce qui implique souvent l’étude de l’élasticité-prix de la demande.\nConcurrence : Prendre en compte les prix fixés par les concurrents et la position concurrentielle de l’entreprise sur le marché. Cela peut conduire à des stratégies de prix compétitives telles que le prix d’écrémage ou le prix de pénétration.\nObjectifs de l’Entreprise : Fixer les prix en fonction des objectifs stratégiques de l’entreprise, qui peuvent inclure la maximisation des profits, la part de marché, la survie sur le marché, ou le leadership en termes de qualité.\nValeur Perçue : Considérer la valeur perçue par les consommateurs, qui peut justifier des prix plus élevés si le produit est perçu comme offrant un bénéfice supérieur ou une qualité supérieure.\n\n\n\n\n\nPrix de Pénétration : Fixer un prix bas pour entrer rapidement sur un marché et attirer un large volume de consommateurs.\nPrix d’Écrémage : Fixer un prix initial élevé pour maximiser les profits des segments de marché moins sensibles au prix, avant de baisser progressivement le prix.\nPrix Psychologique : Utiliser des techniques de fixation des prix qui influencent la perception du consommateur, comme fixer un prix à 9,99 € au lieu de 10 €.\nPrix de Groupe : Offrir des prix différents à différents segments de marché en fonction de leur disposition à payer.\nPrix de Prestiges : Fixer un prix élevé pour donner une image de qualité supérieure ou de luxe.\n\nLe pricing est donc une discipline complexe qui requiert une compréhension approfondie de nombreux facteurs économiques et comportementaux pour réussir."
  },
  {
    "objectID": "posts/fifth/index.html#les-principaux-aspects-du-pricing",
    "href": "posts/fifth/index.html#les-principaux-aspects-du-pricing",
    "title": "Stratégie de fixation des prix",
    "section": "",
    "text": "Analyse des Coûts : Comprendre les coûts fixes et variables associés à la production et à la distribution d’un produit pour s’assurer que le prix couvre ces coûts et permet une marge bénéficiaire.\nÉtude de la Demande : Analyser comment les consommateurs réagissent aux changements de prix, ce qui implique souvent l’étude de l’élasticité-prix de la demande.\nConcurrence : Prendre en compte les prix fixés par les concurrents et la position concurrentielle de l’entreprise sur le marché. Cela peut conduire à des stratégies de prix compétitives telles que le prix d’écrémage ou le prix de pénétration.\nObjectifs de l’Entreprise : Fixer les prix en fonction des objectifs stratégiques de l’entreprise, qui peuvent inclure la maximisation des profits, la part de marché, la survie sur le marché, ou le leadership en termes de qualité.\nValeur Perçue : Considérer la valeur perçue par les consommateurs, qui peut justifier des prix plus élevés si le produit est perçu comme offrant un bénéfice supérieur ou une qualité supérieure."
  },
  {
    "objectID": "posts/fifth/index.html#stratégies-de-pricing",
    "href": "posts/fifth/index.html#stratégies-de-pricing",
    "title": "Stratégie de fixation des prix",
    "section": "",
    "text": "Prix de Pénétration : Fixer un prix bas pour entrer rapidement sur un marché et attirer un large volume de consommateurs.\nPrix d’Écrémage : Fixer un prix initial élevé pour maximiser les profits des segments de marché moins sensibles au prix, avant de baisser progressivement le prix.\nPrix Psychologique : Utiliser des techniques de fixation des prix qui influencent la perception du consommateur, comme fixer un prix à 9,99 € au lieu de 10 €.\nPrix de Groupe : Offrir des prix différents à différents segments de marché en fonction de leur disposition à payer.\nPrix de Prestiges : Fixer un prix élevé pour donner une image de qualité supérieure ou de luxe.\n\nLe pricing est donc une discipline complexe qui requiert une compréhension approfondie de nombreux facteurs économiques et comportementaux pour réussir."
  },
  {
    "objectID": "index.html#capacités-organisationnelles",
    "href": "index.html#capacités-organisationnelles",
    "title": "Curriculum Vitae",
    "section": " Capacités organisationnelles",
    "text": "Capacités organisationnelles"
  },
  {
    "objectID": "index.html#powerbi",
    "href": "index.html#powerbi",
    "title": "Curriculum Vitae",
    "section": " PowerBI",
    "text": "PowerBI"
  }
]