[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "François BOUSSENGUI",
    "section": "",
    "text": "Data Scientist, je suis passionné par les statistiques et de tout ce qui touche à la donnée.\nMon rôle : Accompagner les entreprises dans la valorisation de leurs données, permettant ainsi une prise de décisions stratégiques éclairées.\nSur ce site, vous découvrirez mon parcours académique et professionnel, un aperçu de mes compétences – acquises et en cours de développement – ainsi que des projets que j’ai réalisés."
  },
  {
    "objectID": "posts/fifth/index.html",
    "href": "posts/fifth/index.html",
    "title": "Stratégie de fixation des prix",
    "section": "",
    "text": "Le pricing en économie fait référence à l’ensemble des processus et des stratégies utilisés par les entreprises pour fixer les prix de leurs produits ou services. Il s’agit d’une composante essentielle du marketing et de la gestion des entreprises, car le prix d’un produit influence directement la demande des consommateurs, la concurrence sur le marché, et la rentabilité de l’entreprise.\n\n\n\nAnalyse des Coûts : Comprendre les coûts fixes et variables associés à la production et à la distribution d’un produit pour s’assurer que le prix couvre ces coûts et permet une marge bénéficiaire.\nÉtude de la Demande : Analyser comment les consommateurs réagissent aux changements de prix, ce qui implique souvent l’étude de l’élasticité-prix de la demande.\n\n\n\n\n\n\n\nElasticité-prix\n\n\n\n\n\nL’élasticité prix-demande mesure la sensibilité de la quantité demandée d’un bien ou service par rapport à une variation de son prix. Elle est définie comme le pourcentage de variation de la quantité demandée divisé par le pourcentage de variation du prix. Voici la formule de l’élasticité prix-demande :\n\\(E_{pd} = \\frac{\\Delta Q / Q}{\\Delta P / P}\\)\noù :\n\n\\(E_{pd}\\) est l’élasticité prix-demande,\n\\(\\Delta Q\\) est la variation de la quantité demandée,\n\\(Q\\) est la quantité demandée initiale,\n\\(\\Delta P\\) est la variation du prix,\n\\(P\\) est le prix initial.\n\nEn termes différentiels, cette formule peut être exprimée comme :\n\\(E_{pd} = \\frac{dQ}{dP} \\times \\frac{P}{Q}\\)\n\n\n\nÉlasticité unitaire \\((E_{pd} = -1)\\) : Une variation de 1% du prix entraîne une variation de 1% de la quantité demandée dans le sens opposé.\nDemande élastique \\((E_{pd} &lt; -1)\\) : La demande est très sensible aux variations de prix. Une variation de 1% du prix entraîne une variation de plus de 1% de la quantité demandée.\nDemande inélastique \\((-1 &lt; E_{pd} &lt; 0)\\) : La demande est peu sensible aux variations de prix. Une variation de 1% du prix entraîne une variation de moins de 1% de la quantité demandée.\nDemande parfaitement élastique \\((E_{pd} = -\\infty)\\) : Toute variation de prix entraînera une variation infinie de la quantité demandée.\nDemande parfaitement inélastique \\((E_{pd} = 0)\\) : La quantité demandée reste constante quelle que soit la variation de prix.\n\n\n\n\nSupposons qu’une augmentation du prix d’un bien de 10% entraîne une diminution de la quantité demandée de 20%.\n\nVariation en pourcentage du prix \\(\\Delta P / P\\) : 10%\nVariation en pourcentage de la quantité demandée \\(\\Delta Q / Q\\) : -20%\n\nL’élasticité prix-demande serait alors :\n\\(E_{pd} = \\frac{-20\\%}{10\\%} = -2\\)\nCela signifie que la demande est élastique : une augmentation de 1% du prix entraîne une diminution de 2% de la quantité demandée.\n\n\n\n\n\nConcurrence : Prendre en compte les prix fixés par les concurrents et la position concurrentielle de l’entreprise sur le marché. Cela peut conduire à des stratégies de prix compétitives telles que le prix d’écrémage ou le prix de pénétration.\nObjectifs de l’Entreprise : Fixer les prix en fonction des objectifs stratégiques de l’entreprise, qui peuvent inclure la maximisation des profits, la part de marché, la survie sur le marché, ou le leadership en termes de qualité.\nValeur Perçue : Considérer la valeur perçue par les consommateurs, qui peut justifier des prix plus élevés si le produit est perçu comme offrant un bénéfice supérieur ou une qualité supérieure.\n\n\n\n\n\nPrix de Pénétration : Fixer un prix bas pour entrer rapidement sur un marché et attirer un large volume de consommateurs.\nPrix d’Écrémage : Fixer un prix initial élevé pour maximiser les profits des segments de marché moins sensibles au prix, avant de baisser progressivement le prix.\nPrix Psychologique : Utiliser des techniques de fixation des prix qui influencent la perception du consommateur, comme fixer un prix à 9,99 € au lieu de 10 €.\nPrix de Groupe : Offrir des prix différents à différents segments de marché en fonction de leur disposition à payer.\nPrix de Prestiges : Fixer un prix élevé pour donner une image de qualité supérieure ou de luxe.\n\nLe pricing est donc une discipline complexe qui requiert une compréhension approfondie de nombreux facteurs économiques et comportementaux pour réussir."
  },
  {
    "objectID": "posts/fifth/index.html#les-principaux-aspects-du-pricing",
    "href": "posts/fifth/index.html#les-principaux-aspects-du-pricing",
    "title": "Stratégie de fixation des prix",
    "section": "",
    "text": "Analyse des Coûts : Comprendre les coûts fixes et variables associés à la production et à la distribution d’un produit pour s’assurer que le prix couvre ces coûts et permet une marge bénéficiaire.\nÉtude de la Demande : Analyser comment les consommateurs réagissent aux changements de prix, ce qui implique souvent l’étude de l’élasticité-prix de la demande.\n\n\n\n\n\n\n\nElasticité-prix\n\n\n\n\n\nL’élasticité prix-demande mesure la sensibilité de la quantité demandée d’un bien ou service par rapport à une variation de son prix. Elle est définie comme le pourcentage de variation de la quantité demandée divisé par le pourcentage de variation du prix. Voici la formule de l’élasticité prix-demande :\n\\(E_{pd} = \\frac{\\Delta Q / Q}{\\Delta P / P}\\)\noù :\n\n\\(E_{pd}\\) est l’élasticité prix-demande,\n\\(\\Delta Q\\) est la variation de la quantité demandée,\n\\(Q\\) est la quantité demandée initiale,\n\\(\\Delta P\\) est la variation du prix,\n\\(P\\) est le prix initial.\n\nEn termes différentiels, cette formule peut être exprimée comme :\n\\(E_{pd} = \\frac{dQ}{dP} \\times \\frac{P}{Q}\\)\n\n\n\nÉlasticité unitaire \\((E_{pd} = -1)\\) : Une variation de 1% du prix entraîne une variation de 1% de la quantité demandée dans le sens opposé.\nDemande élastique \\((E_{pd} &lt; -1)\\) : La demande est très sensible aux variations de prix. Une variation de 1% du prix entraîne une variation de plus de 1% de la quantité demandée.\nDemande inélastique \\((-1 &lt; E_{pd} &lt; 0)\\) : La demande est peu sensible aux variations de prix. Une variation de 1% du prix entraîne une variation de moins de 1% de la quantité demandée.\nDemande parfaitement élastique \\((E_{pd} = -\\infty)\\) : Toute variation de prix entraînera une variation infinie de la quantité demandée.\nDemande parfaitement inélastique \\((E_{pd} = 0)\\) : La quantité demandée reste constante quelle que soit la variation de prix.\n\n\n\n\nSupposons qu’une augmentation du prix d’un bien de 10% entraîne une diminution de la quantité demandée de 20%.\n\nVariation en pourcentage du prix \\(\\Delta P / P\\) : 10%\nVariation en pourcentage de la quantité demandée \\(\\Delta Q / Q\\) : -20%\n\nL’élasticité prix-demande serait alors :\n\\(E_{pd} = \\frac{-20\\%}{10\\%} = -2\\)\nCela signifie que la demande est élastique : une augmentation de 1% du prix entraîne une diminution de 2% de la quantité demandée.\n\n\n\n\n\nConcurrence : Prendre en compte les prix fixés par les concurrents et la position concurrentielle de l’entreprise sur le marché. Cela peut conduire à des stratégies de prix compétitives telles que le prix d’écrémage ou le prix de pénétration.\nObjectifs de l’Entreprise : Fixer les prix en fonction des objectifs stratégiques de l’entreprise, qui peuvent inclure la maximisation des profits, la part de marché, la survie sur le marché, ou le leadership en termes de qualité.\nValeur Perçue : Considérer la valeur perçue par les consommateurs, qui peut justifier des prix plus élevés si le produit est perçu comme offrant un bénéfice supérieur ou une qualité supérieure."
  },
  {
    "objectID": "posts/fifth/index.html#stratégies-de-pricing",
    "href": "posts/fifth/index.html#stratégies-de-pricing",
    "title": "Stratégie de fixation des prix",
    "section": "",
    "text": "Prix de Pénétration : Fixer un prix bas pour entrer rapidement sur un marché et attirer un large volume de consommateurs.\nPrix d’Écrémage : Fixer un prix initial élevé pour maximiser les profits des segments de marché moins sensibles au prix, avant de baisser progressivement le prix.\nPrix Psychologique : Utiliser des techniques de fixation des prix qui influencent la perception du consommateur, comme fixer un prix à 9,99 € au lieu de 10 €.\nPrix de Groupe : Offrir des prix différents à différents segments de marché en fonction de leur disposition à payer.\nPrix de Prestiges : Fixer un prix élevé pour donner une image de qualité supérieure ou de luxe.\n\nLe pricing est donc une discipline complexe qui requiert une compréhension approfondie de nombreux facteurs économiques et comportementaux pour réussir."
  },
  {
    "objectID": "posts/fourth/index.html",
    "href": "posts/fourth/index.html",
    "title": "Mesure de l’efficacité technique d’une entreprise",
    "section": "",
    "text": "1 Contexte général\nL’analyse des frontières stochastiques (SFA) est une méthode de modélisation économique. Elle trouve son point de départ dans les modèles stochastiques de production frontière introduits simultanément par Aigner, Lovell et Schmidt (1977) et Meeusen et Van den Broeck (1977).\nLe modèle de frontière de production sans composante aléatoire peut s’écrire :\n\\(y_i = f(x_i, \\beta)\\times TE_i\\)\noù \\(y_i\\) est la production scalaire observée du producteur \\(i\\) ; \\(i=1,..I,\\) \\(x_i\\) est un vecteur de \\(N\\) entrées utilisé par le \\(producteur_i\\) ;\n\n\\(\\beta\\) est un vecteur de paramètres technologiques à estimer ;\n\\(f(x_i , \\beta)\\) est la fonction frontière de production ;\n\n\\(TE_i\\) désigne l’efficacité technique définie comme le rapport entre la production observée et la production maximale réalisable. \\(TE = (\\frac{y}{y*})\\). \\(TE_i = 1\\) montre que la ième entreprise obtient la production maximale réalisable, tandis que \\(TE_i\\) &lt; 1 fournit une mesure de l’écart entre la production observée et la production maximale réalisable. En d’autres termes, \\(TE_i\\) détermine l’utilisation non efficiente des inputs.\nUne composante stochastique décrivant les chocs aléatoires affectant le processus de production est ajoutée. Ces chocs ne sont pas directement imputables au producteur ou à la technologie sous-jacente. Ces chocs peuvent provenir de changements climatiques, de difficultés économiques ou simplement de chance. Nous notons ces effets par \\(exp(v_i)\\). Chaque producteur est confronté à un choc différent, mais nous supposons que les chocs sont aléatoires et qu’ils sont décrits par une distribution commune.\nLa frontière de production stochastique deviendra :\n\\(y_i = f(x_i, \\beta) \\times TE_i \\times (v_i)\\)\nNous supposons que \\(TE_i\\) est également une variable stochastique, avec une fonction de distribution spécifique, commune à tous les producteurs.\nL’analyse des frontières stochastiques a également examiné l’efficacité du « coût » et du « profit » (voir Kumbhakar & Lovell 2003). L’approche de la « frontière des coûts » tente de mesurer dans quelle mesure l’entreprise se trouve loin de la minimisation totale des coûts (c’est-à-dire du rapport coût-efficacité). Du point de vue de la modélisation, la composante non négative d’inefficacité des coûts est ajoutée plutôt que soustraite dans la spécification stochastique. « L’analyse de la frontière du profit » examine le cas où les producteurs sont traités comme ceux qui maximisent le profit (la production et les intrants doivent être décidés par l’entreprise) et non comme ceux qui minimisent les coûts (où le niveau de production est considéré comme étant donné de manière exogène). La spécification ici est similaire à celle de la « frontière de production ».\n\n\n2 Objectifs du travail\nL’objectif de ce travail est d’appliquer les techniques d’analyse des frontières de production sur des données de transport aérien américain. Pour ce faire, nous disposions d’une base de données de 232 observations de sociétés issues du transport aérien américain. Les variables présentes dans le jeu de données sont les suivantes :\n\n\n\nVariables\n\n\n\n\nCoût total\n\n\nQuantité produite\n\n\nLe prix du travail\n\n\nLe prix du capital\n\n\nLe prix du carburant\n\n\nLe part du coût du travail dans le coût total\n\n\nLe part du coût du capital dans le coût total\n\n\nLe part du coût du carburant dans le coût total\n\n\n\n\n\n3 Méthodologie\nPour atteindre notre objectif, nous avons tout d’abord procédé à une analyse descriptive de notre jeu de données qui nous a permis d’observer les tendances générales qui s’y dégagent. En d’autres termes, nous avons réalisé une étude sur :\n\nAnalyse des coûts\nQuantités produites\nLa productivité des entreprises\n\nEnsuite, nous avons réalisé une modélisation de la frontière stochastique respectivement du point de vue des coûts mais aussi de la production. Dans les deux cas, nous avons réalisé diverses modélisations afin d’apprécier les résultats des différentes formes fonctionnelles que peuvent prendre ces modèles et confronter les résultats obtenus dans le but d’otenir le meilleur.\n\n\n4 Outil technique\n\n\n\n\n\nVous trouverez le rapport ici :\n\n\n\n\n\n\n\n\n\n\n\n Retour au sommet"
  },
  {
    "objectID": "posts/third/index.html",
    "href": "posts/third/index.html",
    "title": "Prévision des défauts de paiement bancaire",
    "section": "",
    "text": "1 Contexte général\nLa détection des défauts de paiements des crédits bancaires est un enjeu majeur pour les banques. Une gestion rigoureuse, permet d’avoir un recouvrement de créance efficace et maintenir des flux de trésorerie solides. De ce fait, il est essentiel de minimmiser ces pertes. La classification supervisée regroupe l’ensemble des méthodes statistiques dont l’objectif principal est de prédire pour un individu donné l’appartenance à une classe connue au préalable. Nous sommes ici dans le cas d’une banque de détails qui souhaite attribuer un score ou probabilité de risque à ses clients.\n\n\n2 Objectifs du travail\nAinsi, dans le cas des défauts de paiement bancaire, l’objectif est de pouvoir modéliser l’appartenance d’un individu à l’une des classes suivantes :\n\nOui [1], l’individu est en défaut de paiement ;\nNon [0], l’individu n’est pas en défaut de paiement ;\n\n\n\n3 Méthodologie\nDe prime abord, nous avons réalisé une analyse descriptive qui a nous permis de mettre en exergue un déséquilibre des classes pour la variable à expliquer. En d’autres termes, nous avons une présence élevée de personne n’étant pas en défaut de paiement contrairement à celles qui le sont.\nCela est un fait positif pour une banque en soi.\nCependant, ce déséquilibre impact négativement la performance et biaise le résultat des modèles.\nCela nous a donc conduit a procédé comme suit :\n\nDécoupage de la population en 2 sous-groupes :\n\nUn groupe dédié à l’apprentissage, autrement dit, le groupe d’entraînement (2/3) ;\nUn groupe dédié à la validation des modèles, autrement dit, le groupe test (1/3) ;\n\nPremière application des modèles sans prise en compte du déséquilibre des classes.\nSeconde à application des modèles en prenant en compte le déséquilibre des classes par le biais d’application de méthode de ré-échantillonnage des classes, à savoir :\n\n\n\n\n\n\n\nSous-échantillonnage\n\n\n\n\n\nRéduit le nombre d’échantillons de la classe majoritaire.\n\n\n\n\n\n\n\n\n\nSur-échantillognnage\n\n\n\n\n\nAugmente le nombre d’échantillons de la classe minoritaire.\n\n\n\n\n\n\n\n\n\nSMOTE\n\n\n\n\n\nGénère des exemples synthétiques de la classe minoritaire.\n\n\n\n\nLes modèles utilisés sont les suivants :\n\n\n\n\n\n\n\nAnalyse linéaire discriminante (LDA)\n\n\n\n\n\nL’analyse discriminante linéaire (LDA) est une technique de classification et de réduction de dimension qui vise à séparer les classes en trouvant une projection linéaire des données qui maximise la séparation entre les classes tout en minimisant la variance au sein des classes.\n\n\n\n\n\n\n\n\n\nAnalyse quadratique discriminante (QDA)\n\n\n\n\n\nL’analyse discriminante quadratique (QDA) est une extension de l’analyse discriminante linéaire (LDA) qui permet de modéliser des frontières de décision non linéaires. Contrairement à LDA, qui suppose que les covariances des classes sont identiques, QDA permet à chaque classe d’avoir sa propre matrice de covariance. Cela permet une modélisation plus flexible, mais nécessite plus de paramètres et peut donc être moins efficace avec de petits ensembles de données.\n\n\n\n\n\n\n\n\n\nArbres de décisions\n\n\n\n\n\nLes arbres de décision sont des modèles de machine learning non paramétriques utilisés pour la classification et la régression. Ils apprennent des règles de décision simples déduites des données pour prédire la valeur de la variable cible.\n\n\n\n\n\n\n\n\n\nBagging, Boosting\n\n\n\n\n\nLes termes “Bagging” et “Boosting” sont des techniques utilisées en apprentissage automatique (machine learning) pour améliorer les performances des modèles prédictifs en utilisant des ensembles de modèles plus simples.\n\n\n\n\n\n\n\n\n\nForêts aléatoires\n\n\n\n\n\nLes forêts aléatoires sont une technique de machine learning utilisée pour la classification et la régression. Elles fonctionnent en combinant plusieurs arbres de décision, chacun construit sur un échantillon différent des données d’entraînement. Le principe de base est le suivant :\n\nConstruction d’arbres : Un grand nombre d’arbres de décision sont construits, chaque arbre étant entraîné sur un échantillon aléatoire des données d’entraînement.\nPrédiction par vote majoritaire : Pour la classification, chaque arbre “vote” pour une classe, et la classe la plus souvent choisie par les arbres est la prédiction finale. Pour la régression, la prédiction finale est la moyenne des prédictions de tous les arbres.\n\nL’utilisation de multiples arbres et l’échantillonnage aléatoire des données permettent de réduire le risque de surapprentissage (overfitting) et d’améliorer la robustesse et la précision des prédictions.\n\n\n\n\n\n4 Principaux résultats\nAprès avoir entraîné les modèles sur l’échantillon d’entraînement, nous avons appliqué les modèles sur les données test afin d’en apprécier leur performance. Plus précisément, nous avons comparé les résultats de nos 2 approches. C’est-à-dire l’approche tenant compte du déséquilibre des classes et celle ne la prenant pas en compte.\nSur la base des différentes métriques d’évaluation que nous avons utilisé, ils s’avère que le modèle le plus performabnt est une Forêt Aléatoire sur laquelle nous avons appliqué la méthode SMOTE.\nIl présente un taux de bonne prédictions de 94,6% contre 5,4% de taux de mauvaises prédictions.\n\n\n5 Conclusions et perspective\nDans la réalité, il est très probable de rencontrer un déséquilibre de classes de la variable à expliquer pour les problèmes de classification supervisée.\nC’est un aspect qui biaise fortement les résultats d’estimations. Par conséquent, il est important de pouvoir le détecter assez tôt et appliquer les méthodes adéquates pour prendre en compte le problème. Au sortir de là, cela nous permet d’obtenir un modèle qui n’est pas biaisé. Ce dernier nous permet donc aisément de prédire l’appartenance à l’une des classes de la variable à expliquer. Dans le cas des défauts de paiement bancaire, l’intérêt de ce genre de méthodes est qu’elle donne la possibilité de mettre en place de moyens de prévention pour se prémunir des personnes qui présentent un fort risque d’être en défaut de paiement.\n\n\n6 Outil technique\n\n\n\n\n\nVous trouverez le rapport ici :\n\n\n\n\n\n\nLire le rapport \n\n\n\n\n\n Retour au sommet"
  },
  {
    "objectID": "posts/sixth/index.html",
    "href": "posts/sixth/index.html",
    "title": "Marketing quantitatif au service de la santé",
    "section": "",
    "text": "Le marketing quantitatif est une approche analytique du marketing qui se concentre sur l’utilisation de données et de statistiques pour prendre des décisions éclairées et mesurer les performances des activités marketing. Les prestataires de services peuvent avoir recours à ce genre de techniques afin de mieux comprendre la demande et ainsi affiner leur propositions.\nEn l’occurrence, nous sommes dans le cas d’une étude qui concerne le programme d’assurance Medicare aux Etats-Unis. C’est un programme d’assurance maladie qui aide les personnes âgées à payer les services de santé. Certaines personnes souscrivent une assurance complémentaire, Medigap 1 qui les aide à payer le reste à charge de Medicare et les autres dépenses médicales qui ne sont pas couvertes par Medicare. Cette assurance est parfois fournie par le dernier employeur de la personne dans le cadre d’une prestation de retraite. D’autres personnes souscrivent une assurance maladie complémentaire auprès de sociétés d’assurances privées."
  },
  {
    "objectID": "posts/first/index.html",
    "href": "posts/first/index.html",
    "title": "Méthodes de prévision",
    "section": "",
    "text": "Les Moindres Carrés Ordinaires (MCO), ou en anglais Ordinary Least Squares (OLS) est une méthode statistique utilisée pour modéliser la relation entre deux variables quantitatives. Il s’agit de la forme la plus élémentaire de la régression linéaire. En régression linéaire simple, une variable indépendante (ou explicative) \\(x\\), est utilisée pour prédire une variable dépendante (ou réponse) \\(y\\). L’objectif de la régression linéaire simple est de trouver les valeurs des coefficients \\(\\beta_0\\) et \\(\\beta_1\\) qui minimisent la somme des carrés des erreurs entre les valeurs observées et les valeurs prédites par le modèle.\nL’économétrie offre un panel de méthodes de prévision statistique qui dépendent de la nature des données ainsi que de la problématique à résoudre.\nAinsi, ces résultats s’inscrivent dans le cadre de travaux de recherche en économétrie réalisées durant ma seconde année de Master."
  },
  {
    "objectID": "posts/second/index.html",
    "href": "posts/second/index.html",
    "title": "L’immobilier à Saratoga ~ Californie",
    "section": "",
    "text": "Dans le cadre d’un projet réalisé dans l’apprentissage de méthodes de Datamining, 1 il a été question d’appliquer des méthodes de classification non supervisée 2 sur une base de données contenant des informations sur 1728 biens immobiliers de la ville de Saratoga, en Californie."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Travaux",
    "section": "",
    "text": "L’immobilier à Saratoga ~ Californie\n\n\n\nMachine Learning\n\n\n\nApplication des méthodes de classification non supervisée\n\n\n\nBOUSSENGUI François ET LEGER Aline\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL’Univers de l’Horlogerie de Seconde Main\n\n\n\nAnalyse de données\n\n\n\nPourquoi certaines montres valent-elles plus cher que d’autres ? Une analyse des facteurs de valorisation.\n\n\n\nBOUSSENGUI François\n\n\n25 déc. 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMarketing quantitatif au service de la santé\n\n\n\nÉconométrie\n\n\n\nL’économétrie au service de la santé\n\n\n\nBOUSSENGUI François\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMesure de l’efficacité technique d’une entreprise\n\n\n\nÉconométrie\n\n\n\nApplication de méthodes économétriques\n\n\n\nBOUSSENGUI François - LEGER Aline - RIGARDIE Loick\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMéthodes de prévision\n\n\n\nÉconométrie\n\n\n\nTravaux de recherche en économétrie\n\n\n\nBOUSSENGUI François - BARRE Nicolas - SABAYE Fried\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrévision des défauts de paiement bancaire\n\n\n\nMachine Learning\n\n\n\nApplication des méthodes de classification supervisée\n\n\n\nBOUSSENGUI François - BARRE Nicolas - LEGER Aline\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStratégie de fixation des prix\n\n\n\nTarification\n\n\n\nCas pratique de tarification\n\n\n\nBOUSSENGUI François - LEGER Aline\n\n\n\n\n\n\n\n\nAucun article correspondant\n\n Retour au sommet"
  },
  {
    "objectID": "posts/skills.html",
    "href": "posts/skills.html",
    "title": "Compétences",
    "section": "",
    "text": "Sur cette page, vous trouverez une présentation de mes compétences.\n\n\nThéoriques\n\n\n\n\n\n\n\nÉconomie\n\n\n\n\n\n\nMicro-économie : Théorie du consommateur & du producteur, équilibre de marché en concurrence pure et parfaite.\nThéorie des jeux : Equilibre de nash (Modélisation mathématiques des interactions stratégiques entre les agents économiques).\nÉconomie industrielle : Equilibre de Nash en situation non concurrentielle (Duopole, Monopole, Oligopole )\n\n\n\n\n\n\n\n\n\n\nStatistiques\n\n\n\n\n\n\nAnalyse de données exploratoire\nÉconométrie : Régression linéaire simple ou multiple, modèles à variable à expliquer dichotomiques, séries-temporelles, etc.\nMicro-économétrie : Modèles à effets fixe ou aléatoires, etc.\nMachine Learning : Regression, classification supervisée & non supervisée\nDeep Learning : Réseaux de neurones\nSéries temporelles\n\n\n\n\n\n\nOutils techniques\n\n\n\n\n\n\n\n PYTHON\n\n\n\n\n\n\nWeb Scraping (récupération automatique de données) avec beautifulsoup et selenium.\nNettoyage et traitement des données avec polars, pandas, numpy.\nVisualisation des données avec plotly et seaborn.\nMachine learning : Scikit learn, PyTorch.\nCréation d’application web : Streamlit, Flask (en apprentissage).\nDéveloppement de code de qualité industrielle : mypy pour le typage statique, ruff pour le linting et le formatage du code, pytest pour les tests.\n\n\n\n\n\n\n\n\n\n\n R\n\n\n\n\n\n\nNettoyage et traitement des données avec tidyverse : {dplyr}, {purrr}, {stringr}, etc.\nVisualisation des données avec {ggplot2} et {plotly}.\nCréation d’application web et tableaux de bord avec {shiny}\nCréation de site web avec Quarto\nMachine Learning avec {tidymodels}.\nAnalyse de données exploratoire et analyse factorielle : ACP – AFC – ACM – AFDM.\nEconométrie et de micro-économétrie : {micEcon}, {sfa}, etc.\n\n\n\n\n\n\n\n\n\n\n SQL\n\n\n\n\n\n\nNotion sur les bases de données relationnelles\nManipulation des données (SELECT, WHERE, ORDER BY, LIMIT, etc.)\nFonction et opérateurs (COUNT, SUM,AVG, etc.)\nJointures\nIndexation et performance (Création d'index pour améliorer les performances de requêtes)\n\n\n\n\n\n\n\n\n\n\nQlikSense\n\n\n\n\n\n\nCréation de tableaux de bord interactifs\nGestion des scripts\n\n\n\n\n\n\n\n\n\n\n Excel\n\n\n\n\n\n\nTraitement de données\nTableaux croisés dynamiques\nRequêtage par le biais de PowerQuery\nAutomatisation de tâches par le biais de VBA\n\n\n\n\n\n\n\n\n\n\n Git\n\n\n\n\n\n\nGestion de projet\nVersionning\n\n\n\n\n\n\nSoft skills & centre d’intérêts\n\n\n\n\n\n\n\nCommunication\n\n\n\n\n\n\nAptitude à partager des resultats techniques à des publics non avisés.\n\n\n\n\n\n\n\n\n\n\nForce de proposition\n\n\n\n\n\n\nAucune hésitation à proposer de nouvelles solutions.\n\n\n\n\n\n\n\n\n\n\nGestion du temps & rigourosité\n\n\n\n\n\n\nImportance de la gestion optimale du temps.\nÊtre rigoureux est primordiale afin d’assurer un niveau de résultat de haute qualité.\n\n\n\n\n\n\n\n\n\n\nCuriosité\n\n\n\n\n\n\nToujours en veille sur les nouvelles pratiques et différentes évolutions du secteur.\n\n\n\n\n\n\n\n\n\n\nPragmatisme et adaptabilité\n\n\n\n\n\n\nFacilité à m’adapter à des environnements hétérogènes.\n\n\n\n\n\n\n\n\n\n\nCentre d’intérêts\n\n\n\n\n\n\nIntelligence Artificielle, Machine Learning\nTechnologie & Innovation\nÉconomie & politique\nHorlogerie\nSports mécaniques (F1, Moto GP, WRC, WEC)\n\n\n\n\n\n\n\n\n Retour au sommet"
  },
  {
    "objectID": "posts/first/index.html#représentation-graphique",
    "href": "posts/first/index.html#représentation-graphique",
    "title": "Méthodes de prévision",
    "section": "Représentation graphique :",
    "text": "Représentation graphique :\n\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LinearRegression?Documentation for LinearRegressioniFittedLinearRegression() \n\n\n\n\n\n\n\n\n\n2. Les modèles qui décrivent une relation non linéaire entre la variable à expliquer et la/les variable(s) explicative(s).\n\nRégression non paramétrique : La régression non paramétrique est une technique statistique qui permet de modéliser les relations entre variables sans supposer de forme paramétrique spécifique pour la relation\n\nPour chacune des méthodes, nous avons mis en évidence :\n\nLa forme fonctionnelle du modèle : La forme fonctionnelle d’un modèle se réfère à la spécification de la relation mathématique entre les variables indépendantes (ou explicatives) et la variable dépendante (ou à expliquer). Cette spécification définit comment les variables sont liées dans le modèle et peut prendre plusieurs formes selon la nature des données et les hypothèses sous-jacentes\nLes principales hypothèses associées au modèle : Les principales hypothèses d’un modèle sont essentielles pour garantir la validité et la fiabilité des estimations des coefficients.\nLeur application dans  et"
  },
  {
    "objectID": "posts/first/index.html#comparaison-des-méthodes",
    "href": "posts/first/index.html#comparaison-des-méthodes",
    "title": "Méthodes de prévision",
    "section": "Comparaison des méthodes",
    "text": "Comparaison des méthodes\nEn conclusion, nous pouvons dire qu’il existe 2 grandes familles de méthodes de prévision : * Les modèles linéaires * Les modèles non linéaires\nGrâce à des représentations graphiques, nous allons visualiser les différences de résultats entre ces deux familles de méthodes.\n\n\nLinearRegression()\n\n\nLinearRegression()\n\n\nRandomForestRegressor()\n\n\n&lt;matplotlib.collections.PathCollection object at 0x11711a8c0&gt;\n\n\n[&lt;matplotlib.lines.Line2D object at 0x117119870&gt;]\n\n\n[&lt;matplotlib.lines.Line2D object at 0x1170d86d0&gt;]\n\n\n[&lt;matplotlib.lines.Line2D object at 0x1170d93c0&gt;]\n\n\n&lt;matplotlib.legend.Legend object at 0x11711b6d0&gt;\n\n\n\n\n\n\n\n\n\nPour chacune des méthodes, nous avons mis en évidence :\n\nLa forme fonctionnelle du modèle : La forme fonctionnelle d’un modèle se réfère à la spécification de la relation mathématique entre les variables indépendantes (ou explicatives) et la variable dépendante (ou à expliquer). Cette spécification définit comment les variables sont liées dans le modèle et peut prendre plusieurs formes selon la nature des données et les hypothèses sous-jacentes\nLes principales hypothèses associées au modèle : Les principales hypothèses d’un modèle sont essentielles pour garantir la validité et la fiabilité des estimations des coefficients.\nLeur application dans  et"
  },
  {
    "objectID": "posts/first/index.html#comparaison-des-méthodes-et-conclusion",
    "href": "posts/first/index.html#comparaison-des-méthodes-et-conclusion",
    "title": "Méthodes de prévision",
    "section": "Comparaison des méthodes et conclusion",
    "text": "Comparaison des méthodes et conclusion\nEn conclusion, nous pouvons dire qu’il existe 2 grandes familles de méthodes de prévision :\n\nLes modèles linéaires : décrivant une relation linéaire entre la variable dépendante et les variables indépendantes.\nLes modèles non linéaires : inversement, décrivant une relation non linéaire entre la variable dépendant et les variables indépendantes.\n\nGrâce à des représentations graphiques, nous allons visualiser les différences de résultats entre ces deux familles de méthodes :\n\n\nLinearRegression()\n\n\nLinearRegression()\n\n\nRandomForestRegressor()\n\n\n&lt;matplotlib.collections.PathCollection object at 0x136f92950&gt;\n\n\n[&lt;matplotlib.lines.Line2D object at 0x136f93850&gt;]\n\n\n[&lt;matplotlib.lines.Line2D object at 0x136fb06a0&gt;]\n\n\n[&lt;matplotlib.lines.Line2D object at 0x136fb1450&gt;]\n\n\n&lt;matplotlib.legend.Legend object at 0x136f928f0&gt;\n\n\n\n\n\n\n\n\n\nPar ailleurs, pour chacune de ces méthodes nous avons mis en évidence les éléments suivants :\n\nLa forme fonctionnelle du modèle : La forme fonctionnelle d’un modèle se réfère à la spécification de la relation mathématique entre les variables indépendantes (ou explicatives) et la variable dépendante (ou à expliquer). Cette spécification définit comment les variables sont liées dans le modèle et peut prendre plusieurs formes selon la nature des données et les hypothèses sous-jacentes\nLes principales hypothèses associées au modèle : Les principales hypothèses d’un modèle sont essentielles pour garantir la validité et la fiabilité des estimations des coefficients.\nLeur application dans des outils techniques appropriés :  et"
  },
  {
    "objectID": "posts/fifth/index.html#footnotes",
    "href": "posts/fifth/index.html#footnotes",
    "title": "Stratégie de fixation des prix",
    "section": "Notes de bas de page",
    "text": "Notes de bas de page\n\n\n\\(\\theta\\) représente la sensibilité du consommateur.↩︎"
  },
  {
    "objectID": "posts/second/index.html#footnotes",
    "href": "posts/second/index.html#footnotes",
    "title": "L’immobilier à Saratoga ~ Californie",
    "section": "Notes de bas de page",
    "text": "Notes de bas de page\n\n\nLa fouille de données (ou “datamining” en anglais) désigne le processus de découverte de motifs, de corrélations ou d’anomalies en analysant de grands ensembles de données à l’aide de diverses techniques computationnelles. Cela implique d’extraire des informations utiles à partir de données brutes pour découvrir des motifs cachés, des relations ou des insights qui peuvent aider à la prise de décision ou à la prédiction.↩︎\nLa classification non supervisée, également connue sous le nom de clustering, est une méthode de fouille de données qui consiste à regrouper des objets ou des données sans utiliser d’étiquettes ou de catégories prédéfinies.↩︎\nL’homogénéité d’une population ou d’une classe, en termes statistiques, se réfère à la similitude ou à la cohérence des individus ou des observations au sein de cette population ou classe. Cela signifie que les membres de cette population ou classe présentent des caractéristiques ou des attributs similaires.↩︎"
  },
  {
    "objectID": "posts/sixth/index.html#footnotes",
    "href": "posts/sixth/index.html#footnotes",
    "title": "Marketing quantitatif au service de la santé",
    "section": "Notes de bas de page",
    "text": "Notes de bas de page\n\n\nMedigap, également connu sous le nom de “Medicare Supplement Insurance,” est une police d’assurance privée qui aide à couvrir certains des coûts de santé non pris en charge par Medicare Original (Parts A et B), tels que les franchises, les copayments et les coinsurances.↩︎"
  },
  {
    "objectID": "posts/first/index.html#fonction-de-coût",
    "href": "posts/first/index.html#fonction-de-coût",
    "title": "Méthodes de prévision",
    "section": "3.1 2. Fonction de Coût",
    "text": "3.1 2. Fonction de Coût\nLa fonction de coût pour la régression à noyau est souvent basée sur la perte de Huber, la perte d’epsilon-insensible ou d’autres fonctions de perte robustes. Une fonction de coût typique pour la régression à noyau est la suivante :\n\\(J(\\alpha) = \\frac{1}{2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\alpha_i \\alpha_j K(x_i, x_j) - \\sum_{i=1}^{N} \\alpha_i y_i\\) \\(+\\) \\(C \\sum_{i=1}^{N} \\max(0, |f(x_i) - y_i| - \\epsilon)\\)\noù : - \\(\\alpha_i\\) sont les coefficients duals. - \\(K(x_i, x_j)\\)est la fonction de noyau. - \\(y_i\\) sont les valeurs cibles. - \\(C\\)est un paramètre de régularisation. - \\(\\epsilon\\) est un paramètre de tolérance pour la perte epsilon-insensible."
  },
  {
    "objectID": "posts/first/index.html#minimisation-de-la-fonction-de-coût",
    "href": "posts/first/index.html#minimisation-de-la-fonction-de-coût",
    "title": "Méthodes de prévision",
    "section": "3.2 3. Minimisation de la Fonction de Coût",
    "text": "3.2 3. Minimisation de la Fonction de Coût\nPour minimiser cette fonction de coût, nous utilisons des techniques d’optimisation convexes telles que le Gradient Descent, le Coordinate Descent ou des algorithmes spécialisés comme le Sequential Minimal Optimization (SMO).\n\n3.2.0.1 Gradient Descent\nL’algorithme de gradient descent ajuste les paramètres \\(\\alpha\\) en suivant le gradient de la fonction de coût :\n\\(\\alpha_i \\leftarrow \\alpha_i - \\eta \\frac{\\partial J(\\alpha)}{\\partial \\alpha_i}\\)\noù \\(\\eta\\) est le taux d’apprentissage.\n\n\n3.2.0.2 Sequential Minimal Optimization (SMO)\nL’algorithme SMO divise le problème d’optimisation en sous-problèmes plus petits qui peuvent être résolus analytiquement. Ce processus est itératif et continue jusqu’à ce que la convergence soit atteinte."
  },
  {
    "objectID": "posts/seventh/index.html",
    "href": "posts/seventh/index.html",
    "title": "L’Univers de l’Horlogerie de Seconde Main",
    "section": "",
    "text": "1 Contexte général de l’analyse du marché de l’horlogerie\nL’industrie horlogère est un secteur dynamique et hautement concurrentiel, où les tendances de prix et les préférences des consommateurs évoluent constamment. Afin de mieux comprendre les variations de prix sur le marché de la seconde main, et les caractéristiques des montres proposées sur le marché, cette analyse se concentre sur l’exploration des données collectées sur le site Chrono24, l’une des principales plateformes de vente de montres de luxe en ligne.\n\n\n2 Objectif de l’analyse\nL’objectif principal de cette analyse est de fournir des insights pertinents sur les tendances actuelles du marché des montres en se basant sur des données provenant de Chrono24. À travers le scraping de données en ligne, nous avons extrait des informations détaillées sur un large éventail de montres proposées à la vente, notamment :\n\nPrix des montres : Données sur les prix pour les différentes marques, modèles, et états des montres.\nCaractéristiques des montres : Informations sur les spécifications telles que les matériaux utilisés (acier, or, etc.), le type de mouvement, la taille, et les autres caractéristiques techniques.\nMarques populaires : Identification des marques les plus recherchées et les plus proposées sur le marché secondaire.\nÉvolution des prix : Analyse des variations de prix des montres selon des critères comme la marque, la matière du boîtier, ou la rareté.\n\n\n\n3 Méthodologie\nLes données ont été collectées par scraping depuis le site web de Chrono24 à l’aide d’outils Python tels que BeautifulSoup et Selenium. Ce processus a permis d’extraire un ensemble de données riche et diversifié sur les montres mises en vente, comprenant des informations sur les prix, les marques, les matériaux, les tailles, et bien plus encore. Ces données ont ensuite été nettoyées et préparées pour l’analyse à l’aide de bibliothèques telles que Pandas et NumPy.\nL’analyse s’est articulée autour de plusieurs axes :\n\nAnalyse descriptive : Statistiques de base (moyenne, médiane, écart-type) sur les prix des montres et leurs caractéristiques.\nVisualisation des données : Utilisation de graphiques pour représenter la distribution des prix par marque, la répartition des prix selon les matériaux, et d’autres caractéristiques pertinentes.\nModélisation prédictive : Développement de modèles permettant de prédire les variations de prix en fonction de certains facteurs comme la marque, le type de mouvement, et l’état de la montre.\n\n\n\n\n\n\n\nPrésentation des variables de la base données\n\n\n\n\n\n\n\n\n\n\n\n\nVariables\nInterprétation\n\n\n\n\nMarque\nMarque de la montre\n\n\nModèle\nModèle de la montre\n\n\nmouvement\nType de mouvement (manuel, autmatique, etc. )\n\n\nMatiere du boîtier\nMatière du boîtier (acier, or, etc. )\n\n\nMatiere du bracelet\nMatière du bracelet (or, acier, caoutchouc)\n\n\nEtat de la montre\nEtat de la montre (Bon, mauvais, etc. )\n\n\nSexe\ncatégorie de la montre : homme/femme\n\n\nprix\nPrix de la montre (en €)\n\n\nRéserve de macrhe\nNiveau de réserve de marche de la montre\n\n\nDiamètre\nDiamètre de la montre\n\n\nEtenchéité\nNiveau d’étenchéité de la montre\n\n\nmatiere de la lunette\nMatière de la lunette de la montre\n\n\nmatiere du verre\nMatière du verre de la montre\n\n\nmatiere de la boucle\nMatière de la boucle de la montre\n\n\nPays\nPays de provenance de la montre\n\n\n\n\n\n\n\n\n4 Résultats attendus\nÀ travers cette analyse, nous cherchons à obtenir une vue d’ensemble des tendances actuelles du marché des montres de luxe. Cela permettra de répondre à plusieurs questions clés :\n\nQuelles sont les marques les plus recherchées et les plus coûteuses ?\nComment les caractéristiques (matériaux, type de mouvement, etc.) influent-elles sur le prix des montres ?\nExiste-t-il des tendances saisonnières ou géographiques influençant les prix ?\n\n\n\n5 Applications de l’analyse\nLes résultats de cette analyse peuvent être utilisés pour :\n\nLes revendeurs : Affiner leur stratégie de tarification en fonction des tendances observées sur le marché.\nLes acheteurs : Obtenir une vue d’ensemble des prix moyens et des bonnes affaires dans le marché de l’horlogerie.\nLes marques et fabricants : Comprendre les attentes des consommateurs et les tendances de demande en matière de modèles spécifiques ou de caractéristiques.\n\nEn résumé, cette analyse vise à fournir une compréhension approfondie des dynamiques du marché de l’horlogerie via les données issues de Chrono24, ce qui pourra servir à la fois pour des études de marché, des prévisions de prix, et la définition de stratégies commerciales adaptées.\n\n\n6 Outil technique\n\nLe projet a entièrement été developpé en Python.\n\n\nCliquer ici pour voir le code source.\n\n\n\n7 Application pour visualiser les statistiques :\n\nLancer l’application\n\n\n\n\n\n Retour au sommet"
  },
  {
    "objectID": "posts/seventh/index.html#répartition-des-prix-par-provenances",
    "href": "posts/seventh/index.html#répartition-des-prix-par-provenances",
    "title": "Analyse du marché horloger de luxe",
    "section": "7.1 Répartition des prix par provenances :",
    "text": "7.1 Répartition des prix par provenances :\n\n\n               Provenance des montres               \n┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┓\n┃        Pays        ┃ Nombre de montres ┃       % ┃\n┡━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━┩\n│       FRANCE       │             10620 │ 33.37 % │\n│     ALLEMAGNE      │              4292 │ 13.48 % │\n│       ITALIE       │              3470 │ 10.90 % │\n│     ÉTATS-UNIS     │              2931 │  9.21 % │\n│      BELGIQUE      │              2096 │  6.59 % │\n│      PAYS-BAS      │              1318 │  4.14 % │\n│      ESPAGNE       │              1083 │  3.40 % │\n│    ROYAUME-UNI     │              1029 │  3.23 % │\n│       JAPON        │               855 │  2.69 % │\n│      POLOGNE       │               518 │  1.63 % │\n│       SUÈDE        │               382 │  1.20 % │\n│     HONG_KONG      │               375 │  1.18 % │\n│      AUTRICHE      │               349 │  1.10 % │\n│       SUISSE       │               288 │  0.90 % │\n│      DANEMARK      │               199 │  0.63 % │\n│ RÉPUBLIQUE_TCHEQUE │               140 │  0.44 % │\n│       GRÈCE        │               127 │  0.40 % │\n│      LITUANIE      │               110 │  0.35 % │\n│     SINGAPOUR      │                96 │  0.30 % │\n│      ROUMANIE      │                93 │  0.29 % │\n│      PORTUGAL      │                93 │  0.29 % │\n│      INCONNU       │                89 │  0.28 % │\n│ EMIRAT_ARABE_UNIS  │                87 │  0.27 % │\n│      UKRAINE       │                78 │  0.25 % │\n│      MALAISIE      │                71 │  0.22 % │\n│       MONACO       │                70 │  0.22 % │\n│      HONGRIE       │                66 │  0.21 % │\n│       CANADA       │                63 │  0.20 % │\n│     AUSTRALIE      │                55 │  0.17 % │\n│     THAÏLANDE      │                48 │  0.15 % │\n│      TURQUIE       │                46 │  0.14 % │\n│        INDE        │                45 │  0.14 % │\n│     INDONÉSIE      │                43 │  0.14 % │\n│       BRÉSIL       │                41 │  0.13 % │\n│       TAÏWAN       │                37 │  0.12 % │\n│   AFRIQUE_DU_SUD   │                34 │  0.11 % │\n│      BULGARIE      │                32 │  0.10 % │\n│      MEXIQUE       │                31 │  0.10 % │\n│      FINLANDE      │                31 │  0.10 % │\n│     LUXEMBOURG     │                28 │  0.09 % │\n│     SLOVAQUIE      │                27 │  0.08 % │\n│       CORÉE        │                20 │  0.06 % │\n│      SLOVÉNIE      │                19 │  0.06 % │\n│  NOUVELLE-ZÉLANDE  │                18 │  0.06 % │\n│       CHINE        │                18 │  0.06 % │\n│    PHILIPPINES     │                18 │  0.06 % │\n│      LETTONIE      │                18 │  0.06 % │\n│       SERBIE       │                17 │  0.05 % │\n│      ESTONIE       │                17 │  0.05 % │\n│      VIETNAM       │                17 │  0.05 % │\n│       ÉGYPTE       │                16 │  0.05 % │\n│      ALBANIE       │                15 │  0.05 % │\n│    SAINT-MARIN     │                13 │  0.04 % │\n│  ARABIE_SAOUDITE   │                12 │  0.04 % │\n│       MAROC        │                 9 │  0.03 % │\n│       CHYPRE       │                 9 │  0.03 % │\n│       LIBAN        │                 9 │  0.03 % │\n│      ANDORRE       │                 8 │  0.03 % │\n│      GÉORGIE       │                 6 │  0.02 % │\n│       QATAR        │                 6 │  0.02 % │\n│      COLOMBIE      │                 5 │  0.02 % │\n│       ISRAËL       │                 5 │  0.02 % │\n│      NORVÈGE       │                 5 │  0.02 % │\n│       MACAO        │                 4 │  0.01 % │\n│       MALTE        │                 4 │  0.01 % │\n│      CROATIE       │                 4 │  0.01 % │\n│       PANAMA       │                 4 │  0.01 % │\n│   LIECHTENSTEIN    │                 4 │  0.01 % │\n│        OMAN        │                 4 │  0.01 % │\n│       BOSNIE       │                 3 │  0.01 % │\n│      IRLANDE       │                 3 │  0.01 % │\n│     GIBRALTAR      │                 3 │  0.01 % │\n│     ARGENTINE      │                 3 │  0.01 % │\n│    BIÉLORUSSIE     │                 3 │  0.01 % │\n│     KAZAKHSTAN     │                 3 │  0.01 % │\n│      ARMÉNIE       │                 2 │  0.01 % │\n│       CHILI        │                 2 │  0.01 % │\n│      ÉQUATEUR      │                 2 │  0.01 % │\n│     SRI_LANKA      │                 2 │  0.01 % │\n│      MOLDAVIE      │                 2 │  0.01 % │\n│      ALGÉRIE       │                 2 │  0.01 % │\n│        ÎLES        │                 2 │  0.01 % │\n│     HONG KONG      │                 1 │  0.00 % │\n│       LIBYE        │                 1 │  0.00 % │\n│     MACÉDOINE      │                 1 │  0.00 % │\n│ SAINT-CHRISTOPHER  │                 1 │  0.00 % │\n│     VENEZUELA      │                 1 │  0.00 % │\n│      ISLANDE       │                 1 │  0.00 % │\n└────────────────────┴───────────────────┴─────────┘\n\n\n\n\n                             Statistiques par pays                             \n┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━┓\n┃        Pays        ┃ Nombre de montres ┃ Prix moyen ┃  Prix min ┃  Prix max ┃\n┡━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━┩\n│ SAINT-CHRISTOPHER  │                 1 │  200000.00 │ 200000.00 │ 200000.00 │\n│       MONACO       │                70 │   46088.42 │   1655.00 │ 302100.00 │\n│      NORVÈGE       │                 5 │   31432.40 │   2615.00 │  74048.00 │\n│ EMIRAT_ARABE_UNIS  │                87 │   30750.04 │   1552.00 │ 453273.00 │\n│      AUTRICHE      │               349 │   29773.07 │    169.00 │ 779500.00 │\n│       LIBYE        │                 1 │   25000.00 │  25000.00 │  25000.00 │\n│   LIECHTENSTEIN    │                 4 │   24944.25 │  17786.00 │  33435.00 │\n│      MALAISIE      │                71 │   21534.98 │   1100.00 │ 202217.00 │\n│       CORÉE        │                20 │   21156.37 │   1734.00 │  60931.00 │\n│ RÉPUBLIQUE_TCHEQUE │               140 │   20033.01 │    399.00 │ 330000.00 │\n│       CHINE        │                18 │   17328.53 │   1281.00 │  82813.00 │\n│     HONG_KONG      │               375 │   16353.63 │    344.00 │ 287911.00 │\n│     ÉTATS-UNIS     │              2931 │   15128.74 │   1012.00 │ 339488.00 │\n│    ROYAUME-UNI     │              1029 │   14853.07 │   1080.00 │ 292603.00 │\n│  ARABIE_SAOUDITE   │                12 │   13907.56 │   2032.00 │  79770.00 │\n│      ARMÉNIE       │                 2 │   12763.00 │   6721.00 │  18805.00 │\n│     GIBRALTAR      │                 3 │   12755.00 │   2820.00 │  24168.00 │\n│       SUISSE       │               288 │   12199.42 │    362.00 │  94539.00 │\n│      DANEMARK      │               199 │   12023.65 │    900.00 │  91415.00 │\n│       MALTE        │                 4 │   11837.50 │   6000.00 │  20600.00 │\n│       SUÈDE        │               382 │   10821.71 │    850.00 │ 116003.00 │\n│     ALLEMAGNE      │              4292 │   10616.46 │    110.00 │ 690000.00 │\n│      ROUMANIE      │                93 │   10546.97 │    295.00 │ 175000.00 │\n│      ESPAGNE       │              1083 │   10443.99 │     90.00 │ 440000.00 │\n│       ITALIE       │              3470 │   10433.91 │    130.00 │ 470000.00 │\n│     SLOVAQUIE      │                27 │   10276.81 │    290.00 │  99900.00 │\n│       JAPON        │               855 │   10239.75 │   1008.00 │ 521782.00 │\n│       FRANCE       │             10620 │   10146.47 │     49.00 │ 689000.00 │\n│      POLOGNE       │               518 │   10124.33 │    290.00 │ 245000.00 │\n│       CANADA       │                63 │    9476.18 │   1158.00 │  43856.00 │\n│      BELGIQUE      │              2096 │    8975.80 │    100.00 │ 299000.00 │\n│       QATAR        │                 6 │    8775.00 │   1323.00 │  19766.00 │\n│      PORTUGAL      │                93 │    8644.44 │    240.00 │  39999.00 │\n│      PAYS-BAS      │              1318 │    8624.19 │    120.00 │ 119995.00 │\n│      ESTONIE       │                17 │    8476.00 │   2250.00 │  32000.00 │\n│      TURQUIE       │                46 │    8466.59 │    635.00 │  22730.00 │\n│     AUSTRALIE      │                55 │    8455.12 │   1052.00 │  48346.00 │\n│       CHYPRE       │                 9 │    7802.78 │    420.00 │  26118.00 │\n│      LITUANIE      │               110 │    7742.33 │    330.00 │  99999.00 │\n│      FINLANDE      │                31 │    7545.00 │     90.00 │  89500.00 │\n│      IRLANDE       │                 3 │    7316.67 │    380.00 │  16975.00 │\n│       GRÈCE        │               127 │    7286.08 │    278.00 │  40000.00 │\n│      CROATIE       │                 4 │    6701.75 │    108.00 │  24000.00 │\n│       TAÏWAN       │                37 │    6599.21 │   1010.00 │  46156.00 │\n│     THAÏLANDE      │                48 │    6379.93 │   1127.00 │  44893.00 │\n│    BIÉLORUSSIE     │                 3 │    6311.33 │   4625.00 │   9669.00 │\n│     LUXEMBOURG     │                28 │    6259.86 │    390.00 │  20000.00 │\n│     SINGAPOUR      │                96 │    6136.43 │   1096.00 │  48913.00 │\n│     INDONÉSIE      │                43 │    5918.77 │    150.00 │  37969.00 │\n│       MACAO        │                 4 │    5732.75 │   2588.00 │  15132.00 │\n│       LIBAN        │                 9 │    5635.00 │    600.00 │  18769.00 │\n│      UKRAINE       │                78 │    5541.94 │     65.00 │  23880.00 │\n│    SAINT-MARIN     │                13 │    5537.92 │   3300.00 │   9839.00 │\n│     VENEZUELA      │                 1 │    5162.00 │   5162.00 │   5162.00 │\n│       BRÉSIL       │                41 │    5141.23 │    600.00 │  18138.00 │\n│      ANDORRE       │                 8 │    5049.75 │    637.00 │   7923.00 │\n│   AFRIQUE_DU_SUD   │                34 │    4920.26 │   1354.00 │  14560.00 │\n│      HONGRIE       │                66 │    4919.46 │    175.00 │  21450.00 │\n│      BULGARIE      │                32 │    4427.29 │    450.00 │  26900.00 │\n│      MEXIQUE       │                31 │    4310.61 │   1620.00 │   9449.00 │\n│      INCONNU       │                89 │    4279.00 │   3748.00 │   4810.00 │\n│        INDE        │                45 │    4121.13 │   1039.00 │  14025.00 │\n│       SERBIE       │                17 │    4073.59 │    150.00 │  18718.00 │\n│       ISRAËL       │                 5 │    4066.50 │   3382.00 │   4751.00 │\n│      LETTONIE      │                18 │    3940.39 │    349.00 │  13400.00 │\n│      SLOVÉNIE      │                19 │    3856.21 │    106.00 │  22900.00 │\n│    PHILIPPINES     │                18 │    3701.67 │   1501.00 │   6913.00 │\n│      COLOMBIE      │                 5 │    3500.40 │   1551.00 │   7271.00 │\n│        ÎLES        │                 2 │    3201.00 │   3190.00 │   3212.00 │\n│       CHILI        │                 2 │    3173.00 │   3173.00 │   3173.00 │\n│  NOUVELLE-ZÉLANDE  │                18 │    2898.70 │   1310.00 │   6005.00 │\n│       ÉGYPTE       │                16 │    2781.33 │   1657.00 │   4451.00 │\n│     KAZAKHSTAN     │                 3 │    2745.50 │   2745.00 │   2746.00 │\n│      VIETNAM       │                17 │    2741.50 │   1369.00 │   3029.00 │\n│      MOLDAVIE      │                 2 │    2547.50 │   2541.00 │   2554.00 │\n│      GÉORGIE       │                 6 │    2528.60 │   1126.00 │   5926.00 │\n│      ÉQUATEUR      │                 2 │    2308.50 │   1231.00 │   3386.00 │\n│       PANAMA       │                 4 │    2098.00 │   2098.00 │   2098.00 │\n│      ALBANIE       │                15 │    1785.46 │    140.00 │  15796.00 │\n│        OMAN        │                 4 │    1629.33 │   1056.00 │   2767.00 │\n│     HONG KONG      │                 1 │    1407.00 │   1407.00 │   1407.00 │\n│     ARGENTINE      │                 3 │    1396.00 │   1396.00 │   1396.00 │\n│     SRI_LANKA      │                 2 │    1366.00 │   1360.00 │   1372.00 │\n│       MAROC        │                 9 │    1013.00 │    105.00 │   2509.00 │\n│      ALGÉRIE       │                 2 │     665.00 │    410.00 │    920.00 │\n│     MACÉDOINE      │                 1 │     340.00 │    340.00 │    340.00 │\n│       BOSNIE       │                 3 │        nan │       nan │       nan │\n│      ISLANDE       │                 1 │        nan │       nan │       nan │\n└────────────────────┴───────────────────┴────────────┴───────────┴───────────┘"
  },
  {
    "objectID": "posts/seventh/index.html#répartition-des-prix-selon-le-type-de-mouvement",
    "href": "posts/seventh/index.html#répartition-des-prix-selon-le-type-de-mouvement",
    "title": "Analyse du marché horloger de luxe",
    "section": "7.2 Répartition des prix selon le type de mouvement :",
    "text": "7.2 Répartition des prix selon le type de mouvement :\n\n\n            Statistiques par Mouvement             \n┏━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┓\n┃  Mouvement  ┃ Prix moyen ┃ Prix min ┃  Prix max ┃\n┡━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━┩\n│ AUTOMATIQUE │   11538.25 │    59.00 │ 779500.00 │\n│   MANUEL    │    7313.69 │    90.00 │ 326800.00 │\n│   QUARTZ    │    2945.07 │    49.00 │  28000.00 │\n│  BATTERIE   │    2630.00 │  1000.00 │   4260.00 │\n│   SOLAIRE   │    1171.75 │   700.00 │   2300.00 │\n└─────────────┴────────────┴──────────┴───────────┘"
  },
  {
    "objectID": "posts/seventh/index.html#répartition-des-prix-selon-le-sexe",
    "href": "posts/seventh/index.html#répartition-des-prix-selon-le-sexe",
    "title": "Analyse du marché horloger de luxe",
    "section": "7.3 Répartition des prix selon le sexe :",
    "text": "7.3 Répartition des prix selon le sexe :\n\n\n            Statistiques par Sexe            \n┏━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┓\n┃ Sexe  ┃ Prix moyen ┃ Prix min ┃  Prix max ┃\n┡━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━┩\n│ HOMME │   11909.98 │    49.00 │ 690000.00 │\n│ FEMME │   10018.34 │    90.00 │ 779500.00 │\n└───────┴────────────┴──────────┴───────────┘"
  },
  {
    "objectID": "posts/seventh/index.html#répartition-des-prix-selon-la-matière-du-boitier",
    "href": "posts/seventh/index.html#répartition-des-prix-selon-la-matière-du-boitier",
    "title": "Analyse du marché horloger de luxe",
    "section": "7.5 Répartition des prix selon la matière du boitier :",
    "text": "7.5 Répartition des prix selon la matière du boitier :\n\n\n           Statistiques par Matiere_boitier            \n┏━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┓\n┃ Matiere_boitier ┃ Prix moyen ┃ Prix min ┃  Prix max ┃\n┡━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━┩\n│     PLATINE     │   75938.82 │  1516.00 │ 690000.00 │\n│     OR_ROSE     │   41777.57 │   290.00 │ 631397.00 │\n│    OR_BLANC     │   28163.81 │   750.00 │ 779500.00 │\n│     CARBONE     │   25398.11 │   250.00 │ 689000.00 │\n│    OR_ROUGE     │   19542.16 │  3799.00 │  47990.00 │\n│    OR_JAUNE     │   15789.21 │   160.00 │ 392000.00 │\n│     TANTALE     │   14655.00 │  7000.00 │  21120.00 │\n│    PALLADIUM    │   11900.00 │ 11900.00 │  11900.00 │\n│    OR_ACIER     │    9303.73 │    90.00 │ 148000.00 │\n│     TITANE      │    9272.68 │   234.00 │ 390000.00 │\n│      ACIER      │    8316.00 │    65.00 │ 440000.00 │\n│    CÉRAMIQUE    │    7463.14 │   209.00 │ 330000.00 │\n│     BRONZE      │    4050.21 │   700.00 │  46072.00 │\n│    ALUMINIUM    │    3318.33 │   290.00 │  14521.00 │\n│     ARGENT      │    2263.75 │   135.00 │  13580.00 │\n│   PLAQUÉE_OR    │    1723.49 │   359.00 │   5500.00 │\n│  VERRE_SAPHIR   │    1237.00 │  1237.00 │   1237.00 │\n│    PLASTIQUE    │     807.16 │    80.00 │   4499.00 │\n└─────────────────┴────────────┴──────────┴───────────┘"
  },
  {
    "objectID": "posts/seventh/index.html#répartition-des-prix-selon-la-matière-du-bracelet",
    "href": "posts/seventh/index.html#répartition-des-prix-selon-la-matière-du-bracelet",
    "title": "Analyse du marché horloger de luxe",
    "section": "7.6 Répartition des prix selon la matière du bracelet :",
    "text": "7.6 Répartition des prix selon la matière du bracelet :\n\n\n           Statistiques par Matiere_bracelet            \n┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┓\n┃ Matiere_bracelet ┃ Prix moyen ┃ Prix min ┃  Prix max ┃\n┡━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━┩\n│     PLATINE      │   83331.30 │  4080.00 │ 690000.00 │\n│     OR_ROSE      │   66541.32 │   630.00 │ 521782.00 │\n│        OR        │   31789.55 │   790.00 │ 779500.00 │\n│     OR_BLANC     │   20807.53 │   250.00 │ 113443.00 │\n│      SATIN       │   20088.26 │   750.00 │  93194.00 │\n│    CAOUTCHOUC    │   19179.74 │    80.00 │ 390000.00 │\n│     OR_JAUNE     │   16053.32 │  1195.00 │ 148000.00 │\n│     OR_ACIER     │    9535.66 │   169.00 │  97198.00 │\n│      ACIER       │    9431.21 │    65.00 │ 440000.00 │\n│    CÉRAMIQUE     │    8576.80 │   490.00 │ 107700.00 │\n│      TITANE      │    7386.65 │   234.00 │ 259000.00 │\n│     OR_ROUGE     │    6966.00 │  4000.00 │   9710.00 │\n│       CUIR       │    6630.74 │    90.00 │ 631397.00 │\n│    PLASTIQUE     │    5868.15 │   120.00 │  41191.00 │\n│  CUIRE_DE_VACHE  │    5791.45 │   200.00 │  76800.00 │\n│      ARGENT      │    5266.61 │   240.00 │  29490.00 │\n│    ALUMINIUM     │    4950.00 │  4950.00 │   4950.00 │\n│     TEXTILE      │    4178.00 │   118.00 │ 689000.00 │\n│  CUIR_AUTRUCHE   │    4091.45 │   275.00 │   7950.00 │\n│     SILICONE     │    3360.60 │   250.00 │  57500.00 │\n│      BRONZE      │    1843.00 │  1300.00 │   2515.00 │\n│      REQUIN      │     395.00 │   395.00 │    395.00 │\n└──────────────────┴────────────┴──────────┴───────────┘"
  },
  {
    "objectID": "posts/seventh/index.html#répartition-des-prix-selon-létat-de-la-montre",
    "href": "posts/seventh/index.html#répartition-des-prix-selon-létat-de-la-montre",
    "title": "Analyse du marché horloger de luxe",
    "section": "7.7 Répartition des prix selon l’état de la montre :",
    "text": "7.7 Répartition des prix selon l’état de la montre :\n\n\n           Statistiques par Matiere_bracelet            \n┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┓\n┃ Matiere_bracelet ┃ Prix moyen ┃ Prix min ┃  Prix max ┃\n┡━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━┩\n│     PLATINE      │   83331.30 │  4080.00 │ 690000.00 │\n│     OR_ROSE      │   66541.32 │   630.00 │ 521782.00 │\n│        OR        │   31789.55 │   790.00 │ 779500.00 │\n│     OR_BLANC     │   20807.53 │   250.00 │ 113443.00 │\n│      SATIN       │   20088.26 │   750.00 │  93194.00 │\n│    CAOUTCHOUC    │   19179.74 │    80.00 │ 390000.00 │\n│     OR_JAUNE     │   16053.32 │  1195.00 │ 148000.00 │\n│     OR_ACIER     │    9535.66 │   169.00 │  97198.00 │\n│      ACIER       │    9431.21 │    65.00 │ 440000.00 │\n│    CÉRAMIQUE     │    8576.80 │   490.00 │ 107700.00 │\n│      TITANE      │    7386.65 │   234.00 │ 259000.00 │\n│     OR_ROUGE     │    6966.00 │  4000.00 │   9710.00 │\n│       CUIR       │    6630.74 │    90.00 │ 631397.00 │\n│    PLASTIQUE     │    5868.15 │   120.00 │  41191.00 │\n│  CUIRE_DE_VACHE  │    5791.45 │   200.00 │  76800.00 │\n│      ARGENT      │    5266.61 │   240.00 │  29490.00 │\n│    ALUMINIUM     │    4950.00 │  4950.00 │   4950.00 │\n│     TEXTILE      │    4178.00 │   118.00 │ 689000.00 │\n│  CUIR_AUTRUCHE   │    4091.45 │   275.00 │   7950.00 │\n│     SILICONE     │    3360.60 │   250.00 │  57500.00 │\n│      BRONZE      │    1843.00 │  1300.00 │   2515.00 │\n│      REQUIN      │     395.00 │   395.00 │    395.00 │\n└──────────────────┴────────────┴──────────┴───────────┘"
  },
  {
    "objectID": "posts/seventh/index.html#répartition-des-prix-selon-la-matière-de-la-lunette",
    "href": "posts/seventh/index.html#répartition-des-prix-selon-la-matière-de-la-lunette",
    "title": "Analyse du marché horloger de luxe",
    "section": "7.8 Répartition des prix selon la matière de la lunette :",
    "text": "7.8 Répartition des prix selon la matière de la lunette :\n\n\n           Statistiques par Matiere_lunette            \n┏━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┓\n┃ Matiere_lunette ┃ Prix moyen ┃ Prix min ┃  Prix max ┃\n┡━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━┩\n│     CARBONE     │   72411.20 │    90.00 │ 689000.00 │\n│     OR_ROSE     │   27236.14 │   590.00 │ 521782.00 │\n│     PLATINE     │   25010.12 │  1300.00 │ 690000.00 │\n│       OR        │   16523.01 │   160.00 │ 549000.00 │\n│    CÉRAMIQUE    │   14323.58 │   209.00 │ 390000.00 │\n│    OR_BLANC     │   12188.44 │   500.00 │ 202217.00 │\n│     TITANE      │   10200.50 │   234.00 │ 245000.00 │\n│      LISSE      │    9034.26 │  5499.00 │  13500.00 │\n│    OR_JAUNE     │    8863.47 │   250.00 │ 148000.00 │\n│      ACIER      │    8117.39 │    65.00 │ 779500.00 │\n│    OR_ROUGE     │    6292.94 │  2750.00 │  29701.00 │\n│    ALUMINIUM    │    4280.71 │   270.00 │  24990.00 │\n│     ARGENT      │    3408.35 │   290.00 │  88750.00 │\n│    OR_ACIER     │    3328.99 │   169.00 │  20670.00 │\n│     BRONZE      │    3305.61 │   800.00 │  46072.00 │\n│    PLASTIQUE    │    1608.46 │    80.00 │  13499.00 │\n│    TUNGSTÈNE    │    1591.50 │   370.00 │   3227.00 │\n│    PALLADIUM    │     550.00 │   550.00 │    550.00 │\n└─────────────────┴────────────┴──────────┴───────────┘"
  },
  {
    "objectID": "posts/seventh/index.html#répartition-des-prix-selon-la-matière-de-la-boucle",
    "href": "posts/seventh/index.html#répartition-des-prix-selon-la-matière-de-la-boucle",
    "title": "Analyse du marché horloger de luxe",
    "section": "7.9 Répartition des prix selon la matière de la boucle :",
    "text": "7.9 Répartition des prix selon la matière de la boucle :\n\n\n           Statistiques par Matiere_boucle            \n┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┓\n┃ Matiere_boucle ┃ Prix moyen ┃ Prix min ┃  Prix max ┃\n┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━┩\n│    CARBONE     │   64556.00 │    90.00 │ 689000.00 │\n│    PLATINE     │   26700.74 │  1516.00 │ 690000.00 │\n│       OR       │   14771.20 │   160.00 │ 779500.00 │\n│   CÉRAMIQUE    │   14668.30 │   209.00 │ 390000.00 │\n│     TITANE     │   10275.92 │   234.00 │ 339488.00 │\n│     ACIER      │    7791.52 │    65.00 │ 440000.00 │\n│    OR_ACIER    │    6557.89 │    90.00 │  68365.00 │\n│   ALUMINIUM    │    4603.69 │   270.00 │  24990.00 │\n│     BRONZE     │    3525.84 │  1190.00 │  46072.00 │\n│     ARGENT     │    2349.47 │   106.00 │  43260.00 │\n│   PLASTIQUE    │    1599.93 │    80.00 │  13499.00 │\n│   TUNGSTÈNE    │    1299.75 │   370.00 │   3227.00 │\n│   PALLADIUM    │     550.00 │   550.00 │    550.00 │\n└────────────────┴────────────┴──────────┴───────────┘"
  },
  {
    "objectID": "posts/seventh/index.html#répartition-des-prix-selon-le-type-de-boucle",
    "href": "posts/seventh/index.html#répartition-des-prix-selon-le-type-de-boucle",
    "title": "Analyse du marché horloger de luxe",
    "section": "7.10 Répartition des prix selon le type de boucle :",
    "text": "7.10 Répartition des prix selon le type de boucle :\n\n\n                Statistiques par Boucle                \n┏━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┓\n┃     Boucle      ┃ Prix moyen ┃ Prix min ┃  Prix max ┃\n┡━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━┩\n│   DOUBLE_PLIS   │   14109.77 │    65.00 │ 690000.00 │\n│      PLIS       │   11871.44 │    80.00 │ 779500.00 │\n│ BOUCLE_ARDILLON │    7419.38 │    70.00 │ 392000.00 │\n│ FERMOIR_BIJOUX  │    7332.17 │   240.00 │  72500.00 │\n│  PAS_DE_BOUCLE  │    2692.00 │   500.00 │   5500.00 │\n│ BOUCLE ARDILLON │    1407.00 │  1407.00 │   1407.00 │\n└─────────────────┴────────────┴──────────┴───────────┘"
  },
  {
    "objectID": "posts/seventh/index.html#répartition-des-prix-selon-le-nombre-de-complications",
    "href": "posts/seventh/index.html#répartition-des-prix-selon-le-nombre-de-complications",
    "title": "Analyse du marché horloger de luxe",
    "section": "7.11 Répartition des prix selon le nombre de complications :",
    "text": "7.11 Répartition des prix selon le nombre de complications :\n\n\n           Statistiques par Comptage_fonctions            \n┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┓\n┃ Comptage_fonctions ┃ Prix moyen ┃ Prix min ┃  Prix max ┃\n┡━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━┩\n│        6.0         │   20433.62 │   299.00 │ 299900.00 │\n│        2.0         │   12028.13 │    80.00 │ 689000.00 │\n│        4.0         │   12026.30 │   140.00 │ 302100.00 │\n│        1.0         │   11536.47 │    70.00 │ 690000.00 │\n│        5.0         │   11188.42 │   320.00 │ 209999.00 │\n│        0.0         │   10190.14 │    49.00 │ 779500.00 │\n│        3.0         │    9629.03 │    80.00 │ 521782.00 │\n│        7.0         │    6624.26 │   250.00 │  52453.00 │\n│        8.0         │    3979.67 │   120.00 │  18450.00 │\n│        12.0        │    1950.00 │  1950.00 │   1950.00 │\n│        9.0         │    1750.00 │  1750.00 │   1750.00 │\n│        19.0        │    1468.00 │  1468.00 │   1468.00 │\n│        10.0        │    1190.00 │  1100.00 │   1280.00 │\n└────────────────────┴────────────┴──────────┴───────────┘"
  },
  {
    "objectID": "posts/seventh/index.html#répartition-des-prix-selon-le-diamètre-de-la-montre",
    "href": "posts/seventh/index.html#répartition-des-prix-selon-le-diamètre-de-la-montre",
    "title": "Analyse du marché horloger de luxe",
    "section": "7.12 Répartition des prix selon le diamètre de la montre :",
    "text": "7.12 Répartition des prix selon le diamètre de la montre :"
  },
  {
    "objectID": "posts/seventh/index.html#répartition-des-prix-selon-le-niveau-détenchéité",
    "href": "posts/seventh/index.html#répartition-des-prix-selon-le-niveau-détenchéité",
    "title": "Analyse du marché horloger de luxe",
    "section": "7.13 Répartition des prix selon le niveau d’étenchéité :",
    "text": "7.13 Répartition des prix selon le niveau d’étenchéité :"
  },
  {
    "objectID": "posts/seventh/index.html#répartition-des-prix-selon-la-marque",
    "href": "posts/seventh/index.html#répartition-des-prix-selon-la-marque",
    "title": "Analyse du marché horloger de luxe",
    "section": "7.4 Répartition des prix selon la marque :",
    "text": "7.4 Répartition des prix selon la marque :\n\n\n                   Statistiques par Marque                   \n┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┓\n┃        Marque         ┃ Prix moyen ┃ Prix min ┃  Prix max ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━┩\n│     RICHARD-MILLE     │  235473.26 │ 99900.00 │ 689000.00 │\n│       FPJOURNE        │  109509.29 │ 51029.00 │ 299900.00 │\n│      DE-BETHUNE       │   69900.00 │ 69900.00 │  69900.00 │\n│    PATEK-PHILIPPE     │   54576.68 │  2999.00 │ 779500.00 │\n│        URWERK         │   46072.00 │ 46072.00 │  46072.00 │\n│    AUDEMARS-PIGUET    │   45427.53 │  2000.00 │ 521782.00 │\n│    A-LANGE-&-SÖHNE    │   40202.17 │ 13300.00 │ 159000.00 │\n│     HARRY-WINSTON     │   39272.50 │ 16946.00 │  61599.00 │\n│  VAN-CLEEF-&-ARPELS   │   29800.00 │  7500.00 │  59900.00 │\n│   MORITZ-GROSSMANN    │   29701.00 │ 29701.00 │  29701.00 │\n│         BOVET         │   26825.00 │ 25400.00 │  28250.00 │\n│  VACHERON-CONSTANTIN  │   23177.34 │  2900.00 │ 107275.00 │\n│        BREGUET        │   22043.16 │  4250.00 │  63990.00 │\n│     HMOSER-&-CIE      │   20142.55 │ 11489.00 │  26500.00 │\n│     ULYSSE-NARDIN     │   18180.34 │  3331.00 │ 631397.00 │\n│  PARMIGIANI-FLEURIER  │   17942.04 │  5696.00 │  69000.00 │\n│     ROGER-DUBUIS      │   17034.73 │  5918.00 │  38500.00 │\n│      JAQUET-DROZ      │   14496.92 │  4145.00 │  34911.00 │\n│         ROLEX         │   12966.58 │   250.00 │ 549000.00 │\n│        HUBLOT         │   12719.31 │  1400.00 │  45500.00 │\n│        PIAGET         │   12358.62 │  1500.00 │  64220.00 │\n│     FRANCK-MULLER     │   11683.68 │  1527.00 │  59500.00 │\n│       BLANCPAIN       │   11144.49 │  1450.00 │  47950.00 │\n│   GIRARD-PERREGAUX    │   11111.31 │  1100.00 │ 111900.00 │\n│        CHOPARD        │   11096.54 │   349.00 │  73900.00 │\n│     DE-GRISOGONO      │   10199.17 │  6500.00 │  19500.00 │\n│         CORUM         │   10132.53 │  1370.00 │  41950.00 │\n│     LOUIS-MOINET      │   10000.00 │ 10000.00 │  10000.00 │\n│         DIOR          │    8400.33 │  1200.00 │  45810.00 │\n│      JACOB-&-CO       │    8155.60 │  3990.00 │  13500.00 │\n│        BULGARI        │    8011.38 │   809.00 │  33900.00 │\n│   JAEGER-LECOULTRE    │    7774.12 │   550.00 │  55450.00 │\n│  GLASHÜTTE-ORIGINAL   │    7693.98 │  2600.00 │  19500.00 │\n│        CARTIER        │    7454.14 │   495.00 │ 375618.00 │\n│     GÉRALD-GENTA      │    7220.00 │  6900.00 │   7900.00 │\n│          IWC          │    6733.35 │   700.00 │  38200.00 │\n│        PANERAI        │    6525.73 │  3446.00 │  21500.00 │\n│        CHANEL         │    6432.64 │  1907.00 │  14625.00 │\n│       PEQUIGNET       │    6415.83 │   700.00 │  10800.00 │\n│      GRAND-SEIKO      │    6320.40 │  1308.00 │  29990.00 │\n│       BOUCHERON       │    6190.00 │  1990.00 │  22000.00 │\n│        ZENITH         │    5578.32 │    90.00 │  23800.00 │\n│        TIFFANY        │    5448.00 │  5448.00 │   5448.00 │\n│      JORG-HYSEK       │    5296.86 │  2098.00 │   6500.00 │\n│        CHAUMET        │    5203.89 │   895.00 │  17080.00 │\n│   UNIVERSAL-GENÈVE    │    5139.97 │  1200.00 │  18500.00 │\n│        GRAHAM         │    4991.00 │  2599.00 │  10000.00 │\n│         OMEGA         │    4955.03 │    90.00 │  99999.00 │\n│      BEDAT-&-CO       │    4780.00 │  3567.00 │   5993.00 │\n│       PERRELET        │    4423.00 │  1800.00 │  14223.00 │\n│       BREITLING       │    4394.35 │   400.00 │  41069.00 │\n│    CARL-F-BUCHERER    │    4338.63 │  1200.00 │   9500.00 │\n│          BRM          │    4099.67 │  3200.00 │   4600.00 │\n│         TUDOR         │    3666.51 │   450.00 │  35000.00 │\n│        VULCAIN        │    3309.95 │  1290.00 │   8500.00 │\n│      BELL-&-ROSS      │    3276.18 │  1250.00 │   8990.00 │\n│    PORSCHE-DESIGN     │    3125.36 │  1250.00 │   4950.00 │\n│       TAG-HEUER       │    3092.63 │   170.00 │  25500.00 │\n│         EBEL          │    2986.40 │   490.00 │   8500.00 │\n│     EBERHARD-&-CO     │    2733.11 │  1149.00 │   3900.00 │\n│      JEANRICHARD      │    2666.00 │   900.00 │   4432.00 │\n│        HERMÈS         │    2534.53 │   650.00 │  11900.00 │\n│      CHRONOSWISS      │    2512.07 │  1100.00 │   5479.00 │\n│        BREMONT        │    2500.00 │  2500.00 │   2500.00 │\n│   CUERVO-Y-SOBRINOS   │    2418.40 │  1300.00 │   4000.00 │\n│        TUTIMA         │    2362.83 │  1499.00 │   4150.00 │\n│         BALL          │    2304.50 │  1201.00 │   4095.00 │\n│  FREDERIQUE-CONSTANT  │    2277.71 │   530.00 │  19800.00 │\n│       MONTBLANC       │    2171.86 │   450.00 │  10430.00 │\n│        ENICAR         │    2169.78 │   108.00 │  11900.00 │\n│    MAURICE-LACROIX    │    2145.88 │   299.00 │  11490.00 │\n│        HANHART        │    2061.25 │   990.00 │   2940.00 │\n│    UNION-GLASHÜTTE    │    2059.23 │  1200.00 │   2995.00 │\n│        CONCORD        │    1999.00 │  1048.00 │   2950.00 │\n│       LONGINES        │    1983.46 │   200.00 │  10950.00 │\n│    BAUME-&-MERCIER    │    1949.63 │   390.00 │  10000.00 │\n│         SINN          │    1864.46 │   820.00 │   3636.00 │\n│    MÜHLE-GLASHÜTTE    │    1834.67 │   850.00 │   4083.00 │\n│         NOMOS         │    1832.80 │   895.00 │   8000.00 │\n│        U-BOAT         │    1769.50 │   675.00 │   2281.00 │\n│         DOXA          │    1752.06 │   720.00 │   5090.00 │\n│     MEISTERSINGER     │    1745.00 │   400.00 │   2990.00 │\n│         ORIS          │    1726.74 │   350.00 │   5096.00 │\n│        MOVADO         │    1680.00 │   360.00 │   3000.00 │\n│      PAUL-PICOT       │    1641.43 │   890.00 │   3000.00 │\n│        FORTIS         │    1633.89 │   850.00 │   4900.00 │\n│      LOUIS-ERARD      │    1631.75 │   637.00 │   4800.00 │\n│         RADO          │    1630.21 │   370.00 │   5575.00 │\n│      MARCELLO-C       │    1611.00 │  1611.00 │   1611.00 │\n│        ZODIAC         │    1417.12 │   370.00 │   2200.00 │\n│         EPOS          │    1390.00 │  1390.00 │   1390.00 │\n│        ETERNA         │    1322.20 │   175.00 │   4800.00 │\n│       JUNGHANS        │    1191.87 │   430.00 │   1890.00 │\n│   ZENO-WATCH-BASEL    │    1181.20 │   350.00 │   3207.00 │\n│     RAYMOND-WEIL      │    1167.62 │   169.00 │   3100.00 │\n│       CHARRIOL        │    1125.00 │  1125.00 │   1125.00 │\n│        ALPINA         │    1029.12 │   220.00 │   2790.00 │\n│         MIDO          │     993.91 │   367.00 │   7900.00 │\n│        CERTINA        │     918.90 │   150.00 │   3200.00 │\n│         CASIO         │     901.78 │    49.00 │  17317.00 │\n│       AEROWATCH       │     900.00 │   900.00 │    900.00 │\n│         APPLE         │     897.50 │   290.00 │   1950.00 │\n│        LOCMAN         │     895.00 │   790.00 │   1000.00 │\n│       HAMILTON        │     855.64 │   270.00 │   2500.00 │\n│         EDOX          │     838.14 │   389.00 │   1500.00 │\n│    MICHEL-HERBELIN    │     832.41 │   220.00 │   2500.00 │\n│  TONINO-LAMBORGHINI   │     823.33 │   690.00 │    890.00 │\n│         SEIKO         │     806.82 │    80.00 │   8499.00 │\n│         GUCCI         │     761.00 │   300.00 │   1574.00 │\n│ VICTORINOX-SWISS-ARMY │     734.46 │   230.00 │   2150.00 │\n│        DAVOSA         │     722.50 │   460.00 │   1175.00 │\n│        ANONIMO        │     700.00 │   700.00 │    700.00 │\n│        TISSOT         │     585.40 │    70.00 │   4200.00 │\n│        GLYCINE        │     572.12 │   260.00 │   1200.00 │\n│      SEVENFRIDAY      │     566.00 │   499.00 │    649.00 │\n│        BULOVA         │     536.00 │   150.00 │   1516.00 │\n│          LIP          │     464.80 │   160.00 │   1150.00 │\n│        SWATCH         │     453.84 │   209.00 │   1650.00 │\n│       STEINHART       │     444.00 │   270.00 │    655.00 │\n│        CITIZEN        │     423.30 │   100.00 │   1199.00 │\n│     REVUE-THOMMEN     │     416.67 │   400.00 │    450.00 │\n│       MONDAINE        │     400.00 │   250.00 │    550.00 │\n│         GRUEN         │     399.67 │   299.00 │    500.00 │\n│        ROAMER         │     360.50 │   106.00 │    615.00 │\n│         LACO          │     357.25 │   260.00 │    550.00 │\n│        ORIENT         │     350.17 │    65.00 │   1250.00 │\n│        WELDER         │     349.00 │   349.00 │    349.00 │\n│        JUNKERS        │     290.00 │   290.00 │    290.00 │\n│         WYLER         │        nan │      nan │       nan │\n└───────────────────────┴────────────┴──────────┴───────────┘"
  },
  {
    "objectID": "content/skills.html",
    "href": "content/skills.html",
    "title": "Compétences",
    "section": "",
    "text": "Sur cette page, vous trouverez une présentation de mes compétences.\n\n\n\nVous trouverez le rapport ici :\n\n\n\n\n\n\nThéoriques\n\n\n\n\n\n\n\nÉconomie\n\n\n\n\n\n\nMicro-économie : Théorie du consommateur & du producteur, équilibre de marché en concurrence pure et parfaite.\nThéorie des jeux : Equilibre de nash (Modélisation mathématiques des interactions stratégiques entre les agents économiques).\nÉconomie industrielle : Equilibre de Nash en situation non concurrentielle (Duopole, Monopole, Oligopole )\n\n\n\n\n\n\n\n\n\n\nStatistiques\n\n\n\n\n\n\nAnalyse de données exploratoire\nÉconométrie : Régression linéaire simple ou multiple, modèles à variable à expliquer dichotomiques, séries-temporelles, etc.\nMicro-économétrie : Modèles à effets fixe ou aléatoires, etc.\nMachine Learning : Regression, classification supervisée & non supervisée\nDeep Learning : Réseaux de neurones\nSéries temporelles\n\n\n\n\n\n\nOutils techniques\n\n\n\n\n\n\n\n PYTHON\n\n\n\n\n\n\nWeb Scraping (récupération automatique de données) avec beautifulsoup et selenium.\nNettoyage et traitement des données avec polars, pandas, numpy.\nVisualisation des données avec plotly et seaborn.\nMachine learning : Scikit learn, PyTorch.\nCréation d’application web : Streamlit, Flask (en apprentissage).\nDéveloppement de code de qualité industrielle : mypy pour le typage statique, ruff pour le linting et le formatage du code, pytest pour les tests.\n\n\n\n\n\n\n\n\n\n\n R\n\n\n\n\n\n\nNettoyage et traitement des données avec tidyverse : {dplyr}, {purrr}, {stringr}, etc.\nVisualisation des données avec {ggplot2} et {plotly}.\nCréation d’application web et tableaux de bord avec {shiny}\nCréation de site web avec Quarto\nMachine Learning avec {tidymodels}.\nAnalyse de données exploratoire et analyse factorielle : ACP – AFC – ACM – AFDM.\nEconométrie et de micro-économétrie : {micEcon}, {sfa}, etc.\n\n\n\n\n\n\n\n\n\n\n SQL\n\n\n\n\n\n\nNotion sur les bases de données relationnelles\nManipulation des données (SELECT, WHERE, ORDER BY, LIMIT, etc.)\nFonction et opérateurs (COUNT, SUM,AVG, etc.)\nJointures\nIndexation et performance (Création d'index pour améliorer les performances de requêtes)\n\n\n\n\n\n\n\n\n\n\nQlikSense\n\n\n\n\n\n\nCréation de tableaux de bord interactifs\nGestion des scripts\n\n\n\n\n\n\n\n\n\n\n Excel\n\n\n\n\n\n\nTraitement de données\nTableaux croisés dynamiques\nRequêtage par le biais de PowerQuery\nAutomatisation de tâches par le biais de VBA\n\n\n\n\n\n\n\n\n\n\n Git\n\n\n\n\n\n\nGestion de projet\nVersionning\n\n\n\n\n\n\nSoft skills & centre d’intérêts\n\n\n\n\n\n\n\nCommunication\n\n\n\n\n\n\nAptitude à partager des resultats techniques à des publics non avisés.\n\n\n\n\n\n\n\n\n\n\nForce de proposition\n\n\n\n\n\n\nAucune hésitation à proposer de nouvelles solutions.\n\n\n\n\n\n\n\n\n\n\nGestion du temps & rigourosité\n\n\n\n\n\n\nImportance de la gestion optimale du temps.\nÊtre rigoureux est primordiale afin d’assurer un niveau de résultat de haute qualité.\n\n\n\n\n\n\n\n\n\n\nCuriosité\n\n\n\n\n\n\nToujours en veille sur les nouvelles pratiques et différentes évolutions du secteur.\n\n\n\n\n\n\n\n\n\n\nPragmatisme et adaptabilité\n\n\n\n\n\n\nFacilité à m’adapter à des environnements hétérogènes.\n\n\n\n\n\n\n\n\n\n\nCentre d’intérêts\n\n\n\n\n\n\nIntelligence Artificielle, Machine Learning\nTechnologie & Innovation\nÉconomie & politique\nHorlogerie\nSports mécaniques (F1, Moto GP, WRC, WEC)\n\n\n\n\n\n\n\n\n Retour au sommet"
  },
  {
    "objectID": "sections/skills.html",
    "href": "sections/skills.html",
    "title": "Compétences",
    "section": "",
    "text": "Vous trouverez ci-dessous une présentation de mes compétences."
  },
  {
    "objectID": "sections/index.html",
    "href": "sections/index.html",
    "title": "Travaux",
    "section": "",
    "text": "L’immobilier à Saratoga ~ Californie\n\n\n\nMachine Learning\n\n\n\nApplication des méthodes de classification non supervisée\n\n\n\nBOUSSENGUI François & LEGER Aline\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL’Univers de l’Horlogerie de Seconde Main\n\n\n\nAnalyse de données\n\n\n\nPourquoi certaines montres valent-elles plus cher que d’autres ? Une analyse des facteurs de valorisation.\n\n\n\nBOUSSENGUI François\n\n\n25 déc. 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMarketing quantitatif au service de la santé\n\n\n\nÉconométrie\n\n\n\nL’économétrie au service de la santé\n\n\n\nBOUSSENGUI François\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMesure de l’efficacité technique d’une entreprise\n\n\n\nÉconométrie\n\n\n\nApplication de méthodes économétriques\n\n\n\nBOUSSENGUI François - LEGER Aline - RIGARDIE Loick\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMéthodes de prévision\n\n\n\nÉconométrie\n\n\n\nTravaux de recherche en économétrie\n\n\n\nBOUSSENGUI François - BARRE Nicolas - SABAYE Fried\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrévision des défauts de paiement bancaire\n\n\n\nMachine Learning\n\n\n\nApplication des méthodes de classification supervisée\n\n\n\nBOUSSENGUI François - BARRE Nicolas - LEGER Aline\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStratégie de fixation des prix\n\n\n\nTarification\n\n\n\nCas pratique de tarification\n\n\n\nBOUSSENGUI François - LEGER Aline\n\n\n\n\n\n\n\n\nAucun article correspondant"
  },
  {
    "objectID": "sections/skills.html#footnotes",
    "href": "sections/skills.html#footnotes",
    "title": "Compétences",
    "section": "Notes de bas de page",
    "text": "Notes de bas de page\n\n\nJ’ai par exemple créé ce site avec Quarto, tout en tirant profit de SASS et de CSS pour en améliorer le rendu.↩︎"
  },
  {
    "objectID": "sections/xp.html",
    "href": "sections/xp.html",
    "title": "Mon parcours",
    "section": "",
    "text": "Aon France\n 02/2023 - Présent\n 35 rue de la fédérarion, 75015, Paris, France\n\nIndustrialisation Python & automatisation : création d’applications python Streamlit destinées aux équipes métiers → Gain de temps conséquent dans la réalisation de tâches répétitives.\nMigration SAP BO → MyReport : pilotage de la migration (recueil des besoins, cartographie des rapports, formation des utilisateurs).\nOutils d’aide au pilotage : développement d’applications python Streamlit internes dédiées aux brokers pour le pilotage de leur activité.\nTableaux de bord suivi de la sinistralité : création de tableaux de bord interactifs Qlik Sense à destination des clients, avec KPI : taux de fréquence, coût moyen, répartition de la charge sinistralité.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Ascentiel Group\n 11/2021 – 02/2023\n 18 Rue des 2 Gares, 92500 Rueil-Malmaison, France\n\nRobot de scraping tarifaire : développement d’un pipeline Python/Selenium pour collecter quotidiennement les tarifs concurrents (assurance chiens/chats), fiabilisation du taux de récupération à 95%.\nAnalyse des résultats techniques des produits : élaboration de rapports sur les performances des couvertures présentés mensuellement au responsable et aux équipes.\n\nSimulations tarifaires & recettage : mise en place d’un environnement de test MySQL, simulation de scénarios de tarification avant déploiement, assurance qualité des mises à jour tarifaires.\n\nDashboards Business : création de tableaux de bord Tableau pour le suivi des souscriptions et résiliations, affaires nouvelles.\n\nÉtudes statistiques & pricing : modélisation des sinistres graves (&gt;= 45.000€) (régression logistique, GLM) et optimisation des tarifs ; recalibration du modèle d’élasticité‑prix, quantification de l’impact de ±5% de variation tarifaire sur le volume de ventes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n April Moto\n 04/2021 – 09/2021\n 14 Quai de Marmoutier, 37100 Tours, France\n\nOptimisation du scraper : refonte du script Python, augmentation du taux de succès de collecte de 70% → 92% en 3 mois.\n\nTableaux de bord Qlik Sense : conception et déploiement de dashboards pour la veille concurrentielle tarifaire.\nModèle prédictif de résiliation : implémentation d’un modèle de machine learning (XGBoost) atteignant 85% de précision, intégré dans le CRM pour priorisation de la relance.\n\nCalcul de la Customer Lifetime Value : élaboration d’une formule CLV tenant compte du taux de churn, valeur moyenne et coût d’acquisition.\nKPI et reporting : amélioration continue des dashboards Qlik Sense pour le suivi des indicateurs clés (acquisition, churn, évolution tarifaire).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n 2019 – 2021\n Faculté de Droit, économie et sciences sociales, 50 Avenue Jean Portalis, 37200 Tours, France\n\nMajeure Data Science : apprentissage approfondi en statistiques, machine learning, séries temporelles et bases de données.\n\nProjet clé : mise en place d’un modèle de machine learning pour prédire le prix de vente de véhicules d’occasion en France.\nMémoire stage de fin d’étude : optimisation du scraper d’un tarifaire en assurance pour deux-roues ; Mise en place d’un modèle prédictif de résiliation.\nOutils & langages : maîtrise de Python (Numpy, Pandas, scikit‑learn), R, SQL, Git, Jupyter, présentation de résultats avec PowerPoint, Beamer et outils BI.\n\n\nMémoire fin d’étude \n\n\nGithub projet fin d’étude \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n 2016 – 2019\n Faculté de Droit, économie et sciences sociales, 50 Avenue Jean Portalis, 37200 Tours, France\n\nFondamentaux économiques: microéconomie, macroéconomie, économétrie et statistiques appliquées.\n\nCompétences analytiques: manipulation de données, rédaction de rapports et communication des résultats en milieu académique et professionnel."
  },
  {
    "objectID": "sections/xp.html#data-engineer-stage",
    "href": "sections/xp.html#data-engineer-stage",
    "title": "Mon parcours",
    "section": "",
    "text": "EDF\n 04/2024 – 10/2024\n Tours, France\nDéveloppement de ViZiR, une application python (streamlit) de Data Visualisation et de post-traitement de résultats de simulation. Multi-formats et utilisée en production par plus d’une centaine d’ingénieurs, ViZiR permet d’analyser à la volée et de manière dynamique les résultats de simulation, tout en permettant une personnalisation sauvegardable poussée \\(\\rightarrow\\) ViZiR facilite les tests de non-régression pour le développement du simulateur EPR2 et contribue à alimenter de nombreuses études au quotidien.\nDéveloppement d’une application  Shiny générant des rapports automatisés sur les impacts fonctionnels et les impacts sûretés liés à la perte d’armoires de contrôle-commande pour l’EPR d’Hinkley Point C \\(\\rightarrow\\) Cet outil a permis d’économiser environ 4400 heures de travail et 330k€, en plus d’améliorer la qualité du livrable final.\nCréation de Data Pipelines utilisant duckdb et polars, pydantic pour la Data Validation.\nOrganisation de présentations et sensibilisation autour des bonnes pratiques de développement sur python et R.\nDécouvrir mon rapport"
  },
  {
    "objectID": "sections/xp.html#data-analyst-bi-dev.-stage",
    "href": "sections/xp.html#data-analyst-bi-dev.-stage",
    "title": "Mon parcours",
    "section": "",
    "text": "Safran Seats\n 04/2023 – 08/2023\n Issoudun, France\nSolution python (créée avec typer) permettant d’analyser la qualité et la cohérence des données entre différentes bases de données (logiciel SIRH, ERP, PLM), destiné à l’usage de l’équipe Data pour des sujets de gouvernance de données.\nMigration de tables, vues et procédures stockées de SQL Server vers Snowflake dans le cadre de la nouvelle infrastructure de Data Warehousing.\nCréation d’un Dashboard PowerBI d’analyse du lead time et de suivi des ordres de fabrication pour la Supply Chain \\(\\rightarrow\\) Ce rapport a notamment permis d’identifier les ordres de fabrication bloqués et a permis d’empêcher leur réapparition.\nElaboration d’un dashboard pour le service HSE permettant de suivre le taux de fréquence des accidents sur site, entre autres KPI \\(\\rightarrow\\) Ce rapport a permis d’éviter une trentaine d’heures par mois de traitement manuel, en plus de faciliter la diffusion des indicateurs.\nDéploiement, suivi et gestion des demandes d’évolution de plus de 4 tableaux de bord sur le PowerBI Report Server de Safran."
  },
  {
    "objectID": "sections/xp.html#data-analyst",
    "href": "sections/xp.html#data-analyst",
    "title": "Mon parcours",
    "section": "",
    "text": "Ascentiel Group\n 11/2021 – 02/2023\n 18 Rue des 2 Gares, 92500 Rueil-Malmaison, France\n\nRobot de scraping tarifaire : développement d’un pipeline Python/Selenium pour collecter quotidiennement les tarifs concurrents (assurance chiens/chats), fiabilisation du taux de récupération à 95%.\nAnalyse des résultats techniques des produits : élaboration de rapports sur les performances des couvertures présentés mensuellement au responsable et aux équipes.\n\nSimulations tarifaires & recettage : mise en place d’un environnement de test MySQL, simulation de scénarios de tarification avant déploiement, assurance qualité des mises à jour tarifaires.\n\nDashboards Business : création de tableaux de bord Tableau pour le suivi des souscriptions et résiliations, affaires nouvelles.\n\nÉtudes statistiques & pricing : modélisation des sinistres graves (&gt;= 45.000€) (régression logistique, GLM) et optimisation des tarifs ; recalibration du modèle d’élasticité‑prix, quantification de l’impact de ±5% de variation tarifaire sur le volume de ventes."
  },
  {
    "objectID": "sections/xp.html#master-data-science-business-econ.-mécen",
    "href": "sections/xp.html#master-data-science-business-econ.-mécen",
    "title": "Mon parcours",
    "section": "",
    "text": "2019 – 2021\n Université de Tours, France"
  },
  {
    "objectID": "sections/xp.html#licence-déconomie",
    "href": "sections/xp.html#licence-déconomie",
    "title": "Mon parcours",
    "section": "",
    "text": "2016 – 2019\n Faculté de Droit, économie et sciences sociales, 50 Avenue Jean Portalis, 37200 Tours, France\n\nFondamentaux économiques: microéconomie, macroéconomie, économétrie et statistiques appliquées.\n\nCompétences analytiques: manipulation de données, rédaction de rapports et communication des résultats en milieu académique et professionnel."
  },
  {
    "objectID": "sections/xp.html#statisticien",
    "href": "sections/xp.html#statisticien",
    "title": "Mon parcours",
    "section": "",
    "text": "Aon France\n 02/2023 - Présent\n 35 rue de la fédérarion, 75015, Paris, France\n\nIndustrialisation Python & automatisation : création d’applications python Streamlit destinées aux équipes métiers → Gain de temps conséquent dans la réalisation de tâches répétitives.\nMigration SAP BO → MyReport : pilotage de la migration (recueil des besoins, cartographie des rapports, formation des utilisateurs).\nOutils d’aide au pilotage : développement d’applications python Streamlit internes dédiées aux brokers pour le pilotage de leur activité.\nTableaux de bord suivi de la sinistralité : création de tableaux de bord interactifs Qlik Sense à destination des clients, avec KPI : taux de fréquence, coût moyen, répartition de la charge sinistralité."
  },
  {
    "objectID": "sections/xp.html#data-analyst-1",
    "href": "sections/xp.html#data-analyst-1",
    "title": "Mon parcours",
    "section": "",
    "text": "April Moto\n 04/2021 – 09/2021\n 14 Quai de Marmoutier, 37100 Tours, France\n\nOptimisation du scraper : refonte du script Python, augmentation du taux de succès de collecte de 70% → 92% en 3 mois.\n\nTableaux de bord Qlik Sense : conception et déploiement de dashboards pour la veille concurrentielle tarifaire.\nModèle prédictif de résiliation : implémentation d’un modèle de machine learning (XGBoost) atteignant 85% de précision, intégré dans le CRM pour priorisation de la relance.\n\nCalcul de la Customer Lifetime Value : élaboration d’une formule CLV tenant compte du taux de churn, valeur moyenne et coût d’acquisition.\nKPI et reporting : amélioration continue des dashboards Qlik Sense pour le suivi des indicateurs clés (acquisition, churn, évolution tarifaire)."
  },
  {
    "objectID": "sections/first/index.html",
    "href": "sections/first/index.html",
    "title": "Méthodes de prévision",
    "section": "",
    "text": "Les Moindres Carrés Ordinaires (MCO), ou en anglais Ordinary Least Squares (OLS) est une méthode statistique utilisée pour modéliser la relation entre deux variables quantitatives. Il s’agit de la forme la plus élémentaire de la régression linéaire. En régression linéaire simple, une variable indépendante (ou explicative) \\(x\\), est utilisée pour prédire une variable dépendante (ou réponse) \\(y\\). L’objectif de la régression linéaire simple est de trouver les valeurs des coefficients \\(\\beta_0\\) et \\(\\beta_1\\) qui minimisent la somme des carrés des erreurs entre les valeurs observées et les valeurs prédites par le modèle.\nL’économétrie offre un panel de méthodes de prévision statistique qui dépendent de la nature des données ainsi que de la problématique à résoudre.\nAinsi, ces résultats s’inscrivent dans le cadre de travaux de recherche en économétrie réalisées durant ma seconde année de Master en économie."
  },
  {
    "objectID": "sections/first/index.html#fonction-de-coût",
    "href": "sections/first/index.html#fonction-de-coût",
    "title": "Méthodes de prévision",
    "section": "3.1 2. Fonction de Coût",
    "text": "3.1 2. Fonction de Coût\nLa fonction de coût pour la régression à noyau est souvent basée sur la perte de Huber, la perte d’epsilon-insensible ou d’autres fonctions de perte robustes. Une fonction de coût typique pour la régression à noyau est la suivante :\n\\(J(\\alpha) = \\frac{1}{2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\alpha_i \\alpha_j K(x_i, x_j) - \\sum_{i=1}^{N} \\alpha_i y_i\\) \\(+\\) \\(C \\sum_{i=1}^{N} \\max(0, |f(x_i) - y_i| - \\epsilon)\\)\noù : - \\(\\alpha_i\\) sont les coefficients duals. - \\(K(x_i, x_j)\\)est la fonction de noyau. - \\(y_i\\) sont les valeurs cibles. - \\(C\\)est un paramètre de régularisation. - \\(\\epsilon\\) est un paramètre de tolérance pour la perte epsilon-insensible."
  },
  {
    "objectID": "sections/first/index.html#minimisation-de-la-fonction-de-coût",
    "href": "sections/first/index.html#minimisation-de-la-fonction-de-coût",
    "title": "Méthodes de prévision",
    "section": "3.2 3. Minimisation de la Fonction de Coût",
    "text": "3.2 3. Minimisation de la Fonction de Coût\nPour minimiser cette fonction de coût, nous utilisons des techniques d’optimisation convexes telles que le Gradient Descent, le Coordinate Descent ou des algorithmes spécialisés comme le Sequential Minimal Optimization (SMO).\n\n3.2.0.1 Gradient Descent\nL’algorithme de gradient descent ajuste les paramètres \\(\\alpha\\) en suivant le gradient de la fonction de coût :\n\\(\\alpha_i \\leftarrow \\alpha_i - \\eta \\frac{\\partial J(\\alpha)}{\\partial \\alpha_i}\\)\noù \\(\\eta\\) est le taux d’apprentissage.\n\n\n3.2.0.2 Sequential Minimal Optimization (SMO)\nL’algorithme SMO divise le problème d’optimisation en sous-problèmes plus petits qui peuvent être résolus analytiquement. Ce processus est itératif et continue jusqu’à ce que la convergence soit atteinte."
  },
  {
    "objectID": "sections/fifth/index.html",
    "href": "sections/fifth/index.html",
    "title": "Stratégie de fixation des prix",
    "section": "",
    "text": "Le pricing en économie fait référence à l’ensemble des processus et des stratégies utilisés par les entreprises pour fixer les prix de leurs produits ou services. Il s’agit d’une composante essentielle du marketing et de la gestion des entreprises, car le prix d’un produit influence directement la demande des consommateurs, la concurrence sur le marché, et la rentabilité de l’entreprise.\n\n\n\nAnalyse des Coûts : Comprendre les coûts fixes et variables associés à la production et à la distribution d’un produit pour s’assurer que le prix couvre ces coûts et permet une marge bénéficiaire.\nÉtude de la Demande : Analyser comment les consommateurs réagissent aux changements de prix, ce qui implique souvent l’étude de l’élasticité-prix de la demande.\n\n\n\n\n\n\n\nElasticité-prix\n\n\n\n\n\nL’élasticité prix-demande mesure la sensibilité de la quantité demandée d’un bien ou service par rapport à une variation de son prix. Elle est définie comme le pourcentage de variation de la quantité demandée divisé par le pourcentage de variation du prix. Voici la formule de l’élasticité prix-demande :\n\\(E_{pd} = \\frac{\\Delta Q / Q}{\\Delta P / P}\\)\noù :\n\n\\(E_{pd}\\) est l’élasticité prix-demande,\n\\(\\Delta Q\\) est la variation de la quantité demandée,\n\\(Q\\) est la quantité demandée initiale,\n\\(\\Delta P\\) est la variation du prix,\n\\(P\\) est le prix initial.\n\nEn termes différentiels, cette formule peut être exprimée comme :\n\\(E_{pd} = \\frac{dQ}{dP} \\times \\frac{P}{Q}\\)\n\n\n\nÉlasticité unitaire \\((E_{pd} = -1)\\) : Une variation de 1% du prix entraîne une variation de 1% de la quantité demandée dans le sens opposé.\nDemande élastique \\((E_{pd} &lt; -1)\\) : La demande est très sensible aux variations de prix. Une variation de 1% du prix entraîne une variation de plus de 1% de la quantité demandée.\nDemande inélastique \\((-1 &lt; E_{pd} &lt; 0)\\) : La demande est peu sensible aux variations de prix. Une variation de 1% du prix entraîne une variation de moins de 1% de la quantité demandée.\nDemande parfaitement élastique \\((E_{pd} = -\\infty)\\) : Toute variation de prix entraînera une variation infinie de la quantité demandée.\nDemande parfaitement inélastique \\((E_{pd} = 0)\\) : La quantité demandée reste constante quelle que soit la variation de prix.\n\n\n\n\nSupposons qu’une augmentation du prix d’un bien de 10% entraîne une diminution de la quantité demandée de 20%.\n\nVariation en pourcentage du prix \\(\\Delta P / P\\) : 10%\nVariation en pourcentage de la quantité demandée \\(\\Delta Q / Q\\) : -20%\n\nL’élasticité prix-demande serait alors :\n\\(E_{pd} = \\frac{-20\\%}{10\\%} = -2\\)\nCela signifie que la demande est élastique : une augmentation de 1% du prix entraîne une diminution de 2% de la quantité demandée.\n\n\n\n\n\nConcurrence : Prendre en compte les prix fixés par les concurrents et la position concurrentielle de l’entreprise sur le marché. Cela peut conduire à des stratégies de prix compétitives telles que le prix d’écrémage ou le prix de pénétration.\nObjectifs de l’Entreprise : Fixer les prix en fonction des objectifs stratégiques de l’entreprise, qui peuvent inclure la maximisation des profits, la part de marché, la survie sur le marché, ou le leadership en termes de qualité.\nValeur Perçue : Considérer la valeur perçue par les consommateurs, qui peut justifier des prix plus élevés si le produit est perçu comme offrant un bénéfice supérieur ou une qualité supérieure.\n\n\n\n\n\nPrix de Pénétration : Fixer un prix bas pour entrer rapidement sur un marché et attirer un large volume de consommateurs.\nPrix d’Écrémage : Fixer un prix initial élevé pour maximiser les profits des segments de marché moins sensibles au prix, avant de baisser progressivement le prix.\nPrix Psychologique : Utiliser des techniques de fixation des prix qui influencent la perception du consommateur, comme fixer un prix à 9,99 € au lieu de 10 €.\nPrix de Groupe : Offrir des prix différents à différents segments de marché en fonction de leur disposition à payer.\nPrix de Prestiges : Fixer un prix élevé pour donner une image de qualité supérieure ou de luxe.\n\nLe pricing est donc une discipline complexe qui requiert une compréhension approfondie de nombreux facteurs économiques et comportementaux pour réussir."
  },
  {
    "objectID": "sections/fifth/index.html#les-principaux-aspects-du-pricing",
    "href": "sections/fifth/index.html#les-principaux-aspects-du-pricing",
    "title": "Stratégie de fixation des prix",
    "section": "",
    "text": "Analyse des Coûts : Comprendre les coûts fixes et variables associés à la production et à la distribution d’un produit pour s’assurer que le prix couvre ces coûts et permet une marge bénéficiaire.\nÉtude de la Demande : Analyser comment les consommateurs réagissent aux changements de prix, ce qui implique souvent l’étude de l’élasticité-prix de la demande.\n\n\n\n\n\n\n\nElasticité-prix\n\n\n\n\n\nL’élasticité prix-demande mesure la sensibilité de la quantité demandée d’un bien ou service par rapport à une variation de son prix. Elle est définie comme le pourcentage de variation de la quantité demandée divisé par le pourcentage de variation du prix. Voici la formule de l’élasticité prix-demande :\n\\(E_{pd} = \\frac{\\Delta Q / Q}{\\Delta P / P}\\)\noù :\n\n\\(E_{pd}\\) est l’élasticité prix-demande,\n\\(\\Delta Q\\) est la variation de la quantité demandée,\n\\(Q\\) est la quantité demandée initiale,\n\\(\\Delta P\\) est la variation du prix,\n\\(P\\) est le prix initial.\n\nEn termes différentiels, cette formule peut être exprimée comme :\n\\(E_{pd} = \\frac{dQ}{dP} \\times \\frac{P}{Q}\\)\n\n\n\nÉlasticité unitaire \\((E_{pd} = -1)\\) : Une variation de 1% du prix entraîne une variation de 1% de la quantité demandée dans le sens opposé.\nDemande élastique \\((E_{pd} &lt; -1)\\) : La demande est très sensible aux variations de prix. Une variation de 1% du prix entraîne une variation de plus de 1% de la quantité demandée.\nDemande inélastique \\((-1 &lt; E_{pd} &lt; 0)\\) : La demande est peu sensible aux variations de prix. Une variation de 1% du prix entraîne une variation de moins de 1% de la quantité demandée.\nDemande parfaitement élastique \\((E_{pd} = -\\infty)\\) : Toute variation de prix entraînera une variation infinie de la quantité demandée.\nDemande parfaitement inélastique \\((E_{pd} = 0)\\) : La quantité demandée reste constante quelle que soit la variation de prix.\n\n\n\n\nSupposons qu’une augmentation du prix d’un bien de 10% entraîne une diminution de la quantité demandée de 20%.\n\nVariation en pourcentage du prix \\(\\Delta P / P\\) : 10%\nVariation en pourcentage de la quantité demandée \\(\\Delta Q / Q\\) : -20%\n\nL’élasticité prix-demande serait alors :\n\\(E_{pd} = \\frac{-20\\%}{10\\%} = -2\\)\nCela signifie que la demande est élastique : une augmentation de 1% du prix entraîne une diminution de 2% de la quantité demandée.\n\n\n\n\n\nConcurrence : Prendre en compte les prix fixés par les concurrents et la position concurrentielle de l’entreprise sur le marché. Cela peut conduire à des stratégies de prix compétitives telles que le prix d’écrémage ou le prix de pénétration.\nObjectifs de l’Entreprise : Fixer les prix en fonction des objectifs stratégiques de l’entreprise, qui peuvent inclure la maximisation des profits, la part de marché, la survie sur le marché, ou le leadership en termes de qualité.\nValeur Perçue : Considérer la valeur perçue par les consommateurs, qui peut justifier des prix plus élevés si le produit est perçu comme offrant un bénéfice supérieur ou une qualité supérieure."
  },
  {
    "objectID": "sections/fifth/index.html#stratégies-de-pricing",
    "href": "sections/fifth/index.html#stratégies-de-pricing",
    "title": "Stratégie de fixation des prix",
    "section": "",
    "text": "Prix de Pénétration : Fixer un prix bas pour entrer rapidement sur un marché et attirer un large volume de consommateurs.\nPrix d’Écrémage : Fixer un prix initial élevé pour maximiser les profits des segments de marché moins sensibles au prix, avant de baisser progressivement le prix.\nPrix Psychologique : Utiliser des techniques de fixation des prix qui influencent la perception du consommateur, comme fixer un prix à 9,99 € au lieu de 10 €.\nPrix de Groupe : Offrir des prix différents à différents segments de marché en fonction de leur disposition à payer.\nPrix de Prestiges : Fixer un prix élevé pour donner une image de qualité supérieure ou de luxe.\n\nLe pricing est donc une discipline complexe qui requiert une compréhension approfondie de nombreux facteurs économiques et comportementaux pour réussir."
  },
  {
    "objectID": "sections/fifth/index.html#footnotes",
    "href": "sections/fifth/index.html#footnotes",
    "title": "Stratégie de fixation des prix",
    "section": "Notes de bas de page",
    "text": "Notes de bas de page\n\n\n\\(\\theta\\) représente la sensibilité du consommateur.↩︎"
  },
  {
    "objectID": "sections/second/index.html",
    "href": "sections/second/index.html",
    "title": "L’immobilier à Saratoga ~ Californie",
    "section": "",
    "text": "Dans le cadre d’un projet réalisé dans l’apprentissage de méthodes de Datamining, 1 il a été question d’appliquer des méthodes de classification non supervisée 2 sur une base de données contenant des informations sur 1728 biens immobiliers de la ville de Saratoga, en Californie."
  },
  {
    "objectID": "sections/second/index.html#footnotes",
    "href": "sections/second/index.html#footnotes",
    "title": "L’immobilier à Saratoga ~ Californie",
    "section": "Notes de bas de page",
    "text": "Notes de bas de page\n\n\nLa fouille de données (ou “datamining” en anglais) désigne le processus de découverte de motifs, de corrélations ou d’anomalies en analysant de grands ensembles de données à l’aide de diverses techniques computationnelles. Cela implique d’extraire des informations utiles à partir de données brutes pour découvrir des motifs cachés, des relations ou des insights qui peuvent aider à la prise de décision ou à la prédiction.↩︎\nLa classification non supervisée, également connue sous le nom de clustering, est une méthode de fouille de données qui consiste à regrouper des objets ou des données sans utiliser d’étiquettes ou de catégories prédéfinies.↩︎\nL’homogénéité d’une population ou d’une classe, en termes statistiques, se réfère à la similitude ou à la cohérence des individus ou des observations au sein de cette population ou classe. Cela signifie que les membres de cette population ou classe présentent des caractéristiques ou des attributs similaires.↩︎"
  },
  {
    "objectID": "sections/sixth/index.html",
    "href": "sections/sixth/index.html",
    "title": "Marketing quantitatif au service de la santé",
    "section": "",
    "text": "Le marketing quantitatif est une approche analytique du marketing qui se concentre sur l’utilisation de données et de statistiques pour prendre des décisions éclairées et mesurer les performances des activités marketing. Les prestataires de services peuvent avoir recours à ce genre de techniques afin de mieux comprendre la demande et ainsi affiner leur propositions.\nEn l’occurrence, nous sommes dans le cas d’une étude qui concerne le programme d’assurance Medicare aux Etats-Unis. C’est un programme d’assurance maladie qui aide les personnes âgées à payer les services de santé. Certaines personnes souscrivent une assurance complémentaire, Medigap 1 qui les aide à payer le reste à charge de Medicare et les autres dépenses médicales qui ne sont pas couvertes par Medicare. Cette assurance est parfois fournie par le dernier employeur de la personne dans le cadre d’une prestation de retraite. D’autres personnes souscrivent une assurance maladie complémentaire auprès de sociétés d’assurances privées."
  },
  {
    "objectID": "sections/sixth/index.html#footnotes",
    "href": "sections/sixth/index.html#footnotes",
    "title": "Marketing quantitatif au service de la santé",
    "section": "Notes de bas de page",
    "text": "Notes de bas de page\n\n\nMedigap, également connu sous le nom de “Medicare Supplement Insurance,” est une police d’assurance privée qui aide à couvrir certains des coûts de santé non pris en charge par Medicare Original (Parts A et B), tels que les franchises, les copayments et les coinsurances.↩︎"
  },
  {
    "objectID": "sections/third/index.html",
    "href": "sections/third/index.html",
    "title": "Prévision des défauts de paiement bancaire",
    "section": "",
    "text": "1 Contexte\nLa détection des défauts de paiements des crédits bancaires est un enjeu majeur pour les banques. Une gestion rigoureuse, permet d’avoir un recouvrement de créance efficace et maintenir des flux de trésorerie solides. De ce fait, il est essentiel de minimmiser ces pertes. La classification supervisée regroupe l’ensemble des méthodes statistiques dont l’objectif principal est de prédire pour un individu donné l’appartenance à une classe connue au préalable. Nous sommes ici dans le cas d’une banque de détails qui souhaite attribuer un score ou probabilité de risque à ses clients.\n\n\n2 Objectifs\nAinsi, dans le cas des défauts de paiement bancaire, l’objectif est de pouvoir modéliser l’appartenance d’un individu à l’une des classes suivantes :\n\nOui [1], l’individu est en défaut de paiement ;\nNon [0], l’individu n’est pas en défaut de paiement ;\n\n\n\n3 Méthodologie\nDe prime abord, nous avons réalisé une analyse descriptive qui a nous permis de mettre en exergue un déséquilibre des classes pour la variable à expliquer. En d’autres termes, nous avons une présence élevée de personne n’étant pas en défaut de paiement contrairement à celles qui le sont.\nCela est un fait positif pour une banque en soi.\nCependant, ce déséquilibre impact négativement la performance et biaise le résultat des modèles.\nCela nous a donc conduit a procédé comme suit :\n\nDécoupage de la population en 2 sous-groupes :\n\nUn groupe dédié à l’apprentissage, autrement dit, le groupe d’entraînement (2/3) ;\nUn groupe dédié à la validation des modèles, autrement dit, le groupe test (1/3) ;\n\nPremière application des modèles sans prise en compte du déséquilibre des classes.\nSeconde à application des modèles en prenant en compte le déséquilibre des classes par le biais d’application de méthode de ré-échantillonnage des classes, à savoir :\n\n\n\n\n\n\n\nSous-échantillonnage\n\n\n\n\n\nRéduit le nombre d’échantillons de la classe majoritaire.\n\n\n\n\n\n\n\n\n\nSur-échantillognnage\n\n\n\n\n\nAugmente le nombre d’échantillons de la classe minoritaire.\n\n\n\n\n\n\n\n\n\nSMOTE\n\n\n\n\n\nGénère des exemples synthétiques de la classe minoritaire.\n\n\n\n\nLes modèles utilisés sont les suivants :\n\n\n\n\n\n\n\nAnalyse linéaire discriminante (LDA)\n\n\n\n\n\nL’analyse discriminante linéaire (LDA) est une technique de classification et de réduction de dimension qui vise à séparer les classes en trouvant une projection linéaire des données qui maximise la séparation entre les classes tout en minimisant la variance au sein des classes.\n\n\n\n\n\n\n\n\n\nAnalyse quadratique discriminante (QDA)\n\n\n\n\n\nL’analyse discriminante quadratique (QDA) est une extension de l’analyse discriminante linéaire (LDA) qui permet de modéliser des frontières de décision non linéaires. Contrairement à LDA, qui suppose que les covariances des classes sont identiques, QDA permet à chaque classe d’avoir sa propre matrice de covariance. Cela permet une modélisation plus flexible, mais nécessite plus de paramètres et peut donc être moins efficace avec de petits ensembles de données.\n\n\n\n\n\n\n\n\n\nArbres de décisions\n\n\n\n\n\nLes arbres de décision sont des modèles de machine learning non paramétriques utilisés pour la classification et la régression. Ils apprennent des règles de décision simples déduites des données pour prédire la valeur de la variable cible.\n\n\n\n\n\n\n\n\n\nBagging, Boosting\n\n\n\n\n\nLes termes “Bagging” et “Boosting” sont des techniques utilisées en apprentissage automatique (machine learning) pour améliorer les performances des modèles prédictifs en utilisant des ensembles de modèles plus simples.\n\n\n\n\n\n\n\n\n\nForêts aléatoires\n\n\n\n\n\nLes forêts aléatoires sont une technique de machine learning utilisée pour la classification et la régression. Elles fonctionnent en combinant plusieurs arbres de décision, chacun construit sur un échantillon différent des données d’entraînement. Le principe de base est le suivant :\n\nConstruction d’arbres : Un grand nombre d’arbres de décision sont construits, chaque arbre étant entraîné sur un échantillon aléatoire des données d’entraînement.\nPrédiction par vote majoritaire : Pour la classification, chaque arbre “vote” pour une classe, et la classe la plus souvent choisie par les arbres est la prédiction finale. Pour la régression, la prédiction finale est la moyenne des prédictions de tous les arbres.\n\nL’utilisation de multiples arbres et l’échantillonnage aléatoire des données permettent de réduire le risque de surapprentissage (overfitting) et d’améliorer la robustesse et la précision des prédictions.\n\n\n\n\n\n4 Principaux\nAprès avoir entraîné les modèles sur l’échantillon d’entraînement, nous avons appliqué les modèles sur les données test afin d’en apprécier leur performance. Plus précisément, nous avons comparé les résultats de nos 2 approches. C’est-à-dire l’approche tenant compte du déséquilibre des classes et celle ne la prenant pas en compte.\nSur la base des différentes métriques d’évaluation que nous avons utilisé, ils s’avère que le modèle le plus performabnt est une Forêt Aléatoire sur laquelle nous avons appliqué la méthode SMOTE.\nLe modèle retenu présente un taux de bonne prédictions de 94,6% contre 5,4% de taux de mauvaises prédictions.\n\n\n5 Conclusions et perspective\nDans la réalité, il est très probable de rencontrer un déséquilibre de classes de la variable à expliquer pour les problèmes de classification supervisée. Surtout dans le milieu bancaire.\nC’est un aspect qui biaise fortement les résultats d’estimations. Par conséquent, il est important de pouvoir le détecter assez tôt et appliquer les méthodes adéquates pour prendre en compte le problème. Au sortir de là, cela nous permet d’obtenir un modèle qui n’est pas biaisé. Ce dernier nous permet donc aisément de prédire, pour un individu donné, sa probabilité d’appartenance à l’une des classes de la variable à expliquer. Dans le cas des défauts de paiement bancaire, l’intérêt de ce genre de méthodes est qu’elle donne la possibilité de mettre en place de moyens de prévention pour se prémunir des personnes qui présentent un fort risque d’être en défaut de paiement.\n\n\n6 Outil technique\n\nLogiciel \n\n\n\nVous trouverez le rapport ici :\n\n\n\n\n\n\nLire le rapport \n\n\n\n\n\n Retour au sommet"
  },
  {
    "objectID": "sections/fourth/index.html",
    "href": "sections/fourth/index.html",
    "title": "Mesure de l’efficacité technique d’une entreprise",
    "section": "",
    "text": "1 Contexte\nL’analyse des frontières stochastiques (SFA) est une méthode de modélisation économique. Elle trouve son point de départ dans les modèles stochastiques de production frontière introduits simultanément par Aigner, Lovell et Schmidt (1977) et Meeusen et Van den Broeck (1977).\nLe modèle de frontière de production sans composante aléatoire peut s’écrire :\n\\(y_i = f(x_i, \\beta)\\times TE_i\\)\noù \\(y_i\\) est la production scalaire observée du producteur \\(i\\) ; \\(i=1,..I,\\) \\(x_i\\) est un vecteur de \\(N\\) entrées utilisé par le \\(producteur_i\\) ;\n\n\\(\\beta\\) est un vecteur de paramètres technologiques à estimer ;\n\\(f(x_i , \\beta)\\) est la fonction frontière de production ;\n\n\\(TE_i\\) désigne l’efficacité technique définie comme le rapport entre la production observée et la production maximale réalisable. \\(TE = (\\frac{y}{y*})\\). \\(TE_i = 1\\) montre que la ième entreprise obtient la production maximale réalisable, tandis que \\(TE_i\\) &lt; 1 fournit une mesure de l’écart entre la production observée et la production maximale réalisable. En d’autres termes, \\(TE_i\\) détermine l’utilisation non efficiente des inputs.\nUne composante stochastique décrivant les chocs aléatoires affectant le processus de production est ajoutée. Ces chocs ne sont pas directement imputables au producteur ou à la technologie sous-jacente. Ces chocs peuvent provenir de changements climatiques, de difficultés économiques ou simplement de chance. Nous notons ces effets par \\(exp(v_i)\\). Chaque producteur est confronté à un choc différent, mais nous supposons que les chocs sont aléatoires et qu’ils sont décrits par une distribution commune.\nLa frontière de production stochastique deviendra :\n\\(y_i = f(x_i, \\beta) \\times TE_i \\times (v_i)\\)\nNous supposons que \\(TE_i\\) est également une variable stochastique, avec une fonction de distribution spécifique, commune à tous les producteurs.\nL’analyse des frontières stochastiques a également examiné l’efficacité du « coût » et du « profit » (voir Kumbhakar & Lovell 2003). L’approche de la « frontière des coûts » tente de mesurer dans quelle mesure l’entreprise se trouve loin de la minimisation totale des coûts (c’est-à-dire du rapport coût-efficacité). Du point de vue de la modélisation, la composante non négative d’inefficacité des coûts est ajoutée plutôt que soustraite dans la spécification stochastique. « L’analyse de la frontière du profit » examine le cas où les producteurs sont traités comme ceux qui maximisent le profit (la production et les intrants doivent être décidés par l’entreprise) et non comme ceux qui minimisent les coûts (où le niveau de production est considéré comme étant donné de manière exogène). La spécification ici est similaire à celle de la « frontière de production ».\n\n\n2 Objectifs\nL’objectif de ce travail est d’appliquer les techniques d’analyse des frontières de production sur des données de transport aérien américain. Pour ce faire, nous disposions d’une base de données de 232 observations de sociétés issues du transport aérien américain. Les variables présentes dans le jeu de données sont les suivantes :\n\n\n\nVariables\n\n\n\n\nCoût total\n\n\nQuantité produite\n\n\nLe prix du travail\n\n\nLe prix du capital\n\n\nLe prix du carburant\n\n\nLe part du coût du travail dans le coût total\n\n\nLe part du coût du capital dans le coût total\n\n\nLe part du coût du carburant dans le coût total\n\n\n\n\n\n3 Méthodologie\nPour atteindre notre objectif, nous avons tout d’abord procédé à une analyse descriptive de notre jeu de données qui nous a permis d’observer les tendances générales qui s’y dégagent. En d’autres termes, nous avons réalisé une étude sur :\n\nAnalyse des coûts\nQuantités produites\nLa productivité des entreprises\n\nEnsuite, nous avons réalisé une modélisation de la frontière stochastique respectivement du point de vue des coûts mais aussi de la production. Dans les deux cas, nous avons réalisé diverses modélisations afin d’apprécier les résultats des différentes formes fonctionnelles que peuvent prendre ces modèles et confronter les résultats obtenus dans le but d’otenir le meilleur.\n\n\n4 Outil technique\n\nLogiciel \n\n\n\nVous trouverez le rapport ici :\n\n\n\n\n\n\n\n\n\n\n\n Retour au sommet"
  },
  {
    "objectID": "sections/seventh/index.html",
    "href": "sections/seventh/index.html",
    "title": "L’Univers de l’Horlogerie de Seconde Main",
    "section": "",
    "text": "1 Contexte général de l’analyse du marché de l’horlogerie\nL’industrie horlogère est un secteur dynamique et hautement concurrentiel, où les tendances de prix et les préférences des consommateurs évoluent constamment. Afin de mieux comprendre les variations de prix sur le marché de la seconde main, et les caractéristiques des montres proposées sur le marché, cette analyse se concentre sur l’exploration des données collectées sur le site Chrono24, l’une des principales plateformes de vente de montres de luxe en ligne.\n\n\n2 Objectif de l’analyse\nL’objectif principal de cette analyse est de fournir des insights pertinents sur les tendances actuelles du marché des montres en se basant sur des données provenant de Chrono24. À travers le scraping de données en ligne, nous avons extrait des informations détaillées sur un large éventail de montres proposées à la vente, notamment :\n\nPrix des montres : Données sur les prix pour les différentes marques, modèles, et états des montres.\nCaractéristiques des montres : Informations sur les spécifications telles que les matériaux utilisés (acier, or, etc.), le type de mouvement, la taille, et les autres caractéristiques techniques.\nMarques populaires : Identification des marques les plus recherchées et les plus proposées sur le marché secondaire.\nÉvolution des prix : Analyse des variations de prix des montres selon des critères comme la marque, la matière du boîtier, ou la rareté.\n\n\n\n3 Méthodologie\nLes données ont été collectées par scraping depuis le site web de Chrono24 à l’aide d’outils Python tels que BeautifulSoup et Selenium. Ce processus a permis d’extraire un ensemble de données riche et diversifié sur les montres mises en vente, comprenant des informations sur les prix, les marques, les matériaux, les tailles, et bien plus encore. Ces données ont ensuite été nettoyées et préparées pour l’analyse à l’aide de bibliothèques telles que Pandas et NumPy.\nL’analyse s’est articulée autour de plusieurs axes :\n\nAnalyse descriptive : Statistiques de base (moyenne, médiane, écart-type) sur les prix des montres et leurs caractéristiques.\nVisualisation des données : Utilisation de graphiques pour représenter la distribution des prix par marque, la répartition des prix selon les matériaux, et d’autres caractéristiques pertinentes.\nModélisation prédictive : Développement de modèles permettant de prédire les variations de prix en fonction de certains facteurs comme la marque, le type de mouvement, et l’état de la montre.\n\n\n\n\n\n\n\nPrésentation des variables de la base données\n\n\n\n\n\n\n\n\n\n\n\n\nVariables\nInterprétation\n\n\n\n\nMarque\nMarque de la montre\n\n\nModèle\nModèle de la montre\n\n\nmouvement\nType de mouvement (manuel, autmatique, etc. )\n\n\nMatiere du boîtier\nMatière du boîtier (acier, or, etc. )\n\n\nMatiere du bracelet\nMatière du bracelet (or, acier, caoutchouc)\n\n\nEtat de la montre\nEtat de la montre (Bon, mauvais, etc. )\n\n\nSexe\ncatégorie de la montre : homme/femme\n\n\nprix\nPrix de la montre (en €)\n\n\nRéserve de macrhe\nNiveau de réserve de marche de la montre\n\n\nDiamètre\nDiamètre de la montre\n\n\nEtenchéité\nNiveau d’étenchéité de la montre\n\n\nmatiere de la lunette\nMatière de la lunette de la montre\n\n\nmatiere du verre\nMatière du verre de la montre\n\n\nmatiere de la boucle\nMatière de la boucle de la montre\n\n\nPays\nPays de provenance de la montre\n\n\n\n\n\n\n\n\n4 Résultats attendus\nÀ travers cette analyse, nous cherchons à obtenir une vue d’ensemble des tendances actuelles du marché des montres de luxe. Cela permettra de répondre à plusieurs questions clés :\n\nQuelles sont les marques les plus recherchées et les plus coûteuses ?\nComment les caractéristiques (matériaux, type de mouvement, etc.) influent-elles sur le prix des montres ?\nExiste-t-il des tendances saisonnières ou géographiques influençant les prix ?\n\n\n\n5 Applications de l’analyse\nLes résultats de cette analyse peuvent être utilisés pour :\n\nLes revendeurs : Affiner leur stratégie de tarification en fonction des tendances observées sur le marché.\nLes acheteurs : Obtenir une vue d’ensemble des prix moyens et des bonnes affaires dans le marché de l’horlogerie.\nLes marques et fabricants : Comprendre les attentes des consommateurs et les tendances de demande en matière de modèles spécifiques ou de caractéristiques.\n\nEn résumé, cette analyse vise à fournir une compréhension approfondie des dynamiques du marché de l’horlogerie via les données issues de Chrono24, ce qui pourra servir à la fois pour des études de marché, des prévisions de prix, et la définition de stratégies commerciales adaptées.\n\n\n6 Outil technique\n\nLe projet a entièrement été developpé en Python.\n\n\nCliquer ici pour voir le code source.\n\n\n\n7 Application pour visualiser les statistiques :\n\nLancer l’application\n\n\n\n\n\n Retour au sommet"
  },
  {
    "objectID": "sections/projet1/index.html",
    "href": "sections/projet1/index.html",
    "title": "Méthodes de prévision",
    "section": "",
    "text": "Les Moindres Carrés Ordinaires (MCO), ou en anglais Ordinary Least Squares (OLS) est une méthode statistique utilisée pour modéliser la relation entre deux variables quantitatives. Il s’agit de la forme la plus élémentaire de la régression linéaire. En régression linéaire simple, une variable indépendante (ou explicative) \\(x\\), est utilisée pour prédire une variable dépendante (ou réponse) \\(y\\). L’objectif de la régression linéaire simple est de trouver les valeurs des coefficients \\(\\beta_0\\) et \\(\\beta_1\\) qui minimisent la somme des carrés des erreurs entre les valeurs observées et les valeurs prédites par le modèle.\nL’économétrie offre un panel de méthodes de prévision statistique qui dépendent de la nature des données ainsi que de la problématique à résoudre.\nAinsi, ces résultats s’inscrivent dans le cadre de travaux de recherche en économétrie réalisées durant ma seconde année de Master en économie."
  },
  {
    "objectID": "sections/projet1/index.html#fonction-de-coût",
    "href": "sections/projet1/index.html#fonction-de-coût",
    "title": "Méthodes de prévision",
    "section": "3.1 2. Fonction de Coût",
    "text": "3.1 2. Fonction de Coût\nLa fonction de coût pour la régression à noyau est souvent basée sur la perte de Huber, la perte d’epsilon-insensible ou d’autres fonctions de perte robustes. Une fonction de coût typique pour la régression à noyau est la suivante :\n\\(J(\\alpha) = \\frac{1}{2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\alpha_i \\alpha_j K(x_i, x_j) - \\sum_{i=1}^{N} \\alpha_i y_i\\) \\(+\\) \\(C \\sum_{i=1}^{N} \\max(0, |f(x_i) - y_i| - \\epsilon)\\)\noù : - \\(\\alpha_i\\) sont les coefficients duals. - \\(K(x_i, x_j)\\)est la fonction de noyau. - \\(y_i\\) sont les valeurs cibles. - \\(C\\)est un paramètre de régularisation. - \\(\\epsilon\\) est un paramètre de tolérance pour la perte epsilon-insensible."
  },
  {
    "objectID": "sections/projet1/index.html#minimisation-de-la-fonction-de-coût",
    "href": "sections/projet1/index.html#minimisation-de-la-fonction-de-coût",
    "title": "Méthodes de prévision",
    "section": "3.2 3. Minimisation de la Fonction de Coût",
    "text": "3.2 3. Minimisation de la Fonction de Coût\nPour minimiser cette fonction de coût, nous utilisons des techniques d’optimisation convexes telles que le Gradient Descent, le Coordinate Descent ou des algorithmes spécialisés comme le Sequential Minimal Optimization (SMO).\n\n3.2.0.1 Gradient Descent\nL’algorithme de gradient descent ajuste les paramètres \\(\\alpha\\) en suivant le gradient de la fonction de coût :\n\\(\\alpha_i \\leftarrow \\alpha_i - \\eta \\frac{\\partial J(\\alpha)}{\\partial \\alpha_i}\\)\noù \\(\\eta\\) est le taux d’apprentissage.\n\n\n3.2.0.2 Sequential Minimal Optimization (SMO)\nL’algorithme SMO divise le problème d’optimisation en sous-problèmes plus petits qui peuvent être résolus analytiquement. Ce processus est itératif et continue jusqu’à ce que la convergence soit atteinte."
  },
  {
    "objectID": "sections/projet5/index.html",
    "href": "sections/projet5/index.html",
    "title": "Stratégie de fixation des prix",
    "section": "",
    "text": "Le pricing en économie fait référence à l’ensemble des processus et des stratégies utilisés par les entreprises pour fixer les prix de leurs produits ou services. Il s’agit d’une composante essentielle du marketing et de la gestion des entreprises, car le prix d’un produit influence directement la demande des consommateurs, la concurrence sur le marché, et la rentabilité de l’entreprise.\n\n\n\nAnalyse des Coûts : Comprendre les coûts fixes et variables associés à la production et à la distribution d’un produit pour s’assurer que le prix couvre ces coûts et permet une marge bénéficiaire.\nÉtude de la Demande : Analyser comment les consommateurs réagissent aux changements de prix, ce qui implique souvent l’étude de l’élasticité-prix de la demande.\n\n\n\n\n\n\n\nElasticité-prix\n\n\n\n\n\nL’élasticité prix-demande mesure la sensibilité de la quantité demandée d’un bien ou service par rapport à une variation de son prix. Elle est définie comme le pourcentage de variation de la quantité demandée divisé par le pourcentage de variation du prix. Voici la formule de l’élasticité prix-demande :\n\\(E_{pd} = \\frac{\\Delta Q / Q}{\\Delta P / P}\\)\noù :\n\n\\(E_{pd}\\) est l’élasticité prix-demande,\n\\(\\Delta Q\\) est la variation de la quantité demandée,\n\\(Q\\) est la quantité demandée initiale,\n\\(\\Delta P\\) est la variation du prix,\n\\(P\\) est le prix initial.\n\nEn termes différentiels, cette formule peut être exprimée comme :\n\\(E_{pd} = \\frac{dQ}{dP} \\times \\frac{P}{Q}\\)\n\n\n\nÉlasticité unitaire \\((E_{pd} = -1)\\) : Une variation de 1% du prix entraîne une variation de 1% de la quantité demandée dans le sens opposé.\nDemande élastique \\((E_{pd} &lt; -1)\\) : La demande est très sensible aux variations de prix. Une variation de 1% du prix entraîne une variation de plus de 1% de la quantité demandée.\nDemande inélastique \\((-1 &lt; E_{pd} &lt; 0)\\) : La demande est peu sensible aux variations de prix. Une variation de 1% du prix entraîne une variation de moins de 1% de la quantité demandée.\nDemande parfaitement élastique \\((E_{pd} = -\\infty)\\) : Toute variation de prix entraînera une variation infinie de la quantité demandée.\nDemande parfaitement inélastique \\((E_{pd} = 0)\\) : La quantité demandée reste constante quelle que soit la variation de prix.\n\n\n\n\nSupposons qu’une augmentation du prix d’un bien de 10% entraîne une diminution de la quantité demandée de 20%.\n\nVariation en pourcentage du prix \\(\\Delta P / P\\) : 10%\nVariation en pourcentage de la quantité demandée \\(\\Delta Q / Q\\) : -20%\n\nL’élasticité prix-demande serait alors :\n\\(E_{pd} = \\frac{-20\\%}{10\\%} = -2\\)\nCela signifie que la demande est élastique : une augmentation de 1% du prix entraîne une diminution de 2% de la quantité demandée.\n\n\n\n\n\nConcurrence : Prendre en compte les prix fixés par les concurrents et la position concurrentielle de l’entreprise sur le marché. Cela peut conduire à des stratégies de prix compétitives telles que le prix d’écrémage ou le prix de pénétration.\nObjectifs de l’Entreprise : Fixer les prix en fonction des objectifs stratégiques de l’entreprise, qui peuvent inclure la maximisation des profits, la part de marché, la survie sur le marché, ou le leadership en termes de qualité.\nValeur Perçue : Considérer la valeur perçue par les consommateurs, qui peut justifier des prix plus élevés si le produit est perçu comme offrant un bénéfice supérieur ou une qualité supérieure.\n\n\n\n\n\nPrix de Pénétration : Fixer un prix bas pour entrer rapidement sur un marché et attirer un large volume de consommateurs.\nPrix d’Écrémage : Fixer un prix initial élevé pour maximiser les profits des segments de marché moins sensibles au prix, avant de baisser progressivement le prix.\nPrix Psychologique : Utiliser des techniques de fixation des prix qui influencent la perception du consommateur, comme fixer un prix à 9,99 € au lieu de 10 €.\nPrix de Groupe : Offrir des prix différents à différents segments de marché en fonction de leur disposition à payer.\nPrix de Prestiges : Fixer un prix élevé pour donner une image de qualité supérieure ou de luxe.\n\nLe pricing est donc une discipline complexe qui requiert une compréhension approfondie de nombreux facteurs économiques et comportementaux pour réussir."
  },
  {
    "objectID": "sections/projet5/index.html#les-principaux-aspects-du-pricing",
    "href": "sections/projet5/index.html#les-principaux-aspects-du-pricing",
    "title": "Stratégie de fixation des prix",
    "section": "",
    "text": "Analyse des Coûts : Comprendre les coûts fixes et variables associés à la production et à la distribution d’un produit pour s’assurer que le prix couvre ces coûts et permet une marge bénéficiaire.\nÉtude de la Demande : Analyser comment les consommateurs réagissent aux changements de prix, ce qui implique souvent l’étude de l’élasticité-prix de la demande.\n\n\n\n\n\n\n\nElasticité-prix\n\n\n\n\n\nL’élasticité prix-demande mesure la sensibilité de la quantité demandée d’un bien ou service par rapport à une variation de son prix. Elle est définie comme le pourcentage de variation de la quantité demandée divisé par le pourcentage de variation du prix. Voici la formule de l’élasticité prix-demande :\n\\(E_{pd} = \\frac{\\Delta Q / Q}{\\Delta P / P}\\)\noù :\n\n\\(E_{pd}\\) est l’élasticité prix-demande,\n\\(\\Delta Q\\) est la variation de la quantité demandée,\n\\(Q\\) est la quantité demandée initiale,\n\\(\\Delta P\\) est la variation du prix,\n\\(P\\) est le prix initial.\n\nEn termes différentiels, cette formule peut être exprimée comme :\n\\(E_{pd} = \\frac{dQ}{dP} \\times \\frac{P}{Q}\\)\n\n\n\nÉlasticité unitaire \\((E_{pd} = -1)\\) : Une variation de 1% du prix entraîne une variation de 1% de la quantité demandée dans le sens opposé.\nDemande élastique \\((E_{pd} &lt; -1)\\) : La demande est très sensible aux variations de prix. Une variation de 1% du prix entraîne une variation de plus de 1% de la quantité demandée.\nDemande inélastique \\((-1 &lt; E_{pd} &lt; 0)\\) : La demande est peu sensible aux variations de prix. Une variation de 1% du prix entraîne une variation de moins de 1% de la quantité demandée.\nDemande parfaitement élastique \\((E_{pd} = -\\infty)\\) : Toute variation de prix entraînera une variation infinie de la quantité demandée.\nDemande parfaitement inélastique \\((E_{pd} = 0)\\) : La quantité demandée reste constante quelle que soit la variation de prix.\n\n\n\n\nSupposons qu’une augmentation du prix d’un bien de 10% entraîne une diminution de la quantité demandée de 20%.\n\nVariation en pourcentage du prix \\(\\Delta P / P\\) : 10%\nVariation en pourcentage de la quantité demandée \\(\\Delta Q / Q\\) : -20%\n\nL’élasticité prix-demande serait alors :\n\\(E_{pd} = \\frac{-20\\%}{10\\%} = -2\\)\nCela signifie que la demande est élastique : une augmentation de 1% du prix entraîne une diminution de 2% de la quantité demandée.\n\n\n\n\n\nConcurrence : Prendre en compte les prix fixés par les concurrents et la position concurrentielle de l’entreprise sur le marché. Cela peut conduire à des stratégies de prix compétitives telles que le prix d’écrémage ou le prix de pénétration.\nObjectifs de l’Entreprise : Fixer les prix en fonction des objectifs stratégiques de l’entreprise, qui peuvent inclure la maximisation des profits, la part de marché, la survie sur le marché, ou le leadership en termes de qualité.\nValeur Perçue : Considérer la valeur perçue par les consommateurs, qui peut justifier des prix plus élevés si le produit est perçu comme offrant un bénéfice supérieur ou une qualité supérieure."
  },
  {
    "objectID": "sections/projet5/index.html#stratégies-de-pricing",
    "href": "sections/projet5/index.html#stratégies-de-pricing",
    "title": "Stratégie de fixation des prix",
    "section": "",
    "text": "Prix de Pénétration : Fixer un prix bas pour entrer rapidement sur un marché et attirer un large volume de consommateurs.\nPrix d’Écrémage : Fixer un prix initial élevé pour maximiser les profits des segments de marché moins sensibles au prix, avant de baisser progressivement le prix.\nPrix Psychologique : Utiliser des techniques de fixation des prix qui influencent la perception du consommateur, comme fixer un prix à 9,99 € au lieu de 10 €.\nPrix de Groupe : Offrir des prix différents à différents segments de marché en fonction de leur disposition à payer.\nPrix de Prestiges : Fixer un prix élevé pour donner une image de qualité supérieure ou de luxe.\n\nLe pricing est donc une discipline complexe qui requiert une compréhension approfondie de nombreux facteurs économiques et comportementaux pour réussir."
  },
  {
    "objectID": "sections/projet5/index.html#footnotes",
    "href": "sections/projet5/index.html#footnotes",
    "title": "Stratégie de fixation des prix",
    "section": "Notes de bas de page",
    "text": "Notes de bas de page\n\n\n\\(\\theta\\) représente la sensibilité du consommateur.↩︎"
  },
  {
    "objectID": "sections/projets3/index.html",
    "href": "sections/projets3/index.html",
    "title": "Prévision des défauts de paiement bancaire",
    "section": "",
    "text": "1 Contexte\nLa détection des défauts de paiements des crédits bancaires est un enjeu majeur pour les banques. Une gestion rigoureuse, permet d’avoir un recouvrement de créance efficace et maintenir des flux de trésorerie solides. De ce fait, il est essentiel de minimmiser ces pertes. La classification supervisée regroupe l’ensemble des méthodes statistiques dont l’objectif principal est de prédire pour un individu donné l’appartenance à une classe connue au préalable. Nous sommes ici dans le cas d’une banque de détails qui souhaite attribuer un score ou probabilité de risque à ses clients.\n\n\n2 Objectifs\nAinsi, dans le cas des défauts de paiement bancaire, l’objectif est de pouvoir modéliser l’appartenance d’un individu à l’une des classes suivantes :\n\nOui [1], l’individu est en défaut de paiement ;\nNon [0], l’individu n’est pas en défaut de paiement ;\n\n\n\n3 Méthodologie\nDe prime abord, nous avons réalisé une analyse descriptive qui a nous permis de mettre en exergue un déséquilibre des classes pour la variable à expliquer. En d’autres termes, nous avons une présence élevée de personne n’étant pas en défaut de paiement contrairement à celles qui le sont.\nCela est un fait positif pour une banque en soi.\nCependant, ce déséquilibre impact négativement la performance et biaise le résultat des modèles.\nCela nous a donc conduit a procédé comme suit :\n\nDécoupage de la population en 2 sous-groupes :\n\nUn groupe dédié à l’apprentissage, autrement dit, le groupe d’entraînement (2/3) ;\nUn groupe dédié à la validation des modèles, autrement dit, le groupe test (1/3) ;\n\nPremière application des modèles sans prise en compte du déséquilibre des classes.\nSeconde à application des modèles en prenant en compte le déséquilibre des classes par le biais d’application de méthode de ré-échantillonnage des classes, à savoir :\n\n\n\n\n\n\n\nSous-échantillonnage\n\n\n\n\n\nRéduit le nombre d’échantillons de la classe majoritaire.\n\n\n\n\n\n\n\n\n\nSur-échantillognnage\n\n\n\n\n\nAugmente le nombre d’échantillons de la classe minoritaire.\n\n\n\n\n\n\n\n\n\nSMOTE\n\n\n\n\n\nGénère des exemples synthétiques de la classe minoritaire.\n\n\n\n\nLes modèles utilisés sont les suivants :\n\n\n\n\n\n\n\nAnalyse linéaire discriminante (LDA)\n\n\n\n\n\nL’analyse discriminante linéaire (LDA) est une technique de classification et de réduction de dimension qui vise à séparer les classes en trouvant une projection linéaire des données qui maximise la séparation entre les classes tout en minimisant la variance au sein des classes.\n\n\n\n\n\n\n\n\n\nAnalyse quadratique discriminante (QDA)\n\n\n\n\n\nL’analyse discriminante quadratique (QDA) est une extension de l’analyse discriminante linéaire (LDA) qui permet de modéliser des frontières de décision non linéaires. Contrairement à LDA, qui suppose que les covariances des classes sont identiques, QDA permet à chaque classe d’avoir sa propre matrice de covariance. Cela permet une modélisation plus flexible, mais nécessite plus de paramètres et peut donc être moins efficace avec de petits ensembles de données.\n\n\n\n\n\n\n\n\n\nArbres de décisions\n\n\n\n\n\nLes arbres de décision sont des modèles de machine learning non paramétriques utilisés pour la classification et la régression. Ils apprennent des règles de décision simples déduites des données pour prédire la valeur de la variable cible.\n\n\n\n\n\n\n\n\n\nBagging, Boosting\n\n\n\n\n\nLes termes “Bagging” et “Boosting” sont des techniques utilisées en apprentissage automatique (machine learning) pour améliorer les performances des modèles prédictifs en utilisant des ensembles de modèles plus simples.\n\n\n\n\n\n\n\n\n\nForêts aléatoires\n\n\n\n\n\nLes forêts aléatoires sont une technique de machine learning utilisée pour la classification et la régression. Elles fonctionnent en combinant plusieurs arbres de décision, chacun construit sur un échantillon différent des données d’entraînement. Le principe de base est le suivant :\n\nConstruction d’arbres : Un grand nombre d’arbres de décision sont construits, chaque arbre étant entraîné sur un échantillon aléatoire des données d’entraînement.\nPrédiction par vote majoritaire : Pour la classification, chaque arbre “vote” pour une classe, et la classe la plus souvent choisie par les arbres est la prédiction finale. Pour la régression, la prédiction finale est la moyenne des prédictions de tous les arbres.\n\nL’utilisation de multiples arbres et l’échantillonnage aléatoire des données permettent de réduire le risque de surapprentissage (overfitting) et d’améliorer la robustesse et la précision des prédictions.\n\n\n\n\n\n4 Principaux\nAprès avoir entraîné les modèles sur l’échantillon d’entraînement, nous avons appliqué les modèles sur les données test afin d’en apprécier leur performance. Plus précisément, nous avons comparé les résultats de nos 2 approches. C’est-à-dire l’approche tenant compte du déséquilibre des classes et celle ne la prenant pas en compte.\nSur la base des différentes métriques d’évaluation que nous avons utilisé, ils s’avère que le modèle le plus performabnt est une Forêt Aléatoire sur laquelle nous avons appliqué la méthode SMOTE.\nLe modèle retenu présente un taux de bonne prédictions de 94,6% contre 5,4% de taux de mauvaises prédictions.\n\n\n5 Conclusions et perspective\nDans la réalité, il est très probable de rencontrer un déséquilibre de classes de la variable à expliquer pour les problèmes de classification supervisée. Surtout dans le milieu bancaire.\nC’est un aspect qui biaise fortement les résultats d’estimations. Par conséquent, il est important de pouvoir le détecter assez tôt et appliquer les méthodes adéquates pour prendre en compte le problème. Au sortir de là, cela nous permet d’obtenir un modèle qui n’est pas biaisé. Ce dernier nous permet donc aisément de prédire, pour un individu donné, sa probabilité d’appartenance à l’une des classes de la variable à expliquer. Dans le cas des défauts de paiement bancaire, l’intérêt de ce genre de méthodes est qu’elle donne la possibilité de mettre en place de moyens de prévention pour se prémunir des personnes qui présentent un fort risque d’être en défaut de paiement.\n\n\n6 Outil technique\n\nLogiciel \n\n\n\nVous trouverez le rapport ici :\n\n\n\n\n\n\nLire le rapport"
  },
  {
    "objectID": "sections/projet7/index.html",
    "href": "sections/projet7/index.html",
    "title": "L’Univers de l’Horlogerie de Seconde Main",
    "section": "",
    "text": "1 Contexte général de l’analyse du marché de l’horlogerie\nL’industrie horlogère est un secteur dynamique et hautement concurrentiel, où les tendances de prix et les préférences des consommateurs évoluent constamment. Afin de mieux comprendre les variations de prix sur le marché de la seconde main, et les caractéristiques des montres proposées sur le marché, cette analyse se concentre sur l’exploration des données collectées sur le site Chrono24, l’une des principales plateformes de vente de montres de luxe en ligne.\n\n\n2 Objectif de l’analyse\nL’objectif principal de cette analyse est de fournir des insights pertinents sur les tendances actuelles du marché des montres en se basant sur des données provenant de Chrono24. À travers le scraping de données en ligne, nous avons extrait des informations détaillées sur un large éventail de montres proposées à la vente, notamment :\n\nPrix des montres : Données sur les prix pour les différentes marques, modèles, et états des montres.\nCaractéristiques des montres : Informations sur les spécifications telles que les matériaux utilisés (acier, or, etc.), le type de mouvement, la taille, et les autres caractéristiques techniques.\nMarques populaires : Identification des marques les plus recherchées et les plus proposées sur le marché secondaire.\nÉvolution des prix : Analyse des variations de prix des montres selon des critères comme la marque, la matière du boîtier, ou la rareté.\n\n\n\n3 Méthodologie\nLes données ont été collectées par scraping depuis le site web de Chrono24 à l’aide d’outils Python tels que BeautifulSoup et Selenium. Ce processus a permis d’extraire un ensemble de données riche et diversifié sur les montres mises en vente, comprenant des informations sur les prix, les marques, les matériaux, les tailles, et bien plus encore. Ces données ont ensuite été nettoyées et préparées pour l’analyse à l’aide de bibliothèques telles que Pandas et NumPy.\nL’analyse s’est articulée autour de plusieurs axes :\n\nAnalyse descriptive : Statistiques de base (moyenne, médiane, écart-type) sur les prix des montres et leurs caractéristiques.\nVisualisation des données : Utilisation de graphiques pour représenter la distribution des prix par marque, la répartition des prix selon les matériaux, et d’autres caractéristiques pertinentes.\nModélisation prédictive : Développement de modèles permettant de prédire les variations de prix en fonction de certains facteurs comme la marque, le type de mouvement, et l’état de la montre.\n\n\n\n\n\n\n\nPrésentation des variables de la base données\n\n\n\n\n\n\n\n\n\n\n\n\nVariables\nInterprétation\n\n\n\n\nMarque\nMarque de la montre\n\n\nModèle\nModèle de la montre\n\n\nmouvement\nType de mouvement (manuel, autmatique, etc. )\n\n\nMatiere du boîtier\nMatière du boîtier (acier, or, etc. )\n\n\nMatiere du bracelet\nMatière du bracelet (or, acier, caoutchouc)\n\n\nEtat de la montre\nEtat de la montre (Bon, mauvais, etc. )\n\n\nSexe\ncatégorie de la montre : homme/femme\n\n\nprix\nPrix de la montre (en €)\n\n\nRéserve de macrhe\nNiveau de réserve de marche de la montre\n\n\nDiamètre\nDiamètre de la montre\n\n\nEtenchéité\nNiveau d’étenchéité de la montre\n\n\nmatiere de la lunette\nMatière de la lunette de la montre\n\n\nmatiere du verre\nMatière du verre de la montre\n\n\nmatiere de la boucle\nMatière de la boucle de la montre\n\n\nPays\nPays de provenance de la montre\n\n\n\n\n\n\n\n\n4 Résultats attendus\nÀ travers cette analyse, nous cherchons à obtenir une vue d’ensemble des tendances actuelles du marché des montres de luxe. Cela permettra de répondre à plusieurs questions clés :\n\nQuelles sont les marques les plus recherchées et les plus coûteuses ?\nComment les caractéristiques (matériaux, type de mouvement, etc.) influent-elles sur le prix des montres ?\nExiste-t-il des tendances saisonnières ou géographiques influençant les prix ?\n\n\n\n5 Applications de l’analyse\nLes résultats de cette analyse peuvent être utilisés pour :\n\nLes revendeurs : Affiner leur stratégie de tarification en fonction des tendances observées sur le marché.\nLes acheteurs : Obtenir une vue d’ensemble des prix moyens et des bonnes affaires dans le marché de l’horlogerie.\nLes marques et fabricants : Comprendre les attentes des consommateurs et les tendances de demande en matière de modèles spécifiques ou de caractéristiques.\n\nEn résumé, cette analyse vise à fournir une compréhension approfondie des dynamiques du marché de l’horlogerie via les données issues de Chrono24, ce qui pourra servir à la fois pour des études de marché, des prévisions de prix, et la définition de stratégies commerciales adaptées.\n\n\n6 Outil technique\n\nLe projet a entièrement été developpé en Python.\n\n\nCliquer ici pour voir le code source.\n\n\n\n7 Application pour visualiser les statistiques :\n\nLancer l’application"
  },
  {
    "objectID": "sections/projet6/index.html",
    "href": "sections/projet6/index.html",
    "title": "Marketing quantitatif au service de la santé",
    "section": "",
    "text": "Le marketing quantitatif est une approche analytique du marketing qui se concentre sur l’utilisation de données et de statistiques pour prendre des décisions éclairées et mesurer les performances des activités marketing. Les prestataires de services peuvent avoir recours à ce genre de techniques afin de mieux comprendre la demande et ainsi affiner leur propositions.\nEn l’occurrence, nous sommes dans le cas d’une étude qui concerne le programme d’assurance Medicare aux Etats-Unis. C’est un programme d’assurance maladie qui aide les personnes âgées à payer les services de santé. Certaines personnes souscrivent une assurance complémentaire, Medigap 1 qui les aide à payer le reste à charge de Medicare et les autres dépenses médicales qui ne sont pas couvertes par Medicare. Cette assurance est parfois fournie par le dernier employeur de la personne dans le cadre d’une prestation de retraite. D’autres personnes souscrivent une assurance maladie complémentaire auprès de sociétés d’assurances privées."
  },
  {
    "objectID": "sections/projet6/index.html#footnotes",
    "href": "sections/projet6/index.html#footnotes",
    "title": "Marketing quantitatif au service de la santé",
    "section": "Notes de bas de page",
    "text": "Notes de bas de page\n\n\nMedigap, également connu sous le nom de “Medicare Supplement Insurance,” est une police d’assurance privée qui aide à couvrir certains des coûts de santé non pris en charge par Medicare Original (Parts A et B), tels que les franchises, les copayments et les coinsurances.↩︎"
  },
  {
    "objectID": "sections/projet4/index.html",
    "href": "sections/projet4/index.html",
    "title": "Mesure de l’efficacité technique d’une entreprise",
    "section": "",
    "text": "1 Contexte\nL’analyse des frontières stochastiques (SFA) est une méthode de modélisation économique. Elle trouve son point de départ dans les modèles stochastiques de production frontière introduits simultanément par Aigner, Lovell et Schmidt (1977) et Meeusen et Van den Broeck (1977).\nLe modèle de frontière de production sans composante aléatoire peut s’écrire :\n\\(y_i = f(x_i, \\beta)\\times TE_i\\)\noù \\(y_i\\) est la production scalaire observée du producteur \\(i\\) ; \\(i=1,..I,\\) \\(x_i\\) est un vecteur de \\(N\\) entrées utilisé par le \\(producteur_i\\) ;\n\n\\(\\beta\\) est un vecteur de paramètres technologiques à estimer ;\n\\(f(x_i , \\beta)\\) est la fonction frontière de production ;\n\n\\(TE_i\\) désigne l’efficacité technique définie comme le rapport entre la production observée et la production maximale réalisable. \\(TE = (\\frac{y}{y*})\\). \\(TE_i = 1\\) montre que la ième entreprise obtient la production maximale réalisable, tandis que \\(TE_i\\) &lt; 1 fournit une mesure de l’écart entre la production observée et la production maximale réalisable. En d’autres termes, \\(TE_i\\) détermine l’utilisation non efficiente des inputs.\nUne composante stochastique décrivant les chocs aléatoires affectant le processus de production est ajoutée. Ces chocs ne sont pas directement imputables au producteur ou à la technologie sous-jacente. Ces chocs peuvent provenir de changements climatiques, de difficultés économiques ou simplement de chance. Nous notons ces effets par \\(exp(v_i)\\). Chaque producteur est confronté à un choc différent, mais nous supposons que les chocs sont aléatoires et qu’ils sont décrits par une distribution commune.\nLa frontière de production stochastique deviendra :\n\\(y_i = f(x_i, \\beta) \\times TE_i \\times (v_i)\\)\nNous supposons que \\(TE_i\\) est également une variable stochastique, avec une fonction de distribution spécifique, commune à tous les producteurs.\nL’analyse des frontières stochastiques a également examiné l’efficacité du « coût » et du « profit » (voir Kumbhakar & Lovell 2003). L’approche de la « frontière des coûts » tente de mesurer dans quelle mesure l’entreprise se trouve loin de la minimisation totale des coûts (c’est-à-dire du rapport coût-efficacité). Du point de vue de la modélisation, la composante non négative d’inefficacité des coûts est ajoutée plutôt que soustraite dans la spécification stochastique. « L’analyse de la frontière du profit » examine le cas où les producteurs sont traités comme ceux qui maximisent le profit (la production et les intrants doivent être décidés par l’entreprise) et non comme ceux qui minimisent les coûts (où le niveau de production est considéré comme étant donné de manière exogène). La spécification ici est similaire à celle de la « frontière de production ».\n\n\n2 Objectifs\nL’objectif de ce travail est d’appliquer les techniques d’analyse des frontières de production sur des données de transport aérien américain. Pour ce faire, nous disposions d’une base de données de 232 observations de sociétés issues du transport aérien américain. Les variables présentes dans le jeu de données sont les suivantes :\n\n\n\nVariables\n\n\n\n\nCoût total\n\n\nQuantité produite\n\n\nLe prix du travail\n\n\nLe prix du capital\n\n\nLe prix du carburant\n\n\nLe part du coût du travail dans le coût total\n\n\nLe part du coût du capital dans le coût total\n\n\nLe part du coût du carburant dans le coût total\n\n\n\n\n\n3 Méthodologie\nPour atteindre notre objectif, nous avons tout d’abord procédé à une analyse descriptive de notre jeu de données qui nous a permis d’observer les tendances générales qui s’y dégagent. En d’autres termes, nous avons réalisé une étude sur :\n\nAnalyse des coûts\nQuantités produites\nLa productivité des entreprises\n\nEnsuite, nous avons réalisé une modélisation de la frontière stochastique respectivement du point de vue des coûts mais aussi de la production. Dans les deux cas, nous avons réalisé diverses modélisations afin d’apprécier les résultats des différentes formes fonctionnelles que peuvent prendre ces modèles et confronter les résultats obtenus dans le but d’otenir le meilleur.\n\n\n4 Outil technique\n\nLogiciel \n\n\n\nVous trouverez le rapport ici :"
  },
  {
    "objectID": "sections/projet2/index.html",
    "href": "sections/projet2/index.html",
    "title": "L’immobilier à Saratoga ~ Californie",
    "section": "",
    "text": "Dans le cadre d’un projet réalisé dans l’apprentissage de méthodes de Datamining, 1 il a été question d’appliquer des méthodes de classification non supervisée 2 sur une base de données contenant des informations sur 1728 biens immobiliers de la ville de Saratoga, en Californie."
  },
  {
    "objectID": "sections/projet2/index.html#footnotes",
    "href": "sections/projet2/index.html#footnotes",
    "title": "L’immobilier à Saratoga ~ Californie",
    "section": "Notes de bas de page",
    "text": "Notes de bas de page\n\n\nLa fouille de données (ou “datamining” en anglais) désigne le processus de découverte de motifs, de corrélations ou d’anomalies en analysant de grands ensembles de données à l’aide de diverses techniques computationnelles. Cela implique d’extraire des informations utiles à partir de données brutes pour découvrir des motifs cachés, des relations ou des insights qui peuvent aider à la prise de décision ou à la prédiction.↩︎\nLa classification non supervisée, également connue sous le nom de clustering, est une méthode de fouille de données qui consiste à regrouper des objets ou des données sans utiliser d’étiquettes ou de catégories prédéfinies.↩︎\nL’homogénéité d’une population ou d’une classe, en termes statistiques, se réfère à la similitude ou à la cohérence des individus ou des observations au sein de cette population ou classe. Cela signifie que les membres de cette population ou classe présentent des caractéristiques ou des attributs similaires.↩︎"
  },
  {
    "objectID": "sections/projet3/index.html",
    "href": "sections/projet3/index.html",
    "title": "Prévision des défauts de paiement bancaire",
    "section": "",
    "text": "1 Contexte\nLa détection des défauts de paiements des crédits bancaires est un enjeu majeur pour les banques. Une gestion rigoureuse, permet d’avoir un recouvrement de créance efficace et maintenir des flux de trésorerie solides. De ce fait, il est essentiel de minimmiser ces pertes. La classification supervisée regroupe l’ensemble des méthodes statistiques dont l’objectif principal est de prédire pour un individu donné l’appartenance à une classe connue au préalable. Nous sommes ici dans le cas d’une banque de détails qui souhaite attribuer un score ou probabilité de risque à ses clients.\n\n\n2 Objectifs\nAinsi, dans le cas des défauts de paiement bancaire, l’objectif est de pouvoir modéliser l’appartenance d’un individu à l’une des classes suivantes :\n\nOui [1], l’individu est en défaut de paiement ;\nNon [0], l’individu n’est pas en défaut de paiement ;\n\n\n\n3 Méthodologie\nDe prime abord, nous avons réalisé une analyse descriptive qui a nous permis de mettre en exergue un déséquilibre des classes pour la variable à expliquer. En d’autres termes, nous avons une présence élevée de personne n’étant pas en défaut de paiement contrairement à celles qui le sont.\nCela est un fait positif pour une banque en soi.\nCependant, ce déséquilibre impact négativement la performance et biaise le résultat des modèles.\nCela nous a donc conduit a procédé comme suit :\n\nDécoupage de la population en 2 sous-groupes :\n\nUn groupe dédié à l’apprentissage, autrement dit, le groupe d’entraînement (2/3) ;\nUn groupe dédié à la validation des modèles, autrement dit, le groupe test (1/3) ;\n\nPremière application des modèles sans prise en compte du déséquilibre des classes.\nSeconde à application des modèles en prenant en compte le déséquilibre des classes par le biais d’application de méthode de ré-échantillonnage des classes, à savoir :\n\n\n\n\n\n\n\nSous-échantillonnage\n\n\n\n\n\nRéduit le nombre d’échantillons de la classe majoritaire.\n\n\n\n\n\n\n\n\n\nSur-échantillognnage\n\n\n\n\n\nAugmente le nombre d’échantillons de la classe minoritaire.\n\n\n\n\n\n\n\n\n\nSMOTE\n\n\n\n\n\nGénère des exemples synthétiques de la classe minoritaire.\n\n\n\n\nLes modèles utilisés sont les suivants :\n\n\n\n\n\n\n\nAnalyse linéaire discriminante (LDA)\n\n\n\n\n\nL’analyse discriminante linéaire (LDA) est une technique de classification et de réduction de dimension qui vise à séparer les classes en trouvant une projection linéaire des données qui maximise la séparation entre les classes tout en minimisant la variance au sein des classes.\n\n\n\n\n\n\n\n\n\nAnalyse quadratique discriminante (QDA)\n\n\n\n\n\nL’analyse discriminante quadratique (QDA) est une extension de l’analyse discriminante linéaire (LDA) qui permet de modéliser des frontières de décision non linéaires. Contrairement à LDA, qui suppose que les covariances des classes sont identiques, QDA permet à chaque classe d’avoir sa propre matrice de covariance. Cela permet une modélisation plus flexible, mais nécessite plus de paramètres et peut donc être moins efficace avec de petits ensembles de données.\n\n\n\n\n\n\n\n\n\nArbres de décisions\n\n\n\n\n\nLes arbres de décision sont des modèles de machine learning non paramétriques utilisés pour la classification et la régression. Ils apprennent des règles de décision simples déduites des données pour prédire la valeur de la variable cible.\n\n\n\n\n\n\n\n\n\nBagging, Boosting\n\n\n\n\n\nLes termes “Bagging” et “Boosting” sont des techniques utilisées en apprentissage automatique (machine learning) pour améliorer les performances des modèles prédictifs en utilisant des ensembles de modèles plus simples.\n\n\n\n\n\n\n\n\n\nForêts aléatoires\n\n\n\n\n\nLes forêts aléatoires sont une technique de machine learning utilisée pour la classification et la régression. Elles fonctionnent en combinant plusieurs arbres de décision, chacun construit sur un échantillon différent des données d’entraînement. Le principe de base est le suivant :\n\nConstruction d’arbres : Un grand nombre d’arbres de décision sont construits, chaque arbre étant entraîné sur un échantillon aléatoire des données d’entraînement.\nPrédiction par vote majoritaire : Pour la classification, chaque arbre “vote” pour une classe, et la classe la plus souvent choisie par les arbres est la prédiction finale. Pour la régression, la prédiction finale est la moyenne des prédictions de tous les arbres.\n\nL’utilisation de multiples arbres et l’échantillonnage aléatoire des données permettent de réduire le risque de surapprentissage (overfitting) et d’améliorer la robustesse et la précision des prédictions.\n\n\n\n\n\n4 Principaux\nAprès avoir entraîné les modèles sur l’échantillon d’entraînement, nous avons appliqué les modèles sur les données test afin d’en apprécier leur performance. Plus précisément, nous avons comparé les résultats de nos 2 approches. C’est-à-dire l’approche tenant compte du déséquilibre des classes et celle ne la prenant pas en compte.\nSur la base des différentes métriques d’évaluation que nous avons utilisé, ils s’avère que le modèle le plus performabnt est une Forêt Aléatoire sur laquelle nous avons appliqué la méthode SMOTE.\nLe modèle retenu présente un taux de bonne prédictions de 94,6% contre 5,4% de taux de mauvaises prédictions.\n\n\n5 Conclusions et perspective\nDans la réalité, il est très probable de rencontrer un déséquilibre de classes de la variable à expliquer pour les problèmes de classification supervisée. Surtout dans le milieu bancaire.\nC’est un aspect qui biaise fortement les résultats d’estimations. Par conséquent, il est important de pouvoir le détecter assez tôt et appliquer les méthodes adéquates pour prendre en compte le problème. Au sortir de là, cela nous permet d’obtenir un modèle qui n’est pas biaisé. Ce dernier nous permet donc aisément de prédire, pour un individu donné, sa probabilité d’appartenance à l’une des classes de la variable à expliquer. Dans le cas des défauts de paiement bancaire, l’intérêt de ce genre de méthodes est qu’elle donne la possibilité de mettre en place de moyens de prévention pour se prémunir des personnes qui présentent un fort risque d’être en défaut de paiement.\n\n\n6 Outil technique\n\nLogiciel \n\n\n\nVous trouverez le rapport ici :\n\n\n\n\n\n\nLire le rapport"
  },
  {
    "objectID": "licence.html",
    "href": "licence.html",
    "title": "Licence",
    "section": "",
    "text": "© 2024 – François BOUSSENGUI\nLe contenu de mon site web est publié sous licence Creative Commons Attribution 4.0 International (CC BY-NC-SA)."
  },
  {
    "objectID": "licence.html#logiciels-utilisés",
    "href": "licence.html#logiciels-utilisés",
    "title": "Licence",
    "section": "Logiciels utilisés",
    "text": "Logiciels utilisés\nLe code source ainsi que l’ensemble des fichiers hostés sur mon site web sont disponibles sur  GitHub.\nIcônes :  FontAwesome\nPolices :  Google Fonts\nHébergement :  Netlify\nThème : https://github.com/robb0wen/synthwave-vscode"
  },
  {
    "objectID": "sections/cours1/index.html",
    "href": "sections/cours1/index.html",
    "title": "Microéconomie - Leçon 1 : Théorie du consommateur",
    "section": "",
    "text": "Cette leçon introduit la théorie du consommateur, qui cherche à modéliser les choix d’un individu confronté à une contrainte de revenu et plusieurs combinaisons possibles de biens à consommer."
  },
  {
    "objectID": "sections/cours1/index.html#hypothèses-de-base",
    "href": "sections/cours1/index.html#hypothèses-de-base",
    "title": "Microéconomie - Leçon 1 : Théorie du consommateur",
    "section": "2.1 1.1 Hypothèses de base",
    "text": "2.1 1.1 Hypothèses de base\nSoit un ensemble de paniers de biens \\(( x = (x_1, x_2) \\in \\mathbb{R}_+^2)\\). On suppose que le consommateur est capable de comparer tous les paniers.\nLes préférences \\(( \\succeq \\)\\) sont supposées :\n\nComplètes : \\(( \\forall x, y, x \\succeq y ) ou ( y \\succeq x )\\)\nRéflexives : \\(( x \\succeq x )\\)\nTransitives : \\(( x \\succeq y, y \\succeq z \\Rightarrow x \\succeq z )\\)\nMonotones : “plus c’est mieux”\nConvexes : les préférences sont “diversifiantes”"
  },
  {
    "objectID": "sections/cours1/index.html#représentation-par-une-fonction-dutilité",
    "href": "sections/cours1/index.html#représentation-par-une-fonction-dutilité",
    "title": "Microéconomie - Leçon 1 : Théorie du consommateur",
    "section": "2.2 1.2 Représentation par une fonction d’utilité",
    "text": "2.2 1.2 Représentation par une fonction d’utilité\nSi les préférences sont continues et convexes, il existe une fonction d’utilité \\(u(x_1, x_2)\\) telle que :\n\\[\nx \\succeq y \\Leftrightarrow u(x_1, x_2) \\geq u(y_1, y_2)\n\\]\nL’utilité est une représentation ordinale : seules les préférences relatives importent."
  },
  {
    "objectID": "sections/cours1/index.html#programme-du-consommateur",
    "href": "sections/cours1/index.html#programme-du-consommateur",
    "title": "Microéconomie - Leçon 1 : Théorie du consommateur",
    "section": "4.1 3.1 Programme du consommateur",
    "text": "4.1 3.1 Programme du consommateur\n\\(\\max_{(x_1,x_2) \\in B} u(x_1, x_2)\\)"
  },
  {
    "objectID": "sections/cours1/index.html#méthode-du-lagrangien",
    "href": "sections/cours1/index.html#méthode-du-lagrangien",
    "title": "Microéconomie - Leçon 1 : Théorie du consommateur",
    "section": "4.2 3.2 Méthode du Lagrangien",
    "text": "4.2 3.2 Méthode du Lagrangien\nSoit \\(( \\mathcal{L}(x_1,x_2,\\lambda) = u(x_1,x_2) - \\lambda (p_1 x_1 + p_2 x_2 - R) )\\)\nConditions du premier ordre (CPO) :\n\\(\\begin{cases} \\frac{\\partial u}{\\partial x_1} = \\lambda p_1 \\\\ \\frac{\\partial u}{\\partial x_2} = \\lambda p_2 \\\\ p_1 x_1 + p_2 x_2 = R \\end{cases}\\)\nCela conduit à la condition d’égalité des taux marginaux de substitution :\n\\(\\frac{\\frac{\\partial u}{\\partial x_1}}{\\frac{\\partial u}{\\partial x_2}} = \\frac{p_1}{p_2}\\)"
  },
  {
    "objectID": "sections/cours1/index.html#fonction-cobb-douglas",
    "href": "sections/cours1/index.html#fonction-cobb-douglas",
    "title": "Microéconomie - Leçon 1 : Théorie du consommateur",
    "section": "5.1 4.1 Fonction Cobb-Douglas",
    "text": "5.1 4.1 Fonction Cobb-Douglas\n\\(u(x_1, x_2) = x_1^\\alpha x_2^{1-\\alpha}\\)\nDemande optimale :\n\\(x_1^* = \\alpha \\frac{R}{p_1}, \\quad x_2^* = (1 - \\alpha) \\frac{R}{p_2}\\)"
  },
  {
    "objectID": "sections/cours1/index.html#biens-parfaits-substituts",
    "href": "sections/cours1/index.html#biens-parfaits-substituts",
    "title": "Microéconomie - Leçon 1 : Théorie du consommateur",
    "section": "5.2 4.2 Biens parfaits substituts",
    "text": "5.2 4.2 Biens parfaits substituts\n\\(u(x_1, x_2) = a x_1 + b x_2\\)"
  },
  {
    "objectID": "sections/cours1/index.html#biens-parfaits-compléments",
    "href": "sections/cours1/index.html#biens-parfaits-compléments",
    "title": "Microéconomie - Leçon 1 : Théorie du consommateur",
    "section": "5.3 4.3 Biens parfaits compléments",
    "text": "5.3 4.3 Biens parfaits compléments\n\\(u(x_1, x_2) = \\min \\{ a x_1, b x_2 \\}\\)"
  },
  {
    "objectID": "sections/cours1/index.html#exercice-1",
    "href": "sections/cours1/index.html#exercice-1",
    "title": "Microéconomie - Leçon 1 : Théorie du consommateur",
    "section": "6.1 Exercice 1",
    "text": "6.1 Exercice 1\nSoit \\(( u(x_1, x_2) = x_1^{0.5} x_2^{0.5} ), ( R = 100 ), ( p_1 = 2 ), ( p_2 = 5 ).\\) Trouver les quantités optimales.\nSolution :\n\\(x_1^* = 0.5 \\cdot \\frac{100}{2} = 25 \\quad ; \\quad x_2^* = 0.5 \\cdot \\frac{100}{5} = 10\\)"
  },
  {
    "objectID": "sections/cours1/index.html#exercice-2",
    "href": "sections/cours1/index.html#exercice-2",
    "title": "Microéconomie - Leçon 1 : Théorie du consommateur",
    "section": "6.2 Exercice 2",
    "text": "6.2 Exercice 2\nSoit \\(( u(x_1, x_2) = \\min\\{x_1, 2x_2\\} ), ( R = 120 ), ( p_1 = 4 ), ( p_2 = 6 )\\). Trouver les quantités optimales.\nSolution :\nIl faut \\(( x_1 = 2x_2 )\\). Résolvons : \\(4x_1 + 6x_2 = 120 \\Rightarrow 4(2x_2) + 6x_2 = 120 \\Rightarrow 14x_2 = 120 \\Rightarrow x_2^* = \\frac{60}{7}, \\quad x_1^* = \\frac{120}{7}\\)"
  },
  {
    "objectID": "sections/cours1/index.html#hypothèses-fondamentales",
    "href": "sections/cours1/index.html#hypothèses-fondamentales",
    "title": "Microéconomie - Leçon 1 : Théorie du consommateur",
    "section": "2.1 1.1 Hypothèses fondamentales",
    "text": "2.1 1.1 Hypothèses fondamentales\nSoit un panier de consommation noté \\(x = (x_1, x_2) \\in \\mathbb{R}_+^2\\), représentant deux biens.\nLes préférences du consommateur sont modélisées par une relation binaire \\(\\succeq\\) telle que :\n\nComplétude : \\(\\forall x, y\\), \\(x \\succeq y\\) ou \\(y \\succeq x\\)\nRéflexivité : \\(x \\succeq x\\)\nTransitivité : \\(x \\succeq y\\) et \\(y \\succeq z \\Rightarrow x \\succeq z\\)\nMonotonie : Si \\(x_1 \\geq y_1\\) et \\(x_2 \\geq y_2\\) avec au moins une inégalité stricte, alors \\(x \\succ y\\)\nConvexité : Le consommateur préfère les combinaisons de paniers aux paniers extrêmes"
  },
  {
    "objectID": "sections/xp.html#master-data-science-business-economics",
    "href": "sections/xp.html#master-data-science-business-economics",
    "title": "Mon parcours",
    "section": "",
    "text": "2019 – 2021\n Faculté de Droit, économie et sciences sociales, 50 Avenue Jean Portalis, 37200 Tours, France\n\nMajeure Data Science : apprentissage approfondi en statistiques, machine learning, séries temporelles et bases de données.\n\nProjet clé : mise en place d’un modèle de machine learning pour prédire le prix de vente de véhicules d’occasion en France.\nMémoire stage de fin d’étude : optimisation du scraper d’un tarifaire en assurance pour deux-roues ; Mise en place d’un modèle prédictif de résiliation.\nOutils & langages : maîtrise de Python (Numpy, Pandas, scikit‑learn), R, SQL, Git, Jupyter, présentation de résultats avec PowerPoint, Beamer et outils BI.\n\n\nMémoire fin d’étude \n\n\nGithub projet fin d’étude"
  }
]