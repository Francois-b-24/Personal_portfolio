---
title: "Méthodes de prévision"
subtitle: ""
author: ""
image: "mco.png"
categories: [Économétrie]
fields: [reading-time]
---


```{r echo=FALSE}
knitr::opts_chunk$set(warning = FALSE, echo = FALSE, fig.align = "center", out.width = "100%")
```

```{r echo=FALSE}
library(reticulate)
use_virtualenv("/Users/f.b/.virtualenvs/r-reticulate")
```

# Contexte général

Les **Moindres Carrés Ordinaires** (MCO), ou en anglais Ordinary Least Squares (OLS) est une méthode statistique utilisée pour modéliser la relation entre deux variables quantitatives. Il s'agit de la forme la plus élémentaire de la régression linéaire. En régression linéaire simple, une variable indépendante (ou explicative) est utilisée pour prédire une variable dépendante (ou réponse). L'objectif de la régression linéaire simple est de trouver les valeurs des coefficients $\beta_0$ et $\beta_1$ qui minimisent la somme des carrés des erreurs entre les valeurs observées et les valeurs prédites par le modèle.

L'économétrie offre un panel de méthodes de prévision statistique qui dépendent de la nature des données ainsi que de la problématique à résoudre. Ainsi, ces travaux de s'inscrivent dans le cadre de travaux de recherches réalisées durant ma seconde année de Master en économétrie.

# Objectifs du travail

Les objectifs de ces travaux sont divers. Principalement, ces travaux portent sur la présentation des principales méthodes alternatives aux **Moindres Carrés Ordinaires** (MCO). Dans un premier temps, il été question de proposer une représentation alternatives des principaux résultats d'une régression linéaire simple. Pour ce faire, nous avons proposé une représentation sous forme *diagrammatique* (graphique) des principaux résultats de la méthode des **Moindres Carrés Ordinaires**. Dans un second temps, il a été question de présenter et de classifier les principales méthodes alternatives à celles des **Moindres Carrés Ordinaires**.

# Méthodologie 

Pour atteindre ces objectifs, nous avons analyser des travaux de recherche en économétrie et nous avons travaillé en étroite collaboration avec notre professeur référent en la matière.

Ainsi, nos recherches nous ont permis d'aboutir à la proposition d'une représentation graphique des principaux résultats d'une régression linéaire simple : 

* $y = \beta_0 + \beta_1x + \epsilon$.

  + $y$ est la variable dépendante (la réponse)
  + $x$ est la variable explicative (le prédicteur)
  + $\beta_0$ est l'ordonnée à l'origine (l'intercept)
  + $\beta_1$ est le coefficient de regression (la pente)
  + $\epsilon$ est l'erreur aléatoire

Par ailleurs, nous avons mis en exergue plusieurs familles de méthodes de prévision économétrique. Nous pouvons les classer comme suit :

**1**. Les modèles décrivant une **relation linéaire** entre la variable à expliquer et la/les variable(s) explicative(s). 

*   **Moindres carrés ordinaires** : C'est une méthode utilisée pour estimer les paramètres d'un modèle de régression linéaire. Elle minimise la somme des carrés des différences entre les valeurs observées et les valeurs prédites par le modèle.

*   **Régression orthogonale** : Également connue sous le nom de régression des moindres carrés orthogonaux (Orthogonal Least Squares Regression) ou régression de Deming, est une méthode qui prend en compte les erreurs dans les deux variables, à la fois la variable indépendante (x) et la variable dépendante (y). Contrairement à la régression linéaire ordinaire qui minimise uniquement les erreurs en y, la régression orthogonale minimise la somme des distances orthogonales entre les points de données et la ligne de régression.

## Représentation graphique  :

```{python}
import numpy as np
import matplotlib.pyplot as plt
from scipy.odr import ODR, Model, RealData
from sklearn.linear_model import LinearRegression

# Génération de données avec erreurs

np.random.seed(0)
x = np.linspace(0, 10, 10)
y = 2 * x + 1 + np.random.normal(size=x.size)

# Régression MCO
mco_model = LinearRegression()
mco_model.fit(x.reshape(-1, 1), y)
y_mco_pred = mco_model.predict(x.reshape(-1, 1))

# Régression Orthogonale
def orthogonal_func(beta, x):
    return beta[0] * x + beta[1]

data = RealData(x, y)
model = Model(orthogonal_func)
odr = ODR(data, model, beta0=[1., 2.])
odr_res = odr.run()
y_ortho_pred = orthogonal_func(odr_res.beta, x)

# Visualisation
plt.scatter(x, y, label='Données')
plt.plot(x, y_mco_pred, label='MCO', color='red')
plt.plot(x, y_ortho_pred, label='Régression Orthogonale', color='green')
plt.legend()
plt.show()

```

**2**. Les modèles qui décrivent une relation non linéaire entre la variable à expliquer et la/les variable(s) explicative(s). 

*   **Régression non paramétrique** : La régression non paramétrique est une technique statistique qui permet de modéliser les relations entre variables sans supposer de forme paramétrique spécifique pour la relation

Pour chacune des méthodes, nous avons mis en évidence :

*   **La forme fonctionnelle du modèle** : La forme fonctionnelle d'un modèle se réfère à la spécification de la relation mathématique entre les variables indépendantes (ou explicatives) et la variable dépendante (ou à expliquer). Cette spécification définit comment les variables sont liées dans le modèle et peut prendre plusieurs formes selon la nature des données et les hypothèses sous-jacentes

*  **Les principales hypothèses associées au modèle** : Les principales hypothèses d'un modèle sont essentielles pour garantir la validité et la fiabilité des estimations des coefficients.

-   Leur application dans {{< fa brands r-project >}} et {{< fa brands python >}}

# Outils techniques 

- {{< fa brands r-project >}}

- {{< fa brands python >}}

- LateX 



```{r include_pdf, echo=FALSE, fig.width=10, fig.height=6 }
knitr::include_graphics("/Users/f.b/Desktop/Data_Science/Data_Science/Personal_portfolio/Personal_portfolio/posts/first/AlternativesMCO.pdf")
```

::: {style="text-align:center;"}
[Rapport : Représentation sous forme de diagramme des MCO {{< fa arrow-up-right-from-square >}}](AlternativesMCO.pdf){.btn .btn-outline-primary .btn .center role="button"}
:::


```{r include_pdf_2, echo=FALSE, fig.width=10, fig.height=6 }
knitr::include_graphics("/Users/f.b/Desktop/Data_Science/Data_Science/Personal_portfolio/Personal_portfolio/posts/first/Alternatives aux MCO.pdf")
```

::: {style="text-align:center;"}
[Présentation : Alternatives aux MCO {{< fa arrow-up-right-from-square >}}](Alternatives aux MCO.pdf){.btn .btn-outline-primary .btn .center role="button"}
:::



