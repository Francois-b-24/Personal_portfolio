---
title: "Prévision des défauts de paiement bancaire"
subtitle: ""
author: ""
image: "classification.png"
categories: [Machine Learning]
fields: [reading-time]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = "center", out.width = "100%")
```

# Contexte général

La détection des défauts de paiements des crédits bancaires est un enjeu majeur pour les banques. Une gestion rigoureuse, permet d'avoir un recouvrement de créance efficace et maintenir des flux de trésorerie solides. De ce fait, il est essentiel de minimmiser ces pertes. La **classification supervisée** regroupe l'ensemble des méthodes statistiques dont l'objectif principal est de prédire pour un individu donné l'appartenance à une classe connue au préalable. Nous sommes ici dans le cas d'une banque de détails qui souhaite attribuer un *score* ou *probabilité* de risque à ses clients. 

# Objectifs du travail

Ainsi, dans le cas des défauts de paiement bancaire, l'objectif est de pouvoir modéliser l'appartenance d'un individu à l'une des classes suivantes :

1.  **Oui** [1], l'individu est en défaut de paiement ;

2.  **Non** [0], l'individu n'est pas en défaut de paiement ;


# Méthodologie

De prime abord, nous avons réalisé une analyse descriptive qui a nous permis de découvrir un **déséquilibre des classes** pour la variable à expliquer. En d'autres termes, nous avons une présence élevée de personne n'étant pas en défaut de paiement contrairement à celles qui le sont. 

Cela est un fait positif pour une banque en soi. 

Cependant, ce déséquilibre impact négativement la performance et biaise le résultat des modèles.  

Cela nous a donc conduit a procédé comme suit :


*   Découpage de la population en 2 sous-groupes :

    +   Un groupe dédié à l'apprentissage, autrement dit, le groupe d'entraînement (2/3) ;

    +   Un groupe dédié à la validation des modèles, autrement dit, le groupe test (1/3) ;

*   Première application des modèles sans prise en compte du déséquilibre des classes 

*   Seconde à application des modèles en prenant en compte le déséquilibre des classes par le biais d'application de méthode de ré-échantillonnage des classes, à savoir :

::: {.callout-tip icon=false collapse="true"}
## Sous-échantillonnage

Réduit le nombre d'échantillons de la classe majoritaire.

:::

::: {.callout-tip icon=false collapse="true"}
## Sur-échantillognnage

Augmente le nombre d'échantillons de la classe minoritaire.

:::
    
::: {.callout-tip icon=false collapse="true"}
##  SMOTE
Génère des exemples synthétiques de la classe minoritaire.
:::

* Les modèles utilisés sont les suivants :

::: {.callout-tip icon=false collapse="true"}
## Analyse linéaire discriminante (LDA)
L'analyse discriminante linéaire (LDA) est une technique de classification et de réduction de dimension qui vise à séparer les classes en trouvant une projection linéaire des données qui maximise la séparation entre les classes tout en minimisant la variance au sein des classes. 
:::

::: {.callout-tip icon=false collapse="true"}
## Analyse quadratique discriminante (QDA)

L'analyse discriminante quadratique (QDA) est une extension de l'analyse discriminante linéaire (LDA) qui permet de modéliser des frontières de décision non linéaires. Contrairement à LDA, qui suppose que les covariances des classes sont identiques, QDA permet à chaque classe d'avoir sa propre matrice de covariance. Cela permet une modélisation plus flexible, mais nécessite plus de paramètres et peut donc être moins efficace avec de petits ensembles de données.
:::
 
::: {.callout-tip icon=false collapse="true"}   
## Arbres de décisions

Les arbres de décision sont des modèles de machine learning non paramétriques utilisés pour la classification et la régression. Ils apprennent des règles de décision simples déduites des données pour prédire la valeur de la variable cible.

:::
  
::: {.callout-tip icon=false collapse="true"} 
## Bagging, Boosting
Les termes "Bagging" et "Boosting" sont des techniques utilisées en apprentissage automatique (machine learning) pour améliorer les performances des modèles prédictifs en utilisant des ensembles de modèles plus simples.
:::

::: {.callout-tip icon=false collapse="true"}
## Forêts aléatoires
:::   

   

# Principaux résultats

Après avoir entraîné les modèles sur l'échantillon d'entraînement, nous avons appliqué les modèles sur les données test. Plus précisément, nous avons comparé les résultats obtenu en ayant pris en compte le déséquilibre des classes et ceux obtenu en ne l'ayant pas pris en compte. Il s'avère que le modèle que nous avons retenu sur la base des métriques d'évaluation est une **Forêt Aléatoire** sur laquelle nous avons appliqué la méthode SMOTE. Il présente un taux de bonne prédictions de 94,6% contre 5,4% de taux de mauvaises prédictions.

# Conclusions et perspective

Il est fort probable de rencontrer un déséquilibre de classes de la variable à expliquer pour les problèmes de classification supervisée. C'est un aspect qui biaise fortement les résultats d'estimations. Par conséquent, il est important de pouvoir le détecter assez tôt et appliquer les méthodes adéquates pour résoudre le problème. Au sortir de là, nous obtenons un modèle qui n'est pas biaisé. Ce dernier nous permet donc aisément de prédire l'appartenance à l'une des classes de la variable à expliquer. Dans le cas des défauts de paiement bancaire, l'intérêt de ce genre de méthodes est qu'elle donne la possibilité de mettre en place de moyens de prévention pour se protéger des risques des personnes qui sont en défauts de paiement.

# Outil technique 

- {{< fa brands r-project >}}


```{r include_pdf, echo=FALSE, fig.width=10, fig.height=6 }
knitr::include_graphics("/Users/f.b/Desktop/Data_Science/Data_Science/Personal_portfolio/Personal_portfolio/posts/third/Application de modèles de machine learning.pdf")
```

::: {style="text-align:center;"}
[<img src="down.png" width="100"/>](https://drive.google.com/file/d/1jjlFMDcByaBqEMHDY7o6BApwaPJE7SG-/view?usp=sharing)
:::
