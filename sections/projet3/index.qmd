---
title: "Pr√©vision des d√©fauts de paiement bancaire"
title-block-banner: true
toc: true
toc-title: üìö Table des mati√®res
lang: fr
number-sections: true
subtitle: ""
author: "`BOUSSENGUI Fran√ßois` - `BARRE Nicolas` - `LEGER Aline`"
description: "*Application des m√©thodes de classification supervis√©e*"
image: /assets/img/projet3/cs.jpg
categories: [Machine Learning]
format:
    html:
        code-fold: true
        code-line-numbers: false
        anchor-sections: true
        smooth-scroll: true
        citations-hover: true
        footnotes-hover: true
        html-math-method: mathjax
---

::: {.tech-badges}
::: {.tech-badge .badge-r}
{{< fa brands r-project >}} R
:::
::: {.tech-badge .badge-ml}
{{< fa brain >}} Machine Learning
:::
::: {.tech-badge .badge-datascience}
{{< fa chart-bar >}} Classification
:::
:::

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = "center", out.width = "100%")
```

# Contexte 

La d√©tection des d√©fauts de paiements des cr√©dits bancaires est un enjeu majeur pour les banques. Une gestion rigoureuse, permet d'avoir un recouvrement de cr√©ance efficace et maintenir des flux de tr√©sorerie solides. De ce fait, il est essentiel de minimmiser ces pertes. La **classification supervis√©e** regroupe l'ensemble des m√©thodes statistiques dont l'objectif principal est de pr√©dire pour un individu donn√© l'appartenance √† une classe connue au pr√©alable. Nous sommes ici dans le cas d'une banque de d√©tails qui souhaite attribuer un *score* ou *probabilit√©* de risque √† ses clients. 

# Objectifs

Ainsi, dans le cas des d√©fauts de paiement bancaire, l'objectif est de pouvoir mod√©liser l'appartenance d'un individu √† l'une des classes suivantes :

1.  **Oui** [1], l'individu est en d√©faut de paiement ;

2.  **Non** [0], l'individu n'est pas en d√©faut de paiement ;


# M√©thodologie

De prime abord, nous avons r√©alis√© une analyse descriptive qui a nous permis de mettre en exergue un **d√©s√©quilibre des classes** pour la variable √† expliquer. En d'autres termes, nous avons une pr√©sence √©lev√©e de personne n'√©tant pas en d√©faut de paiement contrairement √† celles qui le sont. 

Cela est un fait positif pour une banque en soi. 

Cependant, ce d√©s√©quilibre impact n√©gativement la performance et biaise le r√©sultat des mod√®les.  

Cela nous a donc conduit a proc√©d√© comme suit :


*   D√©coupage de la population en 2 sous-groupes :

    +   Un groupe d√©di√© √† l'apprentissage, autrement dit, le groupe d'entra√Ænement (2/3) ;

    +   Un groupe d√©di√© √† la validation des mod√®les, autrement dit, le groupe test (1/3) ;

*   Premi√®re application des mod√®les sans prise en compte du d√©s√©quilibre des classes. 

*   Seconde √† application des mod√®les en prenant en compte le d√©s√©quilibre des classes par le biais d'application de m√©thode de r√©-√©chantillonnage des classes, √† savoir :

::: {.callout-tip icon=false collapse="true"}
## Sous-√©chantillonnage

R√©duit le nombre d'√©chantillons de la classe majoritaire.

:::

::: {.callout-tip icon=false collapse="true"}
## Sur-√©chantillognnage

Augmente le nombre d'√©chantillons de la classe minoritaire.

:::
    
::: {.callout-tip icon=false collapse="true"}
##  SMOTE

G√©n√®re des exemples synth√©tiques de la classe minoritaire.

:::

* Les mod√®les utilis√©s sont les suivants :

::: {.callout-tip icon=false collapse="true"}
## Analyse lin√©aire discriminante (LDA)

L'analyse discriminante lin√©aire (LDA) est une technique de classification et de r√©duction de dimension qui vise √† s√©parer les classes en trouvant une projection lin√©aire des donn√©es qui maximise la s√©paration entre les classes tout en minimisant la variance au sein des classes. 

:::

::: {.callout-tip icon=false collapse="true"}
## Analyse quadratique discriminante (QDA)

L'analyse discriminante quadratique (QDA) est une extension de l'analyse discriminante lin√©aire (LDA) qui permet de mod√©liser des fronti√®res de d√©cision non lin√©aires. Contrairement √† LDA, qui suppose que les covariances des classes sont identiques, QDA permet √† chaque classe d'avoir sa propre matrice de covariance. Cela permet une mod√©lisation plus flexible, mais n√©cessite plus de param√®tres et peut donc √™tre moins efficace avec de petits ensembles de donn√©es.
:::
 
::: {.callout-tip icon=false collapse="true"}   
## Arbres de d√©cisions

Les arbres de d√©cision sont des mod√®les de machine learning non param√©triques utilis√©s pour la classification et la r√©gression. Ils apprennent des r√®gles de d√©cision simples d√©duites des donn√©es pour pr√©dire la valeur de la variable cible.

:::
  
::: {.callout-tip icon=false collapse="true"} 
## Bagging, Boosting

Les termes "Bagging" et "Boosting" sont des techniques utilis√©es en apprentissage automatique (machine learning) pour am√©liorer les performances des mod√®les pr√©dictifs en utilisant des ensembles de mod√®les plus simples.

:::

::: {.callout-tip icon=false collapse="true"}
## For√™ts al√©atoires

Les for√™ts al√©atoires sont une technique de machine learning utilis√©e pour la classification et la r√©gression. Elles fonctionnent en combinant plusieurs arbres de d√©cision, chacun construit sur un √©chantillon diff√©rent des donn√©es d'entra√Ænement. Le principe de base est le suivant :

1. **Construction d'arbres** : Un grand nombre d'arbres de d√©cision sont construits, chaque arbre √©tant entra√Æn√© sur un √©chantillon al√©atoire des donn√©es d'entra√Ænement.
2. **Pr√©diction par vote majoritaire** : Pour la classification, chaque arbre "vote" pour une classe, et la classe la plus souvent choisie par les arbres est la pr√©diction finale. Pour la r√©gression, la pr√©diction finale est la moyenne des pr√©dictions de tous les arbres.

L'utilisation de multiples arbres et l'√©chantillonnage al√©atoire des donn√©es permettent de r√©duire le risque de surapprentissage (overfitting) et d'am√©liorer la robustesse et la pr√©cision des pr√©dictions.

:::   

   

# Principaux 

Apr√®s avoir entra√Æn√© les mod√®les sur l'√©chantillon d'entra√Ænement, nous avons appliqu√© les mod√®les sur les donn√©es test afin d'en appr√©cier leur performance. Plus pr√©cis√©ment, nous avons compar√© les r√©sultats de nos 2 approches. C'est-√†-dire l'approche tenant compte du d√©s√©quilibre des classes et celle ne la prenant pas en compte.

Sur la base des diff√©rentes m√©triques d'√©valuation que nous avons utilis√©, ils s'av√®re que le mod√®le le plus performabnt est une **For√™t Al√©atoire** sur laquelle nous avons appliqu√© la m√©thode **SMOTE**. 

Le mod√®le retenu pr√©sente un taux de bonne pr√©dictions de 94,6% contre 5,4% de taux de mauvaises pr√©dictions.

# Conclusions et perspective

Dans la r√©alit√©, il est tr√®s probable de rencontrer un d√©s√©quilibre de classes de la variable √† expliquer pour les probl√®mes de classification supervis√©e. Surtout dans le milieu bancaire. 

C'est un aspect qui biaise fortement les r√©sultats d'estimations. Par cons√©quent, il est important de pouvoir le d√©tecter assez t√¥t et appliquer les m√©thodes ad√©quates pour prendre en compte le probl√®me. Au sortir de l√†, cela nous permet d'obtenir un mod√®le qui n'est pas biais√©. Ce dernier nous permet donc ais√©ment de pr√©dire, pour un individu donn√©, sa probabilit√© d'appartenance √† l'une des classes de la variable √† expliquer. Dans le cas des d√©fauts de paiement bancaire, l'int√©r√™t de ce genre de m√©thodes est qu'elle donne la possibilit√© de mettre en place de moyens de pr√©vention pour se pr√©munir des personnes qui pr√©sentent un fort risque d'√™tre en d√©faut de paiement. 

# Outil technique 

- **Logiciel** {{< fa brands r-project >}}


::: {style="text-align:center;"}

> Vous trouverez le rapport ici :

::: chevron-styling
{{< iconify pixelarticons:chevron-down size=5x >}}
:::
:::

::: {style="text-align:center;"}
[Lire le rapport {{< fa arrow-up-right-from-square >}}](/assets/img/projet3/ml.pdf){.btn .btn-outline-primary .btn .center role="button"}
:::

